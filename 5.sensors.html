<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

        
            <link rel="icon" href="assets/sibin.integral.favicon.ico">
        

        <link rel="stylesheet" href="assets/reveal-js/dist/reveal.css" />

        
            <link rel="stylesheet" href="assets/custom.sibin.css" />
        
        
            <link rel="stylesheet" href="assets/monokai.css" />
        

        
            
        
            
        
    </head>
    <body>
        <div class="reveal">
            <div class="slides">
                <section data-markdown
                
                    data-separator="^\s*---\s*$"
                
                    data-separator-vertical="^\s*-v-\s*$"
                
                    data-separator-notes="^Notes?:"
                
                    data-charset="utf-8"
                
                    data-auto-animate="True"
                
                >
                    <textarea data-template>
                        # sensors and sensing

## **Design of Autonomous Systems**
### csci 6907/4907-Section 86
### Prof. **Sibin Mohan**

---

embedded/autonomous system

---

embedded/autonomous system

<br>

### **perceives** the physical world via sensors

---

### **perceives** the physical world via sensors

gather information about:
- environment
- its _own_ state

---

## sensors

---

## sensors

critical component in...

<img src="img/sense_planning_actuation.png" width="700">

---

## sensors

today, we discuss...

|||
|------|-------|
|<img src="img/sense_planning_actuation.png" width="600">|<img src="img/stack_architecture/stack_overview.2.png" width="500">|
||

---

## sensors

modern autonomous systems &rarr; _wide array_ of sensors

---

## sensors

modern autonomous systems &rarr; _wide array_ of sensors

- measure **different** quantities, _e.g.,_ GPS, velocity, objects, _etc._

---

## sensors

modern autonomous systems &rarr; _wide array_ of sensors

- measure **different** quantities, _e.g.,_ GPS, velocity, objects, _etc._
- sensor measurements often have **errors** 

---

## core idea of sensor

capture physical/chemical/environmental quantity...

---

## core idea of sensor

capture physical/chemical/environmental quantity...

...**convert it to a digital quantity**!

---

## signals

- by definition, sensors generate **signals**

---

## signals

- by definition, sensors generate **signals**
- mapping from the _time_ domain to a _value_ domain


---

## signals

- mapping from the _time_ domain to a _value_ domain

$$
s: D_t \mapsto D_v
$$

---

## signals

- mapping from the _time_ domain to a _value_ domain

$$
s: D_t \mapsto D_v
$$

| symbol | description |
|--------|------------------------------------------|
| $D_t$  | continuous or discrete **time** domain   |
| $D_v$  | continuous or discrete **value** domain  |
||

---

## discrete

<img src="img/sensors/discreet-undercover-sneaky.gif">

---

## discrete

**not** continuous &rarr; **sampling**

---

## discrete

**not** continuous &rarr; **sampling**

<img src="img/sensors/discretization_sampled.signal.svg" title="Sampling image from Wikipedia">

<font color="red"><b>red</b></font> arrows &rarr; instances of sampling

---

<img src="img/sensors/discretization_sampled.signal.svg" title="Sampling image from Wikipedia">

<font color="red"><b>red</b></font> arrows &rarr; instances of sampling

[we will come back to sampling later]

---

## **Types** of Sensors

---

## **Types** of Sensors

- sensors come in various shapes and sizes

---

## **Types** of Sensors

- sensors come in various shapes and sizes
- designers &rarr; develop a **sensor plan**

---

## sensor plan considers

- required functionality
- sensor range(s)
- cost

---

## sensor plan considers

- required functionality
- sensor range(s)
- cost

each autonomous system &rarr; its **own set of sensors**

---

## classification of sensors

---

## classification of sensors

on _typical_ autonomous systems...

---

## classification of sensors

...based on physics used

---

## classification of sensors

|physical property|sensor|
|-----------------|-------|

---

## classification of sensors

|physical property|sensor|
|-----------------|-------|
|[_internal_ measurements](#inertial-measurement-units-imu)| IMU |

---

## classification of sensors

|physical property|sensor|
|-----------------|-------|
|[_internal_ measurements](#inertial-measurement-units-imu)| IMU |
|_external_ measurements| GPS |

---

## classification of sensors

|physical property|sensor|
|-----------------|-------|
|[_internal_ measurements](#inertial-measurement-units-imu)| IMU |
|_external_ measurements| GPS |
|["bouncing" <br> electromagnetic waves](#bouncing-of-electromagnetic-waves--lidar-and-mmwave)| LiDAR, RADAR, <br> mmWave Radar|

---

## classification of sensors

|physical property|sensor|
|-----------------|-------|
|[_internal_ measurements](#inertial-measurement-units-imu)| IMU |
|_external_ measurements| GPS |
|["bouncing" <br> electromagnetic waves](#bouncing-of-electromagnetic-waves--lidar-and-mmwave)| LiDAR, RADAR, <br> mmWave Radar|
|optical| cameras, infrared sensors|

---

## classification of sensors

|physical property|sensor|
|-----------------|-------|
|[_internal_ measurements](#inertial-measurement-units-imu)| IMU |
|_external_ measurements| GPS |
|["bouncing" <br> electromagnetic waves](#bouncing-of-electromagnetic-waves--lidar-and-mmwave)| LiDAR, RADAR, <br> mmWave Radar|
|optical| cameras, infrared sensors|
|[accoustic](#ultrasonic)| ultrasonic sensors|
||

---

## classification of sensors

|physical property|sensor|
|-----------------|-------|
|[_internal_ measurements](#inertial-measurement-units-imu)| IMU |
|_external_ measurements| GPS |
|["bouncing" <br> electromagnetic waves](#bouncing-of-electromagnetic-waves--lidar-and-mmwave)| LiDAR, RADAR, <br> mmWave Radar|
|optical| cameras, infrared sensors|
|[accoustic](#ultrasonic)| ultrasonic sensors|
||

will focus on **some** of these

---

some of them can be **combined**

---

some of them can be **combined**

to generate other sensing patterns

---

some of them can be **combined**

to generate other sensing patterns

### _e.g.,_ **stereo vision** using multiple cameras

---

### Inertial Measurement Units (**IMU**)

---

### Inertial Measurement Units (**IMU**)

define movement of vehicles 


---

### Inertial Measurement Units (**IMU**)

define movement of vehicles 

- along **three** axes
- **acceleration**
- **directionality**

---

## IMU sensors

---

## IMU sensors

<img src="img/sensors/imu_exploded_view.png" width="600">

---

## IMU sensors

<img src="img/sensors/imu_exploded_view.png" width="600">

includes a processor/microcontroller

---

## IMU sensors

constituent parts of IMU

|||||
|---------|--------|---------|-----------|
|<img src="img/sensors/imu_exploded_view.png" width="600">|<img src="img/sensors/imu_accelerometer.png" width="400">||
||


---

## IMU sensors

constituent parts of IMU

|||||
|---------|--------|---------|-----------|
|<img src="img/sensors/imu_exploded_view.png" width="600">|<img src="img/sensors/imu_accelerometer.png" width="400">|<img src="img/sensors/imu_gyro.png" width="400">||
||


---

## IMU sensors

constituent parts of IMU

|||||
|---------|--------|---------|-----------|
|<img src="img/sensors/imu_exploded_view.png" width="600">|<img src="img/sensors/imu_accelerometer.png" width="400">|<img src="img/sensors/imu_gyro.png" width="400">|<img src="img/sensors/imu_magnetometer.png" width="400">|
||


---

## IMU sensors

constituent parts of IMU

|||||
|---------|--------|---------|-----------|
|<img src="img/sensors/imu_exploded_view.png" width="600">|<img src="img/sensors/imu_accelerometer.png" width="400">|<img src="img/sensors/imu_gyro.png" width="400">|<img src="img/sensors/imu_magnetometer.png" width="400">|
||

---

## IMU sensors

constituent parts of IMU

|||||
|---------|--------|---------|-----------|
|<img src="img/sensors/imu_exploded_view.png" width="600">|<img src="img/sensors/imu_accelerometer.png" width="400">|<img src="img/sensors/imu_gyro.png" width="400">|<img src="img/sensors/imu_magnetometer.png" width="400">|
||

let's look at the functionality of each one...

-v-

## gyroscope

-v-

## gyroscope

**inertial** sensor

-v-

## gyroscope

**inertial** sensor &rarr; measures **angular rate**

-v-

<!-- .slide: data-background="white" -->

## gyroscope

**inertial** sensor &rarr; measures **angular rate**

||||
|--------|----------|---------|
|<img src="img/sensors/imu_yaw.gif">|<img src="img/sensors/imu_pitch.gif">|<img src="img/sensors/imu_roll.gif">|
| "yaw" | "pitch" | "roll" |
||

Note: 
MUs come in all shapes and sizes. These days they're very small but the original IMU's ver really large, as evidenced by the one used in the [Apollo space missions]

-v-

|accelerometer|magnetometer|
|-------------|------------|
|inertial acceleration|strength/direction of magnetic field|

---

## LiDAR

---

## LiDAR

light detection and ranging

---

## LiDAR

light detection and ranging

- uses eye safe **lasers beams**
- mapping surroundings 
- create **3D representation**

---

## LiDAR

light detection and ranging

- uses eye safe **lasers beams**
- mapping surroundings 
- create **3D representation**

Note:
lasers are used for...
- imaging
- detection 
- ranging

---

<!-- .slide: data-background="white" -->

### typical operation

<img src="img/sensors/lidar_principle_operation.png" width="1000">

---

<!-- .slide: data-background="white" -->

### typical operation

<img src="img/sensors/lidar_principle_operation.png" width="700">

**round trip time**:

$$
R = \frac{c\tau}{2}
$$

where, `c` is the speed of light. 

---

<!-- .slide: data-background="white" -->

3D representation &rarr; **point cloud**

<img src="img/sensors/lidar_point_cloud_torus.gif" title="3D point cloud of a Torus. Courtesy Wikipedia" width="700">

---

### points clouds around autonomous vehicles

<video controls width="900"> <source src="https://sibin.github.io/teaching/csci6907_88-gwu-secure_autonomous/fall_2022/other_docs/What-is-Lidar-video.mp4"></video>

---

## point clouds

- **3D coordinates**, $(x, y, z)$

---

## point clouds

- **3D coordinates**, $(x, y, z)$
- **strength** of returned signal 
    - **density**/material composition of objects!

---

## point clouds

- **3D coordinates**, $(x, y, z)$
- **strength** of returned signal 
    - **density**/material composition of objects!
- additional **attributes**: 
    - return number, scan angle, scan direction, 
    - point density, RGB color values, time stamps
    - each can be used for refining the scan.

---

## scene illumination

---

<!-- .slide: data-background="white" -->

## scene illumination | **flash** lidar

<img src="img/sensors/lidar_flash.png" width="900"> 

Note:
- _entire_ scene using wide laser 
- receives all echoes on a photodetector array |

---

<!-- .slide: data-background="white" -->

## scene illumination | **scan** lidar

<img src="img/sensors/lidar_scan.png" width="900"> 

Note:
- very narrow laser beams, scan illumination spot with laser beam scanner 
- single photodetector to sequentially estimate $\tau$ for each spot

---

<!-- .slide: data-background="white" -->

## scene illumination | comparison

| | flash lidar | scan lidar |
|----|----|------|
| **architecture** | <img src="img/sensors/lidar_flash.png" width="400"> | <img src="img/sensors/lidar_scan.png" width="400"> |
| **resolution** determined by | photodetector array pizel size (like camera) | laser beam size and spot fixing |
| **frame rates** | higher (up to `100 fps`) | lower (< `30 fps`) |
| **range** | shorter (quick beam divergence, like photography) | longer (`100m+`) |
| **use**   | less common | **most common** |
||

---

## scene illumination | _image_ comparison

consider the following "scene" (taken using camera)

<img src="img/sensors/lidar_camera_image.png" width="1100">

---

## scene illumination | **flash** image

<img src="img/sensors/lidar_flash_image.png" width="1100">

---

## scene illumination | **scan** image [16 lines]

<img src="img/sensors/lidar_scan_16.png" width="1100">

---

## scene illumination | **scan** image [32 lines]

<img src="img/sensors/lidar_scan_32.png" width="1100">


---

## scene illumination | image comparisons

|flash lidar | scan lidar [16] | scan lidar [32] |
|----|----|-----|
| <img src="img/sensors/lidar_flash_image.png" width="400"> | <img src="img/sensors/lidar_scan_16.png" width="400"> | <img src="img/sensors/lidar_scan_32.png" width="400">|
||


---

## potential problems

atmospheric/environmental conditions &rarr; **false positives**

<img src="img/sensors/lidar_fog.png" width="1300">


---

look up the [textbook chapter on sensing](https://autonomy-course.github.io/textbook/autonomy-textbook.html#sensors-and-sensing) 
- for more information about LiDAR 
- also the mmWave RADAR sensor

---

## Errors in Sensing

---

## Errors in Sensing

- sensors deal with &rarr; physical world
- **errors** creep up over time!


---

## Errors in Sensing | types

- sensor **drift**
- **constant bias**
- **calibration** errors
- **scale factor**
- **vibration rectification** errors
- **noise**

Note:
| error type | description |
|----------------|-------------|
| **sensor drift** | over time the sensor measurements will "drift", i.e., a gradual change in its output &rarr; away from average values (e.g., due to wear and tear) |
| **constant bias** | bias of an accelerometer is the offset of its output signal from the actual acceleration value. A constant bias error causes an error in position which grows with time |
| **calibration errors** | ‘calibration errors’ refers to errors in the scale factors, alignments and linearities of the gyros. Such errors tend to produce errors when the device is turning. These errors can result in additional drift |
| **scale factor** | scale factor is the relation of the accelerometer input to the actual sensor output for the measurement. Scale factor, expressed in ppm, is therefore the linear growth of input variation to actual measurement |
| **vibration rectification errors** | vibration rectification error (VRE) is the response of an accelerometer to current rectification in the sensor, causing a shift in the offset of the accelerometer. This can be a significant cumulative error, which propagates with time and can lead to over compensation in stabilization |
| **noise** | random variations in the sensor output that do not correspond to the actual measured value |
||

---

## Errors in Sensing

each error &rarr; dealt with differently

---

## Errors in Sensing

each error &rarr; dealt with differently

can use **sensor fusion** to mitigate some errors

---

## analog-to-digital convertor (ADC)

---

## analog-to-digital convertor (ADC)

$$s: D_t \mapsto D_v$$

---

## analog-to-digital convertor (ADC)

$$s: D_t \mapsto D_v$$

microcontrollers **cannot** read values &rarr; unless it is **digital**

---

need to **convert** signals into **discrete** values

---

$$s: D_t \mapsto D_v$$

$D_v$ must be **discrete**

Note:
A discrete signal or discrete-time signal is a time series consisting of a sequence of quantities. Unlike a continuous-time signal, a discrete-time signal is not a function of a continuous argument; however, it may have been obtained by sampling from a continuous-time signal. When a discrete-time signal is obtained by sampling a sequence at uniformly spaced times, it has an associated **sampling rate**.

---

## sampling

**convert analog &rarr; digital**

---

<!-- .slide: data-background="white" -->

## sampling

**convert analog &rarr; digital**

|analog signal|||
|-------------|-------------|--------|
|<img src="img/sensors/adc_analog_signal.png">|||
||


---

<!-- .slide: data-background="white" -->

## sampling

**convert analog &rarr; digital**

|analog signal|sampling rate||
|-------------|-------------|--------|
|<img src="img/sensors/adc_analog_signal.png" width="700">|<img src="img/sensors/adc_sampling_rate.png" width="700">||
||

---

<!-- .slide: data-background="white" -->

## sampling

**convert analog &rarr; digital**

|analog signal|sampling rate|sampling|
|-------------|-------------|--------|
|<img src="img/sensors/adc_analog_signal.png" width="500">|<img src="img/sensors/adc_sampling_rate.png" width="500">|<img src="img/sensors/adc_sampling.png" width="600">|
||

---

## adc

- device that converts analog &rarr; digital
- very common circuit/microcontroller
- any _physical_ sensor signal &rarr; pass through ADC

---

<!-- .slide: data-background="white" -->

## adc | example

<img src="img/sensors/adc_example.jpg" width="1100">

<font color="blue"><b>analog</b></font> signal is **discretized** into the <font color="red"><b>digital</b></font> signal 

---

## adc | sequence

- **sample** the signal
- **quantify** &rarr; determine resolution
- set **binary values**
- **send to system** read digital signal

---

### adc | important aspects

1. sampling rate
2. resolution

---

## ADC | **Sampling Rate**

- samples per second (SPS or S/s)
- **how many samples** (data points) are taken
- more samples &rarr; higher frequencies

---

## sample rate: $ f_s = \frac{1}{T} $

---

## sample rate: $ f_s = \frac{1}{T} $


|symbol|definition|
|------|----------|
|$f_s$ | sampling rate/frequency|
|$T$ | period of the sample |
||

---

<!-- .slide: data-background="white" -->

<img src="img/sensors/adc_example.jpg" width="1100">

|symbol|value|
|------|----------|
|$f_s$ | `20 Hz` |
|$T$ | `50 ms` |
||

---

<!-- .slide: data-background="white" -->

<img src="img/sensors/adc_example.jpg" width="1100">

|symbol|value|
|------|----------|
|$f_s$ | `20 Hz` |
|$T$ | `50 ms` |
||

this is _slow_ but, signal frequency: `1 Hz`

---

what if,

sampling frequency << signal frequency?

---

what if,

sampling frequency << signal frequency?

## aliasing!

---

## aliasing!

reconstructed signal &rarr; differs from input!

---

<!-- .slide: data-background="white" -->

## aliasing!

reconstructed signal &rarr; differs from input!

<img src="img/sensors/adc_aliasing_example.jpg" width="900">

---

## **Nyquist-Shannon Sampling Theorem**

---

## **Nyquist-Shannon Sampling Theorem**

> sampling rate = **at least twice the highest frequency component**

---

## **Nyquist-Shannon Sampling Theorem**

> sampling rate = **at least twice the highest frequency component**

if less &rarr; aliasing creeps in!

---

## $f_{Nyquist} = 2* f_{max}$

---

## $f_{Nyquist} = 2* f_{max}$

<br>

|symbol|definition|
|------|----------|
|$f_{Nyquist}$ | Nyquist sampling rate/frequency|
|$f_{max}$ | the maximum frequency that appears in the signal |
||

---

## adc | **resolution**

---

## adc | **resolution**

- directly related to precision
- determined by **bit length**

---

<!-- .slide: data-background="white" -->

## adc | **bit length**

<img src="img/sensors/adc_resolution_example.jpg" width="900">

---

<!-- .slide: data-background="white" -->

## adc | **bit length**

<img src="img/sensors/adc_resolution_example.jpg" width="900">

increasing bit lengths &rarr; digital signal better representation

---

## adc | **true** resolution

---

## adc | **true** resolution

$$
Step Size = \frac{V_{ref}}{N}
$$

---

## adc | **true** resolution

$$
Step Size = \frac{V_{ref}}{N}
$$

|symbol|definition|
|------|----------|
|$Step Size$| resolution of each level in terms of voltage|
|$V_{ref}$ |voltage reference/range of voltages|
|$N = 2^n$ | total "size" of the ADC|
|$n$ | bit size|
||

---

## numerical example

- sine wave, voltage = `5V`
- ADC chip precision = `12 bits`

---

## numerical example

- sine wave, voltage = `5V`
- ADC chip precision = `12 bits`
- $N = 2^{12} = $ `4096`

---

## numerical example

- sine wave, voltage = `5V`
- ADC chip precision = `12 bits`
- $N = 2^{12} = $ `4096`


- $Step Size = 5V /\ 4096$ = `0.00122V` (or `1.22mV`)

---

system can tell &rarr; voltage level changes by `1.22 mV`!

---

what happens if, $n=4$?

---

sampling **frequency** and **resolution** &rarr; **quality** of ADC output
                    </textarea>
                </section>
            </div>
        </div>
        <script src="assets/reveal-js/dist/reveal.js"></script>
        <script src="assets/reveal-js/plugin/markdown/markdown.js"></script>
        <script src="assets/reveal-js/plugin/highlight/highlight.js"></script>
        <script src="assets/reveal-js/plugin/zoom/zoom.js"></script>
        <script src="assets/reveal-js/plugin/notes/notes.js"></script>
        <script src="assets/reveal-js/plugin/math/math.js"></script>

        
            
                
                    
                        <script src="https://cdn.jsdelivr.net/npm/reveal.js-mermaid-plugin/plugin/mermaid/mermaid.min.js"></script>
                    
                
            
                
                    
                        <script src="https://cdn.jsdelivr.net/npm/reveal-plantuml/dist/reveal-plantuml.min.js"></script>
                    
                
            
        

        <script>
            Reveal.initialize({
                
                    
                        history: true,
                    
                        slideNumber: "c/t",
                    
                        height: 1080,
                    
                        width: 1920,
                    
                        transition: "fade",
                    
                        backgroundTransition: "slide",
                    
                        RevealMermaid: {"htmlLabels": true, "useMaxWidth": true},
                    
                
                plugins: [
                    RevealMarkdown,
                    RevealHighlight,
                    RevealZoom,
                    RevealNotes,
                    RevealMath,

                    
                        
                            
                                RevealMermaid,
                            
                        
                            
                        
                    
                ],
            });
        </script>
    </body>
</html>