<!doctype html>
<html >
<head>

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!--[if lt IE 9]>
                <script src="http://css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
        <![endif]-->
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Style-Type" content="text/css" />

    <!-- <link rel="stylesheet" type="text/css" href="template.css" /> -->
    <link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/template.css" />

    <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />

    <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
    <!-- <script type='text/javascript' src='menu/js/jquery.cookie.js'></script> -->
    <!-- <script type='text/javascript' src='menu/js/jquery.hoverIntent.minified.js'></script> -->
    <!-- <script type='text/javascript' src='menu/js/jquery.dcjqaccordion.2.7.min.js'></script> -->

    <!-- <link href="menu/css/skins/blue.css" rel="stylesheet" type="text/css" /> -->
    <!-- <link href="menu/css/skins/graphite.css" rel="stylesheet" type="text/css" /> -->
    <!-- <link href="menu/css/skins/grey.css" rel="stylesheet" type="text/css" /> -->

    <!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->


    <!-- <script src="script.js"></script> -->

    <!-- <script src="jquery.sticky-kit.js "></script> -->
    <script type='text/javascript' src='https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/js/jquery.cookie.js'></script>
    <script type='text/javascript' src='https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/js/jquery.hoverIntent.minified.js'></script>
    <script type='text/javascript' src='https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/js/jquery.dcjqaccordion.2.7.min.js'></script>

    <link href="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/css/skins/blue.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/css/skins/graphite.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/css/skins/grey.css" rel="stylesheet" type="text/css" />
    <link href="./elegant_bootstrap.css" rel="stylesheet" type="text/css" />
    <!-- <link href="https://cdn.rawgit.com/ryangrose/easy-pandoc-templates/948e28e5/css/elegant_bootstrap.css" rel="stylesheet" type="text/css" /> -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script src="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/script.js"></script>

    <script src="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/jquery.sticky-kit.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <meta name="generator" content="pandoc" />
  <meta name="author" content="Prof. Sibin Mohan, The George Washington University" />
  <meta name="date" content="2025-02-04" />
  <title>Design of Autonomous Systems</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="style.css" />
</head>
<body>


    <div class="navbar navbar-static-top">
    <div class="navbar-inner">
      <div class="container">
        <span class="doc-title">Design of Autonomous Systems</span>
        <ul class="nav pull-right doc-info">
                    <li><p class="navbar-text">Prof. Sibin Mohan, The
George Washington University</p></li>
                              <li><p class="navbar-text">February 04,
2025</p></li>
                  </ul>
      </div>
    </div>
  </div>
    <div class="container">
    <div class="row">
            <div id="TOC" class="span3">
        <div class="well toc">

        <ul>
        <li><a href="#introduction" id="toc-introduction"><span
        class="toc-section-number">1</span> introduction</a>
        <ul>
        <li><a href="#autonomy" id="toc-autonomy"><span
        class="toc-section-number">1.1</span> autonomy</a>
        <ul>
        <li><a href="#what-are-the-aspects-of-autonomy"
        id="toc-what-are-the-aspects-of-autonomy"><span
        class="toc-section-number">1.1.1</span> what are the
        <em>aspects</em> of autonomy?</a></li>
        </ul></li>
        <li><a href="#let-us-define-autonomy"
        id="toc-let-us-define-autonomy"><span
        class="toc-section-number">1.2</span> let us define
        <strong>autonomy</strong></a></li>
        <li><a href="#autonomous-systems"
        id="toc-autonomous-systems"><span
        class="toc-section-number">1.3</span> autonomous
        systems</a></li>
        <li><a href="#sensors-and-actuators"
        id="toc-sensors-and-actuators"><span
        class="toc-section-number">1.4</span> sensors and
        actuators…</a></li>
        <li><a href="#sensing-and-actuation-in-the-real-world"
        id="toc-sensing-and-actuation-in-the-real-world"><span
        class="toc-section-number">1.5</span> sensing and actuation in
        the real world</a>
        <ul>
        <li><a href="#come-back-to-sensing"
        id="toc-come-back-to-sensing"><span
        class="toc-section-number">1.5.1</span> Come back to
        <strong>sensing</strong></a></li>
        </ul></li>
        <li><a href="#overviewarchitecture-of-autonomous-systems"
        id="toc-overviewarchitecture-of-autonomous-systems"><span
        class="toc-section-number">1.6</span> Overview/Architecture of
        Autonomous Systems</a>
        <ul>
        <li><a href="#high-order-functions"
        id="toc-high-order-functions"><span
        class="toc-section-number">1.6.1</span> high-order
        functions</a></li>
        <li><a href="#slam" id="toc-slam"><span
        class="toc-section-number">1.6.2</span> slam</a></li>
        <li><a href="#waypoint-detection"
        id="toc-waypoint-detection"><span
        class="toc-section-number">1.6.3</span> waypoint
        detection</a></li>
        <li><a href="#yolo" id="toc-yolo"><span
        class="toc-section-number">1.6.4</span> yolo</a></li>
        <li><a href="#object-avoidance" id="toc-object-avoidance"><span
        class="toc-section-number">1.6.5</span> object
        avoidance</a></li>
        <li><a href="#path-planning" id="toc-path-planning"><span
        class="toc-section-number">1.6.6</span> path planning</a></li>
        <li><a href="#compute-platform" id="toc-compute-platform"><span
        class="toc-section-number">1.6.7</span> compute
        platform</a></li>
        <li><a href="#still-some-non-functional-requirements-remain"
        id="toc-still-some-non-functional-requirements-remain"><span
        class="toc-section-number">1.6.8</span> still some
        <strong>non-functional</strong> requirements remain</a></li>
        <li><a href="#safety" id="toc-safety"><span
        class="toc-section-number">1.6.9</span> safety!</a></li>
        <li><a href="#security" id="toc-security"><span
        class="toc-section-number">1.6.10</span> security</a></li>
        <li><a href="#course-structure" id="toc-course-structure"><span
        class="toc-section-number">1.6.11</span> Course
        Structure</a></li>
        </ul></li>
        </ul></li>
        <li><a href="#embedded-architectures"
        id="toc-embedded-architectures"><span
        class="toc-section-number">2</span> Embedded Architectures</a>
        <ul>
        <li><a href="#the-wcet-problem" id="toc-the-wcet-problem"><span
        class="toc-section-number">2.1</span> The <strong>wcet</strong>
        problem</a></li>
        <li><a href="#embedded-processors"
        id="toc-embedded-processors"><span
        class="toc-section-number">2.2</span> Embedded Processors</a>
        <ul>
        <li><a href="#microcontrollers" id="toc-microcontrollers"><span
        class="toc-section-number">2.2.1</span>
        Microcontrollers</a></li>
        <li><a href="#digital-signal-processors-dsps"
        id="toc-digital-signal-processors-dsps"><span
        class="toc-section-number">2.2.2</span> Digital Signal
        Processors (DSPs)</a></li>
        <li><a href="#microprocessors" id="toc-microprocessors"><span
        class="toc-section-number">2.2.3</span> Microprocessors</a></li>
        <li><a href="#system-on-a-chip-soc"
        id="toc-system-on-a-chip-soc"><span
        class="toc-section-number">2.2.4</span> System-on-a-Chip
        (SoC)</a></li>
        <li><a href="#embedded-accelarators-e.g.-gpu-enabled-systems"
        id="toc-embedded-accelarators-e.g.-gpu-enabled-systems"><span
        class="toc-section-number">2.2.5</span> Embedded Accelarators
        (e.g. GPU-enabled systems)</a></li>
        <li><a href="#asics-and-fpgas" id="toc-asics-and-fpgas"><span
        class="toc-section-number">2.2.6</span> ASICs and FPGAs</a></li>
        </ul></li>
        <li><a href="#communication-and-io"
        id="toc-communication-and-io"><span
        class="toc-section-number">2.3</span> Communication and I/O</a>
        <ul>
        <li><a href="#uart-rs-232" id="toc-uart-rs-232"><span
        class="toc-section-number">2.3.1</span> UART | RS-232</a></li>
        <li><a href="#synchronous-i2c-and-spi"
        id="toc-synchronous-i2c-and-spi"><span
        class="toc-section-number">2.3.2</span> Synchronous |
        I<sup>2</sup>C and SPI</a></li>
        <li><a href="#general-purpose-io-gpio"
        id="toc-general-purpose-io-gpio"><span
        class="toc-section-number">2.3.3</span> General-Purpose I/O
        (GPIO)</a></li>
        <li><a href="#jtag-debugging-interface"
        id="toc-jtag-debugging-interface"><span
        class="toc-section-number">2.3.4</span> JTAG Debugging
        Interface</a></li>
        <li><a href="#controller-area-network-can"
        id="toc-controller-area-network-can"><span
        class="toc-section-number">2.3.5</span> Controller Area Network
        (CAN)</a></li>
        <li><a href="#other-broadly-used-protocols"
        id="toc-other-broadly-used-protocols"><span
        class="toc-section-number">2.3.6</span> Other Broadly Used
        Protocols</a></li>
        </ul></li>
        <li><a href="#raspberry-pi-and-navio2"
        id="toc-raspberry-pi-and-navio2"><span
        class="toc-section-number">2.4</span> Raspberry Pi and
        Navio2</a></li>
        <li><a href="#references" id="toc-references"><span
        class="toc-section-number">2.5</span> References</a></li>
        </ul></li>
        <li><a href="#sensors-and-sensing"
        id="toc-sensors-and-sensing"><span
        class="toc-section-number">3</span> Sensors and Sensing</a>
        <ul>
        <li><a href="#types-of-sensors" id="toc-types-of-sensors"><span
        class="toc-section-number">3.1</span> Types of Sensors</a>
        <ul>
        <li><a href="#inertial-measurement-units-imu"
        id="toc-inertial-measurement-units-imu"><span
        class="toc-section-number">3.1.1</span> Inertial Measurement
        Units (IMU)</a></li>
        <li><a
        href="#bouncing-of-electromagnetic-waves-lidar-and-mmwave"
        id="toc-bouncing-of-electromagnetic-waves-lidar-and-mmwave"><span
        class="toc-section-number">3.1.2</span> Bouncing of
        Electromagnetic Waves | LiDAR and mmWave</a></li>
        <li><a href="#ultrasonic" id="toc-ultrasonic"><span
        class="toc-section-number">3.1.3</span> Ultrasonic</a></li>
        </ul></li>
        <li><a href="#errors-in-sensing"
        id="toc-errors-in-sensing"><span
        class="toc-section-number">3.2</span> Errors in Sensing</a></li>
        <li><a href="#analog-to-digital-convertors-adcs"
        id="toc-analog-to-digital-convertors-adcs"><span
        class="toc-section-number">3.3</span> Analog to Digital
        Convertors (ADCs)</a>
        <ul>
        <li><a href="#adc-sampling-rate"
        id="toc-adc-sampling-rate"><span
        class="toc-section-number">3.3.1</span> ADC Sampling
        Rate</a></li>
        <li><a href="#adc-resolution" id="toc-adc-resolution"><span
        class="toc-section-number">3.3.2</span> ADC Resolution</a></li>
        </ul></li>
        </ul></li>
        <li><a href="#real-time-operating-systems"
        id="toc-real-time-operating-systems"><span
        class="toc-section-number">4</span> Real-Time Operating
        Systems</a>
        <ul>
        <li><a href="#key-characteristics-for-rtos"
        id="toc-key-characteristics-for-rtos"><span
        class="toc-section-number">4.0.1</span> Key characteristics for
        RTOS</a></li>
        <li><a href="#kernels-in-rtos" id="toc-kernels-in-rtos"><span
        class="toc-section-number">4.1</span> Kernels in RTOS</a>
        <ul>
        <li><a href="#tasks-jobs-threads"
        id="toc-tasks-jobs-threads"><span
        class="toc-section-number">4.1.1</span> Tasks, Jobs,
        Threads</a></li>
        <li><a href="#inter-task-communication-and-synchronization"
        id="toc-inter-task-communication-and-synchronization"><span
        class="toc-section-number">4.1.2</span> (Inter-Task)
        Communication and Synchronization</a></li>
        <li><a href="#memory-management"
        id="toc-memory-management"><span
        class="toc-section-number">4.1.3</span> Memory
        Management</a></li>
        <li><a href="#timer-and-interrupt-management"
        id="toc-timer-and-interrupt-management"><span
        class="toc-section-number">4.1.4</span> Timer and Interrupt
        Management</a></li>
        <li><a href="#kernel-performance-metrics"
        id="toc-kernel-performance-metrics"><span
        class="toc-section-number">4.1.5</span> Kernel Performance
        Metrics</a></li>
        </ul></li>
        <li><a href="#examples-of-rtos" id="toc-examples-of-rtos"><span
        class="toc-section-number">4.2</span> Examples of RTOS</a>
        <ul>
        <li><a href="#freertos" id="toc-freertos"><span
        class="toc-section-number">4.2.1</span> FreeRTOS</a></li>
        <li><a href="#linuxreal-time" id="toc-linuxreal-time"><span
        class="toc-section-number">4.2.2</span> Linux+Real-Time</a></li>
        <li><a href="#raspberry-pi-osreal-time"
        id="toc-raspberry-pi-osreal-time"><span
        class="toc-section-number">4.2.3</span> Raspberry Pi
        OS+Real-Time</a></li>
        </ul></li>
        <li><a href="#robot-operating-system-ros"
        id="toc-robot-operating-system-ros"><span
        class="toc-section-number">4.3</span> Robot Operating System
        (ROS)</a>
        <ul>
        <li><a href="#ros-components" id="toc-ros-components"><span
        class="toc-section-number">4.3.1</span> ROS Components</a></li>
        <li><a href="#ros-and-real-time"
        id="toc-ros-and-real-time"><span
        class="toc-section-number">4.3.2</span> ROS and
        Real-time?</a></li>
        <li><a href="#rosnavio2" id="toc-rosnavio2"><span
        class="toc-section-number">4.3.3</span> Ros+Navio2</a></li>
        </ul></li>
        </ul></li>
        <li><a href="#scheduling-for-real-time-systems"
        id="toc-scheduling-for-real-time-systems"><span
        class="toc-section-number">5</span> Scheduling for Real-Time
        Systems</a></li>
        <li><a href="#introduction-1" id="toc-introduction-1"><span
        class="toc-section-number">6</span> introduction</a>
        <ul>
        <li><a href="#autonomy-1" id="toc-autonomy-1"><span
        class="toc-section-number">6.1</span> autonomy</a>
        <ul>
        <li><a href="#what-are-the-aspects-of-autonomy-1"
        id="toc-what-are-the-aspects-of-autonomy-1"><span
        class="toc-section-number">6.1.1</span> what are the
        <em>aspects</em> of autonomy?</a></li>
        </ul></li>
        <li><a href="#let-us-define-autonomy-1"
        id="toc-let-us-define-autonomy-1"><span
        class="toc-section-number">6.2</span> let us define
        <strong>autonomy</strong></a></li>
        <li><a href="#autonomous-systems-1"
        id="toc-autonomous-systems-1"><span
        class="toc-section-number">6.3</span> autonomous
        systems</a></li>
        <li><a href="#sensors-and-actuators-1"
        id="toc-sensors-and-actuators-1"><span
        class="toc-section-number">6.4</span> sensors and
        actuators…</a></li>
        <li><a href="#sensing-and-actuation-in-the-real-world-1"
        id="toc-sensing-and-actuation-in-the-real-world-1"><span
        class="toc-section-number">6.5</span> sensing and actuation in
        the real world</a>
        <ul>
        <li><a href="#come-back-to-sensing-1"
        id="toc-come-back-to-sensing-1"><span
        class="toc-section-number">6.5.1</span> Come back to
        <strong>sensing</strong></a></li>
        </ul></li>
        <li><a href="#overviewarchitecture-of-autonomous-systems-1"
        id="toc-overviewarchitecture-of-autonomous-systems-1"><span
        class="toc-section-number">6.6</span> Overview/Architecture of
        Autonomous Systems</a>
        <ul>
        <li><a href="#high-order-functions-1"
        id="toc-high-order-functions-1"><span
        class="toc-section-number">6.6.1</span> high-order
        functions</a></li>
        <li><a href="#slam-1" id="toc-slam-1"><span
        class="toc-section-number">6.6.2</span> slam</a></li>
        <li><a href="#waypoint-detection-1"
        id="toc-waypoint-detection-1"><span
        class="toc-section-number">6.6.3</span> waypoint
        detection</a></li>
        <li><a href="#yolo-1" id="toc-yolo-1"><span
        class="toc-section-number">6.6.4</span> yolo</a></li>
        <li><a href="#object-avoidance-1"
        id="toc-object-avoidance-1"><span
        class="toc-section-number">6.6.5</span> object
        avoidance</a></li>
        <li><a href="#path-planning-1" id="toc-path-planning-1"><span
        class="toc-section-number">6.6.6</span> path planning</a></li>
        <li><a href="#compute-platform-1"
        id="toc-compute-platform-1"><span
        class="toc-section-number">6.6.7</span> compute
        platform</a></li>
        <li><a href="#still-some-non-functional-requirements-remain-1"
        id="toc-still-some-non-functional-requirements-remain-1"><span
        class="toc-section-number">6.6.8</span> still some
        <strong>non-functional</strong> requirements remain</a></li>
        <li><a href="#safety-1" id="toc-safety-1"><span
        class="toc-section-number">6.6.9</span> safety!</a></li>
        <li><a href="#security-1" id="toc-security-1"><span
        class="toc-section-number">6.6.10</span> security</a></li>
        <li><a href="#course-structure-1"
        id="toc-course-structure-1"><span
        class="toc-section-number">6.6.11</span> Course
        Structure</a></li>
        </ul></li>
        </ul></li>
        <li><a href="#embedded-architectures-1"
        id="toc-embedded-architectures-1"><span
        class="toc-section-number">7</span> Embedded Architectures</a>
        <ul>
        <li><a href="#the-wcet-problem-1"
        id="toc-the-wcet-problem-1"><span
        class="toc-section-number">7.1</span> The <strong>wcet</strong>
        problem</a></li>
        <li><a href="#embedded-processors-1"
        id="toc-embedded-processors-1"><span
        class="toc-section-number">7.2</span> Embedded Processors</a>
        <ul>
        <li><a href="#microcontrollers-1"
        id="toc-microcontrollers-1"><span
        class="toc-section-number">7.2.1</span>
        Microcontrollers</a></li>
        <li><a href="#digital-signal-processors-dsps-1"
        id="toc-digital-signal-processors-dsps-1"><span
        class="toc-section-number">7.2.2</span> Digital Signal
        Processors (DSPs)</a></li>
        <li><a href="#microprocessors-1"
        id="toc-microprocessors-1"><span
        class="toc-section-number">7.2.3</span> Microprocessors</a></li>
        <li><a href="#system-on-a-chip-soc-1"
        id="toc-system-on-a-chip-soc-1"><span
        class="toc-section-number">7.2.4</span> System-on-a-Chip
        (SoC)</a></li>
        <li><a href="#embedded-accelarators-e.g.-gpu-enabled-systems-1"
        id="toc-embedded-accelarators-e.g.-gpu-enabled-systems-1"><span
        class="toc-section-number">7.2.5</span> Embedded Accelarators
        (e.g. GPU-enabled systems)</a></li>
        <li><a href="#asics-and-fpgas-1"
        id="toc-asics-and-fpgas-1"><span
        class="toc-section-number">7.2.6</span> ASICs and FPGAs</a></li>
        </ul></li>
        <li><a href="#communication-and-io-1"
        id="toc-communication-and-io-1"><span
        class="toc-section-number">7.3</span> Communication and I/O</a>
        <ul>
        <li><a href="#uart-rs-232-1" id="toc-uart-rs-232-1"><span
        class="toc-section-number">7.3.1</span> UART | RS-232</a></li>
        <li><a href="#synchronous-i2c-and-spi-1"
        id="toc-synchronous-i2c-and-spi-1"><span
        class="toc-section-number">7.3.2</span> Synchronous |
        I<sup>2</sup>C and SPI</a></li>
        <li><a href="#general-purpose-io-gpio-1"
        id="toc-general-purpose-io-gpio-1"><span
        class="toc-section-number">7.3.3</span> General-Purpose I/O
        (GPIO)</a></li>
        <li><a href="#jtag-debugging-interface-1"
        id="toc-jtag-debugging-interface-1"><span
        class="toc-section-number">7.3.4</span> JTAG Debugging
        Interface</a></li>
        <li><a href="#controller-area-network-can-1"
        id="toc-controller-area-network-can-1"><span
        class="toc-section-number">7.3.5</span> Controller Area Network
        (CAN)</a></li>
        <li><a href="#other-broadly-used-protocols-1"
        id="toc-other-broadly-used-protocols-1"><span
        class="toc-section-number">7.3.6</span> Other Broadly Used
        Protocols</a></li>
        </ul></li>
        <li><a href="#raspberry-pi-and-navio2-1"
        id="toc-raspberry-pi-and-navio2-1"><span
        class="toc-section-number">7.4</span> Raspberry Pi and
        Navio2</a></li>
        <li><a href="#references-1" id="toc-references-1"><span
        class="toc-section-number">7.5</span> References</a></li>
        </ul></li>
        <li><a href="#sensors-and-sensing-1"
        id="toc-sensors-and-sensing-1"><span
        class="toc-section-number">8</span> Sensors and Sensing</a>
        <ul>
        <li><a href="#types-of-sensors-1"
        id="toc-types-of-sensors-1"><span
        class="toc-section-number">8.1</span> Types of Sensors</a>
        <ul>
        <li><a href="#inertial-measurement-units-imu-1"
        id="toc-inertial-measurement-units-imu-1"><span
        class="toc-section-number">8.1.1</span> Inertial Measurement
        Units (IMU)</a></li>
        <li><a
        href="#bouncing-of-electromagnetic-waves-lidar-and-mmwave-1"
        id="toc-bouncing-of-electromagnetic-waves-lidar-and-mmwave-1"><span
        class="toc-section-number">8.1.2</span> Bouncing of
        Electromagnetic Waves | LiDAR and mmWave</a></li>
        <li><a href="#ultrasonic-1" id="toc-ultrasonic-1"><span
        class="toc-section-number">8.1.3</span> Ultrasonic</a></li>
        </ul></li>
        <li><a href="#errors-in-sensing-1"
        id="toc-errors-in-sensing-1"><span
        class="toc-section-number">8.2</span> Errors in Sensing</a></li>
        <li><a href="#analog-to-digital-convertors-adcs-1"
        id="toc-analog-to-digital-convertors-adcs-1"><span
        class="toc-section-number">8.3</span> Analog to Digital
        Convertors (ADCs)</a>
        <ul>
        <li><a href="#adc-sampling-rate-1"
        id="toc-adc-sampling-rate-1"><span
        class="toc-section-number">8.3.1</span> ADC Sampling
        Rate</a></li>
        <li><a href="#adc-resolution-1" id="toc-adc-resolution-1"><span
        class="toc-section-number">8.3.2</span> ADC Resolution</a></li>
        </ul></li>
        </ul></li>
        <li><a href="#real-time-operating-systems-1"
        id="toc-real-time-operating-systems-1"><span
        class="toc-section-number">9</span> Real-Time Operating
        Systems</a>
        <ul>
        <li><a href="#key-characteristics-for-rtos-1"
        id="toc-key-characteristics-for-rtos-1"><span
        class="toc-section-number">9.0.1</span> Key characteristics for
        RTOS</a></li>
        <li><a href="#kernels-in-rtos-1"
        id="toc-kernels-in-rtos-1"><span
        class="toc-section-number">9.1</span> Kernels in RTOS</a>
        <ul>
        <li><a href="#tasks-jobs-threads-1"
        id="toc-tasks-jobs-threads-1"><span
        class="toc-section-number">9.1.1</span> Tasks, Jobs,
        Threads</a></li>
        <li><a href="#inter-task-communication-and-synchronization-1"
        id="toc-inter-task-communication-and-synchronization-1"><span
        class="toc-section-number">9.1.2</span> (Inter-Task)
        Communication and Synchronization</a></li>
        <li><a href="#memory-management-1"
        id="toc-memory-management-1"><span
        class="toc-section-number">9.1.3</span> Memory
        Management</a></li>
        <li><a href="#timer-and-interrupt-management-1"
        id="toc-timer-and-interrupt-management-1"><span
        class="toc-section-number">9.1.4</span> Timer and Interrupt
        Management</a></li>
        <li><a href="#kernel-performance-metrics-1"
        id="toc-kernel-performance-metrics-1"><span
        class="toc-section-number">9.1.5</span> Kernel Performance
        Metrics</a></li>
        </ul></li>
        <li><a href="#examples-of-rtos-1"
        id="toc-examples-of-rtos-1"><span
        class="toc-section-number">9.2</span> Examples of RTOS</a>
        <ul>
        <li><a href="#freertos-1" id="toc-freertos-1"><span
        class="toc-section-number">9.2.1</span> FreeRTOS</a></li>
        <li><a href="#linuxreal-time-1" id="toc-linuxreal-time-1"><span
        class="toc-section-number">9.2.2</span> Linux+Real-Time</a></li>
        <li><a href="#raspberry-pi-osreal-time-1"
        id="toc-raspberry-pi-osreal-time-1"><span
        class="toc-section-number">9.2.3</span> Raspberry Pi
        OS+Real-Time</a></li>
        </ul></li>
        <li><a href="#robot-operating-system-ros-1"
        id="toc-robot-operating-system-ros-1"><span
        class="toc-section-number">9.3</span> Robot Operating System
        (ROS)</a>
        <ul>
        <li><a href="#ros-components-1" id="toc-ros-components-1"><span
        class="toc-section-number">9.3.1</span> ROS Components</a></li>
        <li><a href="#ros-and-real-time-1"
        id="toc-ros-and-real-time-1"><span
        class="toc-section-number">9.3.2</span> ROS and
        Real-time?</a></li>
        <li><a href="#rosnavio2-1" id="toc-rosnavio2-1"><span
        class="toc-section-number">9.3.3</span> Ros+Navio2</a></li>
        </ul></li>
        </ul></li>
        <li><a href="#scheduling-for-real-time-systems-1"
        id="toc-scheduling-for-real-time-systems-1"><span
        class="toc-section-number">10</span> Scheduling for Real-Time
        Systems</a>
        <ul>
        <li><a href="#cyclic-executives"
        id="toc-cyclic-executives"><span
        class="toc-section-number">10.1</span> Cyclic Executives</a>
        <ul>
        <li><a href="#frames" id="toc-frames"><span
        class="toc-section-number">10.1.1</span> Frames</a></li>
        </ul></li>
        </ul></li>
        </ul>

        </div>
      </div>
            <div class="span9">
            <!--link rel="stylesheet" href="./custom.sibin.css"-->
            <section id="introduction" class="level1" data-number="1">
            <h1 data-number="1"><span
            class="header-section-number">1</span> introduction</h1>
            <section id="autonomy" class="level2" data-number="1.1">
            <h2 data-number="1.1"><span
            class="header-section-number">1.1</span> autonomy</h2>
            <p>what is “<em>autonomy</em>”?</p>
            <p>we see various examples of it…</p>
            <p><img src="img/philippine_uav.png" height="100" width = "200" style="display: inline-block; margin-right: 10px;">
            <img src="img/white_tesla.png" height="100" width = "200"  style="display: inline-block;"></p>
            <section id="what-are-the-aspects-of-autonomy"
            class="level3" data-number="1.1.1">
            <h3 data-number="1.1.1"><span
            class="header-section-number">1.1.1</span> what are the
            <em>aspects</em> of autonomy?</h3>
            <table>
            <colgroup>
            <col style="width: 13%" />
            <col style="width: 86%" />
            </colgroup>
            <tbody>
            <tr>
            <td><strong>perception</strong></td>
            <td>how do you “<em>see</em>” the world around you?</td>
            </tr>
            <tr>
            <td><strong>sensing</strong></td>
            <td>various ways to perceive the world around you
            (<em>e.g</em>, camera, LiDar)</td>
            </tr>
            <tr>
            <td><strong>compute</strong></td>
            <td>what do you “<em>do</em>” with the information about the
            world?</td>
            </tr>
            <tr>
            <td><strong>motion</strong></td>
            <td>do your computations result in any “<em>physical</em>”
            changes?</td>
            </tr>
            <tr>
            <td><strong>actuation</strong></td>
            <td>what “<em>actions</em>”, if any, do you take for said
            physical changes?</td>
            </tr>
            <tr>
            <td><strong>planning</strong></td>
            <td>can you do some “<em>higher order</em>” thinking <br>
            (<em>i.e.,</em> not just your immediate next move)</td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            <section id="let-us-define-autonomy" class="level2"
            data-number="1.2">
            <h2 data-number="1.2"><span
            class="header-section-number">1.2</span> let us define
            <strong>autonomy</strong></h2>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <tbody>
            <tr>
            <td>Autonomy is the ability to <br> <strong>perform given
            tasks</strong> <br> based on the systems perception <br>
            <scb>without</scb> human intervention</td>
            <td><img src="img/robot_profile_view.jpg" height="275"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="autonomous-systems" class="level2"
            data-number="1.3">
            <h2 data-number="1.3"><span
            class="header-section-number">1.3</span> autonomous
            systems</h2>
            <table>
            <colgroup>
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            </colgroup>
            <tbody>
            <tr>
            <td><strong>cyber</strong></td>
            <td><img src="img/cps_software.png" width="275"></td>
            <td><img src="img/cps_networking.png" height="275"></td>
            <td><img src="img/cps_ecus.png" height="275"></td>
            </tr>
            <tr>
            <td><strong>physical</strong></td>
            <td><img src="img/cps_sensors.png" height="275"></td>
            <td><img src="img/cps_actuators.png" height="275"></td>
            <td><img src="img/cps_plants.png" height="275"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>hence, they fall under the class of systems →
            <strong>cyber-physical</strong> systems</p>
            </section>
            <section id="sensors-and-actuators" class="level2"
            data-number="1.4">
            <h2 data-number="1.4"><span
            class="header-section-number">1.4</span> sensors and
            actuators…</h2>
            <table>
            <colgroup>
            <col style="width: 50%" />
            <col style="width: 50%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/cps_sensors.png" width="150" style="border: 2px solid purple; display: inline-block; padding: 10px; background-color:rgb(236, 219, 250);"></td>
            <td><img src="img/cps_actuators.png" width="125" style="border: 2px solid purple; display: inline-block; padding: 10px; background-color:rgb(236, 219, 250);"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>…are <strong>everywhere</strong>!</p>
            <p>the <strong>embedded</strong> components → interactions
            with the real world</p>
            </section>
            <section id="sensing-and-actuation-in-the-real-world"
            class="level2" data-number="1.5">
            <h2 data-number="1.5"><span
            class="header-section-number">1.5</span> sensing and
            actuation in the real world</h2>
            <p>consider the following example of two cars… <img
            src="img/cars_sensing/cars_sensing_1.png"
            alt="Two cars, one behind the over, top view" /></p>
            <p>the second car is approaching the first <img
            src="img/cars_sensing/cars_sensing_2.png"
            alt="Two cars, one behind the over, top view, an arror to the left on top of the car on the right" /></p>
            <p><strong>sensors</strong> → constantly gathering
            data/sensing</p>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/cars_sensing/cars_sensing_3.png" width="400"></p>
            </div>
            </div>
            <p>on detection (of other car) → quickly
            <strong>compute</strong> what to do</p>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            <li>
            computation
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/cars_sensing/cars_sensing_4.png" width="400"></p>
            </div>
            </div>
            <p>take <strong>physical action</strong> (actuation) → say
            by braking <em>in time</em></p>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            <li>
            computation
            </li>
            <li>
            actuation
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/cars_sensing/cars_sensing_5.png" width="400"></p>
            </div>
            </div>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            <li>
            computation
            </li>
            <li>
            actuation
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/sense_planning_actuation.png" width="400"></p>
            </div>
            </div>
            <p>“<strong>control</strong>”</p>
            <p>Remember this → on detection (of other car) →
            <scb>quickly</scb> <strong>compute</strong> what to do</p>
            <p><img src="img/cars_sensing/cars_sensing_4.png" width="400"></p>
            <p>“quickly” compute → complete computation/actuation →
            before a <strong>deadline</strong></p>
            <p>This is a <strong>real-time system</strong>.</p>
            <section id="come-back-to-sensing" class="level3"
            data-number="1.5.1">
            <h3 data-number="1.5.1"><span
            class="header-section-number">1.5.1</span> Come back to
            <strong>sensing</strong></h3>
            <!--div class="multicolumn">
            <div>
            <br>
            <ul>
                <li>we see <i>one</i> sensor (maybe LiDAR)</li>
                <li>reality &rarr; <b>multiple</b> sensors</li>
                <li>cameras, radars, lidar, etc.</li>
            <ul>
            </div>
            <div>
            <img src="img/autonomous_cars_sensors.png">
            </div>
            </div-->
            <p>Multiple sensors in an autonomous vehicle → need to
            <em>combine</em> them somehow</p>
            <p><strong>sensor fusion</strong></p>
            <p>Once we have information from the sensors (fused or
            otherwise)…</p>
            <p><img src="img/kalman_statistical_view.png" width="400"></p>
            <p>We need <strong>state estimation</strong>
            (<strong>kalman</strong> filter, <strong>ekf</strong>).</p>
            </section>
            </section>
            <section id="overviewarchitecture-of-autonomous-systems"
            class="level2" data-number="1.6">
            <h2 data-number="1.6"><span
            class="header-section-number">1.6</span>
            Overview/Architecture of Autonomous Systems</h2>
            <p>So far, we have (briefly) talked about…</p>
            <p>Sensing:</p>
            <p><img src="img/stack_architecture/stack_overview.2.png" width="200"></p>
            <p>Actuation:</p>
            <p><img src="img/stack_architecture/stack_overview.3.png" width="200"></p>
            <p>But the system includes…an <strong>operating
            system</strong> (OS) in there</p>
            <p><img src="img/stack_architecture/stack_overview.4.png" width="300"></p>
            <p>and it includes <strong>real-time</strong>
            mechanisms.</p>
            <p>We have briefly discussed, <strong>EKF</strong>:</p>
            <p><img src="img/stack_architecture/stack_overview.5.png" width="300"></p>
            <p><strong>note</strong>: ekf is versatile; can be used for
            sensor fusion, slam, etc.</p>
            <p>All of it integrates with…<strong>control</strong>:</p>
            <p><img src="img/stack_architecture/stack_overview.6.png" width="300"></p>
            <p>There are some <strong>real-time</strong> functions in
            there…</p>
            <p><img src="img/stack_architecture/stack_overview.7.png" width="300"></p>
            <p>like <em>braking</em>, <em>engine control</em>.</p>
            <p>Question: if we design such a system…</p>
            <p><img src="img/stack_architecture/stack_overview.7.png" width="300"></p>
            <p>is it “<strong>autonomous</strong>”?</p>
            <p>We are missing some “higher order” functionss from the
            perspective of the autonomous system:</p>
            <ul>
            <li><em>where</em> am I?</li>
            <li><em>where</em> do I need to go?</li>
            <li><em>how</em> do I get there?</li>
            <li><em>what</em> obstacles may I face?</li>
            <li><em>how</em> do I avoid them?</li>
            </ul>
            <p>let us not forget the most important question of all…</p>
            <p><img src="img/drax_gamora.avif" width="400"></p>
            <p><strong>why</strong> is gamora?</p>
            <section id="high-order-functions" class="level3"
            data-number="1.6.1">
            <h3 data-number="1.6.1"><span
            class="header-section-number">1.6.1</span> high-order
            functions</h3>
            <p>In order to answer the following, we need
            <strong>additional functionality</strong>. Let us go through
            what that might be.</p>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <tbody>
            <tr>
            <td></td>
            <td><img src="img/stack_architecture/stack_overview.7.png" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="slam" class="level3" data-number="1.6.2">
            <h3 data-number="1.6.2"><span
            class="header-section-number">1.6.2</span> slam</h3>
            <p>Simultaneous localization and mapping → figure out
            <strong>where</strong> we are.</p>
            <p><img src="img/stack_architecture/stack_overview.8.png" width="300"></p>
            </section>
            <section id="waypoint-detection" class="level3"
            data-number="1.6.3">
            <h3 data-number="1.6.3"><span
            class="header-section-number">1.6.3</span> waypoint
            detection</h3>
            <p>Understand how to move in the <em>right</em> direction at
            the <strong>micro</strong> level, <em>i.e.,</em> find
            <strong>waypoints</strong>.</p>
            <p><img src="img/stack_architecture/stack_overview.9.png" width="300"></p>
            </section>
            <section id="yolo" class="level3" data-number="1.6.4">
            <h3 data-number="1.6.4"><span
            class="header-section-number">1.6.4</span> yolo</h3>
            <p>Is it “you only live once”? Actually this stands for:
            “you only <strong>look</strong> once”. It is an object
            <strong>detection</strong> model that uses convolutional
            neural networks (cnns)</p>
            <p><img src="img/stack_architecture/stack_overview.10.png" width="300"></p>
            </section>
            <section id="object-avoidance" class="level3"
            data-number="1.6.5">
            <h3 data-number="1.6.5"><span
            class="header-section-number">1.6.5</span> object
            avoidance</h3>
            <p>The objective is to avoid objects in the
            <strong>immediate path</strong>.</p>
            <p><img src="img/stack_architecture/stack_overview.11.png" width="300"></p>
            </section>
            <section id="path-planning" class="level3"
            data-number="1.6.6">
            <h3 data-number="1.6.6"><span
            class="header-section-number">1.6.6</span> path
            planning</h3>
            <p>i.e., how to get to <strong>destination</strong> at the
            <strong>macro</strong> level → uses waypoints.</p>
            <p><img src="img/stack_architecture/stack_overview.12.png" width="300"></p>
            </section>
            <section id="compute-platform" class="level3"
            data-number="1.6.7">
            <h3 data-number="1.6.7"><span
            class="header-section-number">1.6.7</span> compute
            platform</h3>
            <p>To run all of these functions, we need low power,
            embedded platforms.</p>
            <p><img src="img/stack_architecture/stack_overview.13.png" width="300"></p>
            </section>
            <section id="still-some-non-functional-requirements-remain"
            class="level3" data-number="1.6.8">
            <h3 data-number="1.6.8"><span
            class="header-section-number">1.6.8</span> still some
            <strong>non-functional</strong> requirements remain</h3>
            <p>any guesses what they could be?</p>
            </section>
            <section id="safety" class="level3" data-number="1.6.9">
            <h3 data-number="1.6.9"><span
            class="header-section-number">1.6.9</span> safety!</h3>
            <p>Essentially safety of → operator, other people, the
            vehicle, environment This is <strong>cross-cutting</strong>
            issue → affected <scb>by</scb> <strong>all</strong> parts of
            system.</p>
            <p><img src="img/stack_architecture/stack_overview.14.png" width="300"></p>
            </section>
            <section id="security" class="level3" data-number="1.6.10">
            <h3 data-number="1.6.10"><span
            class="header-section-number">1.6.10</span> security</h3>
            <p>Security is another cross-cutting issue → <scb>can
            affect</scb> <strong>all</strong> components.</p>
            <p><img src="img/stack_architecture/stack_overview.png" width="300"></p>
            </section>
            <section id="course-structure" class="level3"
            data-number="1.6.11">
            <h3 data-number="1.6.11"><span
            class="header-section-number">1.6.11</span> Course
            Structure</h3>
            <p>Hence this figure is a (loose) map of this course:</p>
            <p><img src="img/stack_architecture/stack_overview.png" width="300">
            <!--link rel="stylesheet" href="./custom.sibin.css"--></p>
            </section>
            </section>
            </section>
            <section id="embedded-architectures" class="level1"
            data-number="2">
            <h1 data-number="2"><span
            class="header-section-number">2</span> Embedded
            Architectures</h1>
            <p>Just like “autonomy” describing and “embedded system” is
            hard. What (typically) distinguishes it from other types of
            computer systems (e.g., laptops, servers or GPUs even) is
            that such systems are typically created for
            <em>specific</em> functionality and often remain fixed and
            operational for years, decades even.</p>
            <p>Embedded systems often trade off between performance and
            other considerations such as power (or battery life), less
            memory, fewer peripherals, limited applications, smaller
            operating system (OS) and so on. There are numerous reasons
            for this – chief among them is <em>predictability</em> –
            designers need to guarantee that the system works correctly,
            and remains safe, all the time. Hence, it must be easy to
            <em>certify</em> <a href="#fn1" class="footnote-ref"
            id="fnref1" role="doc-noteref"><sup>1</sup></a> the
            <em>entire</em> system. This process ensures that the system
            operates <strong>safely</strong>.</p>
            <section id="the-wcet-problem" class="level2"
            data-number="2.1">
            <h2 data-number="2.1"><span
            class="header-section-number">2.1</span> The
            <strong>wcet</strong> problem</h2>
            <p>One piece of information that is required to ensure
            predictability and guarentee safety is <strong><a
            href="https://www.cs.fsu.edu/~whalley/papers/tecs07.pdf">worst-case
            execution time</a></strong> (WCET). The WCET/BCET is the
            <strong>longest</strong>/shortest execution time possible
            for a program, <strong>on a specific hardware
            platform</strong> – and it has to consider <em>all possible
            inputs</em>. WCET is necessary to ensure the
            “schedulability”, resource requirements and performance
            limits of embedded and real-time programs. There are lots of
            approaches to computing the WCET, <em>e.g.,</em></p>
            <ul>
            <li><a
            href="https://www.cs.fsu.edu/~whalley/papers/tecs07.pdf">dynamic/empirical</a>
            analysis → run the program lots of times (thousands,
            millions?) on the platform and measure it</li>
            <li><a
            href="https://www.cs.fsu.edu/~whalley/papers/tecs07.pdf">static</a>
            analysis → analyze the program at <em>compile time</em> to
            compute the <em>worst-case paths</em> through the
            program</li>
            <li><a
            href="https://sibin.github.io/papers/2008_NCSU-Dissertation_CheckerMode_SibinMohan.pdf">hybrid</a>
            → a combination of the two</li>
            <li><a
            href="https://people.ac.upc.edu/fcazorla/articles/jabella_ecrts2014_2.pdf">probabilistic</a>
            → a combination of dynamic analysis+statistical methods</li>
            <li><a
            href="https://dl.acm.org/doi/10.1145/3570361.3615740">ML-based
            methods</a> → applying machine-learning to the problem</li>
            </ul>
            <p>At a high-level, the execution time distributions of
            applications look like:</p>
            <p><img src="./img/embedded_arch/wcet_wilhelm.png" width="400" style="display: inline-block;" title="https://www.inf.ed.ac.uk/teaching/courses/es/PDFs/lecture_11.pdf" /></p>
            <p>WCET analysis is a very active area of research and
            hundreds of papers have been written about it, since it
            directly affects the safety of many critical systems
            (aircraft, power systems, nuclear reactors, space vehicles
            and…autonomous systems).</p>
            <p>There are structural challenges (both in software and
            hardware) that prevent the computation of <em>proper</em>
            wcet for anything but trivial examples. For instance,
            consider,</p>
            <div class="sourceCode" id="cb1"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> main<span class="op">()</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> max <span class="op">=</span> <span class="dv">10</span> <span class="op">;</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> max <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        sum <span class="op">+=</span> i <span class="op">;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>How do you compute the WCET for this code? Say running on
            some known processor, P?</p>
            <p>Well, there’s some information we need,</p>
            <ul>
            <li>how long each instruction takes to execute on P</li>
            <li>how many loop iterations?</li>
            <li>what is the startup/cleanup times for the program on
            P?</li>
            </ul>
            <p>Let’s assume (from the manual for P), we get the
            following information,</p>
            <div class="sourceCode" id="cb2"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>   <span class="dt">void</span> main<span class="op">()</span>         <span class="co">// startup cost = 100 cycles</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>   <span class="op">{</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>       <span class="dt">int</span> max <span class="op">=</span> <span class="dv">15</span> <span class="op">;</span>  <span class="co">// 10 cycles</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>       <span class="dt">int</span> sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>    <span class="co">// 10 cycles </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>       <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> max <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span> <span class="co">// 5 cycles, once</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>            sum <span class="op">+=</span> i <span class="op">;</span> <span class="co">// 20 cycles each iteration</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>   <span class="op">}</span>                   <span class="co">// cleanup cost = 120 cycles</span></span></code></pre></div>
            <p>So, based on this, we can calculate the total time to
            execute this program:</p>
            <p><span
            class="math display"><em>w</em><em>c</em><em>e</em><em>t</em> = <em>s</em><em>t</em><em>a</em><em>r</em><em>t</em><em>u</em><em>p</em>_<em>c</em><em>o</em><em>s</em><em>t</em> + <em>l</em><em>i</em><em>n</em><em>e</em>_3 + <em>l</em><em>i</em><em>n</em><em>e</em>_4 + <em>l</em><em>o</em><em>o</em><em>p</em>_<em>s</em><em>t</em><em>a</em><em>r</em><em>t</em><em>u</em><em>p</em>_<em>c</em><em>o</em><em>s</em><em>t</em> + (<em>l</em><em>i</em><em>n</em><em>e</em>_6 * <em>m</em><em>a</em><em>x</em>)  [1]</span></p>
            <p><span
            class="math display"><em>w</em><em>c</em><em>e</em><em>t</em> = 100 + 10 + 10 + 5 + (20 * 15)</span></p>
            <p><span
            class="math display"><em>w</em><em>c</em><em>e</em><em>t</em> = 425 <em>c</em><em>y</em><em>c</em><em>l</em><em>e</em><em>s</em></span></p>
            <p>Now consider this slight change to the above code:</p>
            <div class="sourceCode" id="cb3"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> main<span class="op">(</span> <span class="dt">int</span> argc<span class="op">,</span> <span class="dt">char</span><span class="op">*</span> argv<span class="op">[]</span> <span class="op">)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> max <span class="op">=</span> atoi<span class="op">(</span> argv<span class="op">[</span><span class="dv">1</span><span class="op">]</span> <span class="op">)</span> <span class="op">;</span>     <span class="co">// convert the command line arg to max</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> max <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span> <span class="co">// how many iterations?</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        sum <span class="op">+=</span> i <span class="op">;</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>The problem is that equation [1] above fails since we no
            longer know the value of <code>max</code>. Hence the
            <em>program can run for any arbitrary amount of time,
            depending on the given input!</em> Note that
            <strong>none</strong> of the aforemention wcet methods will
            help in this case since the input can be completely
            arbitrary. Hence, the structure of the software code can
            affect wcet calculations.</p>
            <p>Another problem is that of <strong>hardware</strong> (and
            interactions between hardware and software). Now consider if
            we modify the original code as,</p>
            <div class="sourceCode" id="cb4"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#define VERY_LARGE_ARRAY</span><span class="op">+</span><span class="pp">SIZE </span><span class="dv">1</span><span class="op">&gt;&gt;</span><span class="dv">18</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> main<span class="op">()</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> first_array<span class="op">[</span>VERY_LARGE_ARRAY_SIZE<span class="op">]</span> <span class="op">;</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> second_array<span class="op">[</span>VERY_LARGE_ARRAY_SIZE<span class="op">]</span> <span class="op">;</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum_first <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum_second <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> VERY_LARGE_ARRAY_SIZE <span class="op">*</span> <span class="dv">2</span> <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span><span class="op">(</span> i<span class="op">%</span><span class="dv">2</span> <span class="op">)</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>            first_sum <span class="op">+=</span> first_array<span class="op">[</span>i<span class="op">/</span><span class="dv">2</span><span class="op">]</span> <span class="op">;</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            second_sum <span class="op">+=</span> second_array<span class="op">[(</span><span class="dt">int</span><span class="op">)((</span>i<span class="op">/</span><span class="dv">2</span><span class="op">)+</span><span class="dv">1</span><span class="op">)]</span> <span class="op">;</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>Now, while we can compute, using equation [1] the wcet
            from the code perspective (since we know the loop runs for
            <code>VERY_LARGE_ARRAY_SIZE * 2</code> iterations), there
            will be significant non-obvious hardware issues, in the
            <strong>cache</strong>. Each iteration is accessing a
            <em>different</em> large array. Hence, it will load the
            cache with lines from that array and in the <em>very next
            iteration</em> the other array will be loaded, also missing
            in the cache. For instance,</p>
            <table>
            <colgroup>
            <col style="width: 14%" />
            <col style="width: 25%" />
            <col style="width: 17%" />
            <col style="width: 41%" />
            </colgroup>
            <thead>
            <tr>
            <th>iteration</th>
            <th>operation</th>
            <th>cache state</th>
            <th>reason</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>1</td>
            <td><code>first_array</code> loaded</td>
            <td>miss</td>
            <td>evicts whatever was previously in cache</td>
            </tr>
            <tr>
            <td>2</td>
            <td><code>second_array</code> loaded</td>
            <td>miss</td>
            <td><strong>evicts <code>first_array</code></strong> due to
            lack of space</td>
            </tr>
            <tr>
            <td>3</td>
            <td><code>first_array</code> loaded again</td>
            <td>miss</td>
            <td><strong>evicts <code>second_array</code></strong> due to
            lack of space</td>
            </tr>
            <tr>
            <td>…</td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, this program will <em>constantly</em> sufffer
            cache misses and since caches misses (and reloads) are
            expensive (in terms of time), the loop’s execution time will
            balloon out of control! Hence, even though we fixed the code
            issue (upper bound on number of iterations, hardware
            artifacts can change the wcet calculations). So now, we need
            to <em>model cache behavior</em> for each program and data
            variable! This is <a
            href="https://user.it.uu.se/~wangyi/pdf-files/2015/lgyrw-acm15.pdf">notoriously
            complicated</a> even for the simplest of programs.</p>
            <p>Other hardware designs further complicate matters,
            e.g.,</p>
            <ul>
            <li>processor pipelining</li>
            <li>prefetching</li>
            <li>branch prediction</li>
            <li>multithreading</li>
            <li>multicore systems</li>
            <li>memory buses</li>
            <li>networks-on-chip</li>
            <li>and too many others to recount here…</li>
            </ul>
            <p>Any contemporary processor design that improves
            performance, <em>turns out to be bad for wcet analysis</em>.
            So, the fewer (or simpler versions of) these features, the
            better it is for the (eventual) safety and certification of
            the system.</p>
            <p>This is one of the main reasons why embedded (and
            especially real-time) systems <strong>prefer simpler
            processors</strong> (simple pipelines, fewer complex
            features, simpler memory/cache architectures, if any) since
            they’re easier to analyze. In fact, many critical systems
            (e.g., aircraft, cars, etc.) <strong>use older
            processors</strong> (often designed in the 1980s and 1990s)
            – even the ones beind design today!</p>
            </section>
            <section id="embedded-processors" class="level2"
            data-number="2.2">
            <h2 data-number="2.2"><span
            class="header-section-number">2.2</span> Embedded
            Processors</h2>
            <p>Just as embedded systems are varied, embedded processors
            come in a myriad of shapes and sizes as well. From the very
            small and simple (e.g., DSPs) to the very large and complex
            (modern multicore chips, some with GPUs!). Here is a
            (non-exhaustive) list of the types of embedded
            processors/architectures in use today:</p>
            <ol type="1">
            <li><a href="#microcontrollers">Microcontrollers</a></li>
            <li><a href="#digital-signal-processors-dsps">Digital Signal
            Processors</a> (DSPs)</li>
            <li><a href="#microprocessors">Microprocessors</a> of
            various designs and architectures (e.g., ARM, x86)</li>
            <li><a href="#system-on-a-chip-soc">System-on-a-Chip</a>
            (SoC)</li>
            <li><a
            href="#embedded-accelarators-eg-gpu-enabled-systems">Embedded
            accelerators</a></li>
            <li><a href="#asics-and-fpgas">ASICs and FPGAs</a></li>
            </ol>
            <section id="microcontrollers" class="level3"
            data-number="2.2.1">
            <h3 data-number="2.2.1"><span
            class="header-section-number">2.2.1</span>
            Microcontrollers</h3>
            <p>According to <a
            href="https://en.wikipedia.org/wiki/Microcontroller">Wikipedia</a>,</p>
            <blockquote>
            <p>“A microcontroller (MC, UC, or μC) or microcontroller
            unit (MCU) is a small computer on a single integrated
            circuit.”</p>
            </blockquote>
            <p>These may be among the most common type of “processors”
            used in embedded systems. According to many studies,
            <strong><a
            href="https://www.embedded.com/the-two-percent-solution/">more
            than 55%</a></strong> of the world’s processors are
            microntrollers! Microcontrollers are typically used in
            small, yet critical, systems such as car engine control,
            implantable medical devices, thermal monitoring, <a
            href="https://sibin.github.io/papers/2021_BuildSys_PIRMedic_AshishKashinath.pdf">fault
            detection and classification</a> among millions of other
            applications.</p>
            <p>Microcontrollers hardware features typically include,</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 45%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>one (sometimes more) CPU cores</td>
            <td>typically simple <code>4</code> or <code>8</code> bit
            chips</td>
            </tr>
            <tr>
            <td>small pipelined architectues</td>
            <td>sometimes <code>2</code> or <code>4</code> stage
            pipelines</td>
            </tr>
            <tr>
            <td>some limited memory</td>
            <td>typically a few hundred kilobytes, perhaps in the form
            of EEPROMs or FLASH</td>
            </tr>
            <tr>
            <td>some programmable I/O</td>
            <td>to interact with the real world</td>
            </tr>
            <tr>
            <td>low operating frequencies</td>
            <td>e.g., <code>4 KHz</code>; simpler/older processors, yet
            more predictable</td>
            </tr>
            <tr>
            <td>low power consumption</td>
            <td>in the <strong>milliwatts</strong> or
            <strong>microwatts</strong> ranges; might even be
            <strong>nanowatts</strong> when the system is
            <em>sleeping</em></td>
            </tr>
            <tr>
            <td>interrupts (some programmable)</td>
            <td>often <em>real-time</em> (ficed/low latency)</td>
            </tr>
            <tr>
            <td>several general-purpose I/O (GPIO) pins</td>
            <td>for I/O</td>
            </tr>
            <tr>
            <td>timers</td>
            <td>e.g., a programmable interval timer (PIT)</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>There are some <strong>additional features</strong> found
            on some microcontrollers, viz.,</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 45%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>analog to digital (ADC) signal convertors</td>
            <td>to convert incoming (real-world, sensor) data to a
            digital form that the uC can operate on</td>
            </tr>
            <tr>
            <td>digital-to-analog (DAC) convertor</td>
            <td>to do the opposite, convert from digital to analog
            signals to send outputs in that form</td>
            </tr>
            <tr>
            <td>universal asynchronous transmitter/receiver (UART)</td>
            <td>to receive/send data over a <em>serial</em> line</td>
            </tr>
            <tr>
            <td>pulse width modulation (PWM)</td>
            <td>so that the CPU can control <strong>motors</strong>
            (significant for us in autonomous/automotive systems), power
            systems, resistive loads, etc.</td>
            </tr>
            <tr>
            <td>JTAG interace</td>
            <td>debugging interface</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Some examples of popular microcontroller families:</p>
            <table>
            <colgroup>
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="./img/embedded_arch/ATmega169-MLF.jpg" height="100"><br>Atmel
            ATmega</td>
            <td><img src="./img/embedded_arch/Microchip_PIC24HJ32GP202.jpg" height="100">
            <br> Microchip Technology</td>
            <td><img src="./img/embedded_arch/Motorola_68HC11.jpg" height="100">
            <br> Motorola (Freescale)</td>
            <td><img src="./img/embedded_arch/NXP_LPC2387FBD100-5543.jpg" height="100">
            <br> NXP</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Microcontroller programs and data,</p>
            <ul>
            <li>are small –&gt; must fit in memory (since very little
            expandable memory exists)</li>
            <li>often directly programmed in <strong>assembly</strong>!
            <ul>
            <li>sometimes the assembly code might need <em>hand
            tuning</em> –&gt; for both, performance as well as fitting
            into the limited memory</li>
            </ul></li>
            <li><strong>C</strong> is another popular language</li>
            <li><strong>no operating systems</strong> (or very
            rare)!</li>
            <li>sometimes have their own special-purpose programming
            languages or instructions</li>
            </ul>
            </section>
            <section id="digital-signal-processors-dsps" class="level3"
            data-number="2.2.2">
            <h3 data-number="2.2.2"><span
            class="header-section-number">2.2.2</span> Digital Signal
            Processors (DSPs)</h3>
            <p>DSPs are specialized microcontrollers optimized for
            <em>digital signal processing</em>. They find wide use in
            audio processing, radar and sonar, speech recognition
            systems, image processing, satellites, telecommunications,
            mobile phones, televisions, etc. Their main goals are to
            isoloate, measure, compress and filter <em>analog</em>
            signals in the real world. They often have <strong>stringent
            real-time constraints</strong>.</p>
            <p>The Texas Instruments DSP chip, <a
            href="https://www.ti.com/lit/ug/spruh79c/spruh79c.pdf?ts=1736945981001">TMS320
            Series</a> is one of the most famous example of this type of
            system:</p>
            <p><img src="./img/embedded_arch/TI_DSP.jpg" height="100" title="Texas Instruments DSP Chip"></p>
            <p>Typical digital signal processing (of any kind) requires
            repetitive mathematical operations over a large number of
            samples, in real-time, viz., - analog to digital conversion
            - maniupulation (the core algorithm) - digital to analog
            conversion</p>
            <p>Often, the <em>entire</em> process must be completed with
            low latency, even within a fixed deadline. They also have
            <strong>low power</strong> requirements since DSPs are often
            used in battery-constrained devices such as mobile phones.
            Hence, the proliferation of specialized DSP chips (instead
            of pure <a href="https://liquidsdr.org">software
            implementations</a>, which also exist; MATLAB has an entire
            <a href="https://www.mathworks.com/help/dsp/index.html">DSP
            System Toolbox</a>).</p>
            <p><strong>Typical DSP architecture</strong>/flow (credit:
            <a
            href="https://en.wikipedia.org/wiki/Digital_signal_processor">Wikipedia</a>):</p>
            <p><img src="./img/embedded_arch/dsp_architecture.png" height="100" title="https://en.wikipedia.org/wiki/Digital_signal_processor"></p>
            <p>These types of chips typically have custom instructions
            for optimizing certain (mathematical) operations (apart from
            the typical <code>add</code>, <code>subtract</code>,
            <code>multiply</code> and <code>divide</code>), e.g., -
            <code>saturate</code>; caps the minimum or maximum value
            that can be held in a fixed-point representation -
            <code>ed</code> ; euclidian distance -
            <code>accumulate</code> instructions ; for <a
            href="https://skills.microchip.com/dsp-features-of-the-microchip-dspic-dsc/693207"><em>multiply-and-accumulate</em></a>
            operations, i.e., <span
            class="math inline"><em>a</em> ← <em>a</em> + (<em>b</em> * <em>c</em>)</span></p>
            <blockquote>
            <p>See the <a
            href="https://ww1.microchip.com/downloads/en/DeviceDoc/sect2.pdf">Microchip
            instruction set</a> details for more information for a
            typical DSP ISA.</p>
            </blockquote>
            <p>DSPs require <em>optimization of streaming data</em> and
            hence, - require <strong>optimized memories and
            caches</strong> → fetch multiple data elements at the same
            time - code may need to be aware of, and
            <strong>explicitly</strong> manipulate caches - may have
            rudimentary OS but <strong>no virtual memory</strong></p>
            </section>
            <section id="microprocessors" class="level3"
            data-number="2.2.3">
            <h3 data-number="2.2.3"><span
            class="header-section-number">2.2.3</span>
            Microprocessors</h3>
            <p>Microprocessors are, then,
            <strong>general-purpose</strong> chips (as opposed to
            microcontrollers and DSPs) that are also used extensively in
            embedded systems. They are used in systems that need more
            heavy duty computing/memory and/or more flexibility in terms
            of programming and management of the system. They use a
            number of commodity processor architectures (e.g,, ARM,
            Intel x86).</p>
            <p>Main features of microprocessors:</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 45%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>cores</td>
            <td>single or multicore; powerful</td>
            </tr>
            <tr>
            <td>pipelines</td>
            <td>more complex pipelines; better performance, harder to
            analyze (e.g., wcet)</td>
            </tr>
            <tr>
            <td>clock speeds</td>
            <td>higher clock speeds; <code>100s</code> of khz, or even
            GHz</td>
            </tr>
            <tr>
            <td>ISA</td>
            <td>common ISA; well understood, not custom</td>
            </tr>
            <tr>
            <td>memory</td>
            <td>significant memory; megabytes, even gigabytes</td>
            </tr>
            <tr>
            <td>cache hierarchies</td>
            <td>multiple levels, optimized</td>
            </tr>
            <tr>
            <td>power consumption</td>
            <td>much higher, but can be reduced (e.g., via <a
            href="https://developer.arm.com/documentation/ddi0375/a/functional-overview/intelligent-energy-management--iem-/dynamic-voltage-scaling--dvs-">voltage
            and frequency scaling</a>)</td>
            </tr>
            <tr>
            <td>size, cost</td>
            <td>often higher</td>
            </tr>
            <tr>
            <td>interrupts, timers</td>
            <td>more varied, easily programmable</td>
            </tr>
            <tr>
            <td>I/O</td>
            <td>more interfaces, including commodity ones like USB</td>
            </tr>
            <tr>
            <td>security</td>
            <td>often includes additional hardware security features,
            e.g., <a
            href="https://sefcom.asu.edu/publications/trustzone-explained-cic2016.pdf">ARM
            TrustZone</a>.</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The <a
            href="https://armkeil.blob.core.windows.net/developer/Files/pdf/product-brief/arm-cortex-m85-product-brief.pdf">ARM
            M-85</a> Embedded Microprocessor architecture:</p>
            <p><img src="./img/embedded_arch/arm_cortex_m85.png" width="300" title="Arm M-85"></p>
            <p>When compared to microcontrollers (or even SoCs), most
            microprpcessors <strong>do not</strong> include components
            such as DSPs, ADCs, DACs, etc. It is possible to
            <em>augment</em> the microprocessor to include this
            functionality → usually by <em>connecting one or more
            microcontrollers to it</em>!</p>
            <p>On the software side, microprocessors typically have the
            <strong>most flexibility</strong>:</p>
            <ul>
            <li>general purpose operating systems (e.g., Linux, Android,
            Windows, UNIX, etc.)</li>
            <li>most programming languages and infrastructures (even <a
            href="https://www.docker.com/blog/getting-started-with-docker-for-arm-on-linux/">Docker</a>!)</li>
            <li>large number of tooling, analysis, debugging
            capabilities</li>
            <li>complex code can run, but <strong>increases analysis
            difficulty</strong></li>
            </ul>
            <p>Due to their power (and cost) these types of systems are
            only used when really necessary or in higher-end systems
            such as mobile phones and autonomous cars.</p>
            </section>
            <section id="system-on-a-chip-soc" class="level3"
            data-number="2.2.4">
            <h3 data-number="2.2.4"><span
            class="header-section-number">2.2.4</span> System-on-a-Chip
            (SoC)</h3>
            <p>An SoC <strong>integrates</strong> most components in and
            around a processor into a <strong>single</strong> circuit,
            viz.,</p>
            <ul>
            <li>processor/chip → could be a microcontroller or even a
            microprocessor</li>
            <li>memory and memory interfaces</li>
            <li>I/O devices</li>
            <li>buses (memory and I/O)</li>
            <li>storage (e.g., flash) and sometimes even secondary
            storage</li>
            <li>radio modems</li>
            <li>(sometimes) accelerators such as GPUs</li>
            </ul>
            <p>All of these are placed on a <strong>single
            substrate</strong>.</p>
            <p>SoCs are often designed in <code>C++</code>,
            <code>MATLAB</code>, <code>SystemC</code>, etc. Once the
            hardware architectures are defined, additional hardware
            elements are written in hardware description languages,
            e.g., register transfer levels (<code>RTL</code>) <a
            href="#fn2" class="footnote-ref" id="fnref2"
            role="doc-noteref"><sup>2</sup></a>.</p>
            <p>Additional components could include,</p>
            <ul>
            <li>DAC</li>
            <li>ADC</li>
            <li>radio and signal processing</li>
            <li>wireless modems</li>
            <li><a
            href="https://www.amd.com/en/products/adaptive-socs-and-fpgas/soc/zynq-7000.html"><em>programmable
            logic</em></a>.</li>
            <li>networks on chip (NoC) <a href="#fn3"
            class="footnote-ref" id="fnref3"
            role="doc-noteref"><sup>3</sup></a></li>
            </ul>
            <p>In some sense, an SoC is an <em>integration of a
            processor with peripherals</em>. New hardware elements</p>
            <p>Some examples of modern SoCs:</p>
            <div class="multicolumn">
            <div>
            <p><img src="./img/embedded_arch/broadcom_pi_chip.png" width="200" title="Broadcom SoC chip used in the Raspberry Pi"></p>
            <p>Broadcom Soc from Raspberry Pi</p>
            </div>
            <div>
            <p><img src="./img/embedded_arch/Apple_M1.jpg" width="200" title="Apple M1 SoC"></p>
            <p>Apple M1 SoC</p>
            </div>
            </div>
            <p>The integration of all hardware components has some
            interesting side-effects:</p>
            <table>
            <colgroup>
            <col style="width: 34%" />
            <col style="width: 31%" />
            <col style="width: 34%" />
            </colgroup>
            <thead>
            <tr>
            <th>effect</th>
            <th>benefit</th>
            <th>problems</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>tight integration</td>
            <td>better performance, fewer latencies</td>
            <td>cannot replace individual components</td>
            </tr>
            <tr>
            <td>custom code/firmware</td>
            <td>better use of hardware</td>
            <td>not reusable in other systems</td>
            </tr>
            <tr>
            <td>custom software libraries</td>
            <td>easier programming of SoC</td>
            <td>reduces code reusability in other systems</td>
            </tr>
            <tr>
            <td>low power consumption</td>
            <td>better battery life, less heat</td>
            <td>(potentially) slower</td>
            </tr>
            </tbody>
            </table>
            <p>Depending on the processor/microcontroller that sits at
            the center of the SoC, the software stack/capabilities can
            vary. Many commons SoCs exhibit the following software
            properties:</p>
            <ul>
            <li>usually use contemporary operating systems, though
            optimized for embedded/SoC systems → e.g., <a
            href="http://www.raspbian.org">Raspbian</a> aka Rasberry Pi
            OS. Hence, they can handle multiprocessing, virtual memory,
            different scheduling policies, etc.</li>
            <li>can be programmed using most common programming
            languages → <code>C</code>, <code>C++</code>,
            <code>python</code>, <code>java</code>, even <a
            href="https://medium.com/@kenichisasagawa/rediscovering-the-joy-of-hardware-hacking-with-raspberry-pi-and-lisp-574c833ab20e"><code>lisp</code></a>!</li>
            </ul>
            <p>The Raspberry Pi is a common example of a system that
            uses a <a
            href="https://www.raspberrypi.com/documentation/computers/processors.html">Broadcom
            BCM series of SoCs</a>. We use the <a
            href="https://www.raspberrypi.com/documentation/computers/processors.html#bcm2711">BCM2711</a>
            SoC in our course for the Raspberry Pi 4-B.</p>
            </section>
            <section id="embedded-accelarators-e.g.-gpu-enabled-systems"
            class="level3" data-number="2.2.5">
            <h3 data-number="2.2.5"><span
            class="header-section-number">2.2.5</span> Embedded
            Accelarators (e.g. GPU-enabled systems)</h3>
            <p>There are hardware platforms that include
            <strong>accelerators</strong> in embedded systems, e.g., <a
            href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">GPUs</a>,
            <a
            href="https://www.nature.com/articles/s41928-022-00778-y">AI-enabled
            silicon</a>, <a
            href="https://www.amd.com/en/products/adaptive-socs-and-fpgas/soc/zynq-7000.html">extra
            programmable FPGA fabric</a>, <a
            href="https://developer.arm.com/documentation/100230/0002/functional-description/external-coprocessors/configuring-which-coprocessors-are-included-in-secure-and-non-secure-states">security
            features</a>, etc. The main idea is that certain computation
            can be <em>offloaded</em> to these accelerators while the
            main CPU continues to process other code/requests. The
            accelerators are specialized for certain computations (e.g.,
            parallel matrix multiplications on GPUs, AES encryption).
            Some chips include FPGA fabric where the designer/user can
            <em>implement their own custom logic/accelerators</em>.</p>
            <p>In a loose sense, the <a
            href="https://navio2.hipi.io">Navio2</a> can be considered
            as a hardware coprocessor for the Raspbery Pi.</p>
            <p>The <a
            href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVidia
            Jetson Orin</a> is a good example of an AI/GPU focussed
            embedded processor:</p>
            <p><img src="./img/embedded_arch/jetson-agx-orin-4c25-d-2x.png" width="300" title="NVIDIA Jetson AGX Orin 64 GB"></p>
            <p><br></p>
            <p>This system’s <a
            href="https://www.techpowerup.com/gpu-specs/jetson-agx-orin-64-gb.c4085">specifications</a>:</p>
            <ul>
            <li>1300 MHz clock speeds</li>
            <li>64 GB Memory</li>
            <li>256 bit memory bus</li>
            <li>204 GB/s bandwidth</li>
            <li>supports a variety of graphics features (DirectX,
            OpenGL, OpenCL, CUDA, Vulkan and Shader Models )</li>
            <li>maximum of 60W power</li>
            <li><strong>275 trillion</strong> operations/s (TOPS)!</li>
            </ul>
            <p>These systems are finding a lot of use in autonomous
            systems since they pack so much processing power into such a
            small form factor</p>
            </section>
            <section id="asics-and-fpgas" class="level3"
            data-number="2.2.6">
            <h3 data-number="2.2.6"><span
            class="header-section-number">2.2.6</span> ASICs and
            FPGAs</h3>
            <p>Application-specific integrated circuits (ASICs) and
            field programmable gate arrays (FPGAs). These platforms
            combine the advantages of both, hardware (<em>speed</em>)
            and software (<em>flexibility/programmability</em>). They
            are similar, yet different. Both are semiconductor devices
            that include <strong>programmable logic gates</strong> but
            an ASIC is <em>static</em> – i.e., once the board has been
            “programmed” it cannot be changed while an FPGA, as the name
            implies, allows for “reprogramming”.</p>
            <p>ASICs are <strong>custom-designed</strong> for specific
            applications and provide high efficiency and performance.
            FPGAs are <strong>reprogramamble</strong> devices that
            provide significant flexibility. Many designers also used it
            for prototyping hardware components (before they are
            eventually included either in the processors or custom
            ASICs). The <a
            href="https://www.wevolver.com/article/asic-vs-fpga">choice
            between ASICs and FPGAs</a> depends entirely on the
            application requirements and other factors such as cost.</p>
            <table>
            <colgroup>
            <col style="width: 50%" />
            <col style="width: 50%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="./img/embedded_arch/asic.webp" width="200"></td>
            <td><img src="./img/embedded_arch/xilinx_spartan_fpga.webp" width="200"></td>
            </tr>
            <tr>
            <td>An ASIC</td>
            <td>Xilinx Spartan FPGA</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <section id="asics" class="level4" data-number="2.2.6.1">
            <h4 data-number="2.2.6.1"><span
            class="header-section-number">2.2.6.1</span> ASICs</h4>
            <p>These are specialized semiconductor devices – to
            implement a <em>custom</em> function, e.g., cryptocurrency
            mining, nuclear reactor control, televisions. ASICs are
            tailored to their specific applications. Once created, it
            cannot be reprogrammed or modified. ASICs are created using
            a process known as <a
            href="https://www.sciencedirect.com/topics/physics-and-astronomy/photolithography">photolithography</a>,
            a method to prepare nanoparticles, that allows components to
            be “etched” on to a silicon wafer.</p>
            <p>The <a
            href="https://www.wevolver.com/article/the-ultimate-guide-to-asic-design-from-concept-to-production">ASIC
            design process</a>, while expensive and time consuming,
            becomes valuable for <em>high-volume</em> products as the
            per-unit cost decrease when production nunbers increase.</p>
            <table>
            <thead>
            <tr>
            <th>advantages</th>
            <th>disadvantages</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>high performance</td>
            <td>lack of flexibility</td>
            </tr>
            <tr>
            <td>low power consumption</td>
            <td>high initial costs</td>
            </tr>
            <tr>
            <td>small form factor</td>
            <td>long development time</td>
            </tr>
            <tr>
            <td>ip protection</td>
            <td>obsolescence risk</td>
            </tr>
            <tr>
            <td>good for mass production</td>
            <td>risks with manufacturing yields</td>
            </tr>
            <tr>
            <td>can integrate multiple functions</td>
            <td>design complexity</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="fpgas" class="level4" data-number="2.2.6.2">
            <h4 data-number="2.2.6.2"><span
            class="header-section-number">2.2.6.2</span> FPGAs</h4>
            <p>These are also semiconductor devices but they can be
            <strong>preprogrammed</strong> to implement various circuits
            and functions. Designers can change the functionality
            <strong>after</strong> the curcuits have been embossed onto
            the hardware. Hence, they’re good for systems that might
            require changes at design time and rapid prototyping. An
            FPGA is a collection of programmable logic and
            interconnects. They include lookup tables (LUTs) and other
            parts that can be used to develop multiple, fairly
            wide-ranging, functions. The programmable blocks can be
            connected to each other via the interconnects. Some FPGAs
            even come with additional flash memory.</p>
            <p><a href="https://www.wevolver.com/article/fpga">FPGAs are
            programmed</a> using hardware description languages such as
            Verilog/VHDL.</p>
            <table>
            <thead>
            <tr>
            <th>advantages</th>
            <th>disadvantages</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>flexibility</td>
            <td>lower performance</td>
            </tr>
            <tr>
            <td>shorter development time</td>
            <td>higher power consumption</td>
            </tr>
            <tr>
            <td>upgradability</td>
            <td>high design complexity</td>
            </tr>
            <tr>
            <td>lower (initial) costs</td>
            <td>higher per-unit costs</td>
            </tr>
            <tr>
            <td>better processing capabilities</td>
            <td>design complexity</td>
            </tr>
            <tr>
            <td>lower obsolescence risks</td>
            <td>larger form factor</td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            </section>
            <section id="communication-and-io" class="level2"
            data-number="2.3">
            <h2 data-number="2.3"><span
            class="header-section-number">2.3</span> Communication and
            I/O</h2>
            <p>Embedded systems need to <strong>communicate</strong>
            and/or <strong>interface</strong> with various elements:</p>
            <ul>
            <li>the physical world via sensors and actuators</li>
            <li>computers for programming (of the embedded system) or
            for data transfer</li>
            <li>with other embedded systems/nodes</li>
            <li>handheld devices</li>
            <li>with the internet (either public or to access back end
            servers)</li>
            <li>satellites?</li>
            </ul>
            <p>Hence a large number of communication standards and I/O
            interfaces have been developed over the years. Let’s look at
            a few of them:</p>
            <ol type="1">
            <li><a href="#uart--rs-232">serial (UART)</a> → e.g., RS
            232</li>
            <li><a href="#synchronous--i2c-and-spi">synchronous</a> →
            I2C, SPI</li>
            <li><a href="#general-purpose-io-gpio">general-purpose
            I/O</a> → GPIO</li>
            <li><a href="#jtag-debugging-interface">debugging
            interface</a> → JTAG</li>
            <li><a href="#controller-area-network-can">embedded internal
            communication</a> → CAN</li>
            <li><a href="#other-broadly-used-protocols">other broadly
            used protocols</a> → USB, Ethernet/WiFi, Radio,
            Bluetooth</li>
            </ol>
            <section id="uart-rs-232" class="level3"
            data-number="2.3.1">
            <h3 data-number="2.3.1"><span
            class="header-section-number">2.3.1</span> UART |
            RS-232</h3>
            <p>Serial communication standards are used extensively
            across many domains, mainly due to their
            <strong>simplicity</strong> and <strong>low hardware
            overheads</strong>. The most common among these are the
            <em>asynchronous serial communication systems</em>.</p>
            <p>From <a
            href="https://en.wikipedia.org/wiki/Asynchronous_serial_communication">Wikipedia</a>:</p>
            <blockquote>
            <p>Asynchronous serial communication is a form of serial
            communication in which the communicating endpoints’
            interfaces are not continuously synchronized by a common
            clock signal. Instead of a common synchronization signal,
            the data stream contains synchronization information in form
            of start and stop signals, before and after each unit of
            transmission, respectively. The start signal prepares the
            receiver for arrival of data and the stop signal resets its
            state to enable triggering of a new sequence.</p>
            </blockquote>
            <p>The following figure shows a communication sample that
            demonstrates these principles:</p>
            <p><img src="img/embedded_arch/comms/Puerto_serie_Rs232.png" width="300"></p>
            <p>We see that each byte has a <code>start</code> bit,
            <code>stop</code> bit and eight <code>data</code> bits. The
            last bit is often used as a <code>parity</code> bit. All of
            these “standards” (i.e., the start/stop/parity bits) must be
            <em>agreed upon ahead of time</em>.</p>
            <p>A <strong>universal asynchronous
            receiver-transmitter</strong> (<strong>UART</strong>) then
            is a peripheral device for such asynchronous commnication;
            the data format and transmission speeds are configurable. It
            sends data bits <em>one-by-one</em> (from least significant
            to most). The precise timing is handlded by the
            communication channel.</p>
            <p>The electric <em>signalling levels</em> are handled by an
            external driver circuit. Common signal levels:</p>
            <ul>
            <li><a
            href="https://www.analog.com/en/resources/technical-articles/fundamentals-of-rs232-serial-communications.html">RS
            232</a></li>
            <li><a
            href="https://www.renkeer.com/what-is-rs485/">RS-485</a></li>
            <li>raw <a
            href="https://www.seeedstudio.com/blog/2019/12/11/rs232-vs-ttl-beginner-guide-to-serial-communication">TTL</a></li>
            </ul>
            <p>Here we will focus on the <strong>RS-232</strong>
            standard since it is most widely used UART signaling level
            standard today. The full name of the standard is:
            “EIA/TIA-232-E Interface Between Data Terminal Equipment and
            Data Circuit-Termination Equipment Employing Serial Binary
            Data Interchange” (“EIA/TIA” stands for the Electronic
            Industry Association and the Telecommunications Industry
            Association). It was introduced in 1962 and has since been
            updated <em>four</em> times to meet evolving needs.</p>
            <p>The RS-232 is a <em>complete</em> standard in that it
            specifies,</p>
            <ul>
            <li>(common) voltage and signal levels</li>
            <li>(common) pin and wiring configurations</li>
            <li>(minimal) control information between
            host/peripherals</li>
            </ul>
            <p>The RS-232 specifies the electrical, functional and
            mechanical characteristics to meet all of the above
            criteria.</p>
            <p>For instance, the <em>electrical</em> characteristics are
            defined in the following figure:</p>
            <p><img src="img/embedded_arch/comms/rs232-electrical.gif" width="400"></p>
            <p>Details:</p>
            <ul>
            <li><strong>high</strong> level [<strong>logical
            <code>0</code></strong>] (aka “marking”) → <code>+5V</code>
            to <code>+15V</code> (realistically <code>+3V</code> to
            <code>+15V</code>)</li>
            <li><strong>low</strong> level [<strong>logical
            <code>1</code></strong>] (aka “spacing”) → <code>-5V</code>
            to <code>-15V</code> (realistically <code>-3V</code> to
            <code>-15V</code>)</li>
            </ul>
            <p>Other properties also defined, <em>e.g.</em>, “<a
            href="https://en.wikipedia.org/wiki/Slew_rate">slew
            rate</a>”, impedance, capacitive loads, etc.</p>
            <p>The standard also defines the mechanical interfaces,
            i.e., the <em>pin connector</em>:</p>
            <p><img src="img/embedded_arch/comms/rs232_pins.gif" width="400"></p>
            <p>While the official standard calls for a 25-pin connector,
            it is rarely used. Instead, the <strong>9-pin</strong>
            connector (shown on the right in the above figure) is in
            common use.</p>
            <p>You can read more details about the standard here: <a
            href="https://www.analog.com/en/resources/technical-articles/fundamentals-of-rs232-serial-communications.html">RS
            232</a></p>
            </section>
            <section id="synchronous-i2c-and-spi" class="level3"
            data-number="2.3.2">
            <h3 data-number="2.3.2"><span
            class="header-section-number">2.3.2</span> Synchronous |
            I<sup>2</sup>C and SPI</h3>
            <p>Synchronous Serial Interfaces (SSIs) are a widely used in
            industrial applications between a master device
            (e.g. controller) and a slave device (e.g. sensor). It is
            based on the <a
            href="https://www.analog.com/media/en/technical-documentation/tech-articles/guide-to-selecting-and-using-rs232-rs422-and-rs485-serial-data-standards--maxim-integrated.pdf">RS-422</a>
            standards and has a high protocol efficiency as well
            multiple hardware implementations.</p>
            <p>SSI properties:</p>
            <ul>
            <li><a
            href="https://en.wikipedia.org/wiki/Differential_signalling">differential
            signalling</a></li>
            <li>simplex (i.e., unidirectional communication only)</li>
            <li>non-multiplexed</li>
            <li>point-to-point and</li>
            <li>uses time-outs to frame the data.</li>
            </ul>
            <section id="i2c" class="level4" data-number="2.3.2.1">
            <h4 data-number="2.3.2.1"><span
            class="header-section-number">2.3.2.1</span>
            I<sup>2</sup>C</h4>
            <p>The <a
            href="https://www.ti.com/lit/an/sbaa565/sbaa565.pdf">Inter-Integrated
            Circuit</a> (I<sup>2</sup>C, IIC, I2C) is a synchronous,
            multi-controller/multi-target (historically termed as
            multi-master/multi-slave), single-ended, serial
            communication bus. I2C systems are used for <em>attaching
            low-power integrated circuits to processors and
            microcontrollers</em> – usually for short distance or
            <em>intra-board communication</em>.</p>
            <p>I2C components are found in a wide variety of products,
            <em>e.g.,</em></p>
            <ul>
            <li>EEPROMs</li>
            <li>VGA/DVI/HDMI connectors</li>
            <li>NVRAM chips</li>
            <li>real-time clocks</li>
            <li>reading hardware monitors and sensors</li>
            <li>controlling actuators</li>
            <li>DAC/ADC</li>
            <li>controlling LCD/OLEDs displays</li>
            <li>changing computer display settings (contrast,
            brightness, etc.)</li>
            <li>controlling speaker volume</li>
            <li>and many many more</li>
            </ul>
            <p>The main advantage of I2C is that a microcontroller can
            control a <em>network</em> of chips with just
            <strong>two</strong> general-purpose I/O pins (serial data
            line and a serial clock line) and software. A controller
            device can communicate with any target device through a
            unique I2C address sent through the serial data line. Hence
            the two signals are:</p>
            <table style="width:100%;">
            <colgroup>
            <col style="width: 30%" />
            <col style="width: 35%" />
            <col style="width: 35%" />
            </colgroup>
            <thead>
            <tr>
            <th>line</th>
            <th>voltage</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>serial data line (SDL)</td>
            <td><code>+5V</code></td>
            <td>transmit data to or from target devices</td>
            </tr>
            <tr>
            <td>serial clock line (SCL)</td>
            <td><code>+3V</code></td>
            <td>synchronously clock data in or out of the target
            device</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Both are bidirectional and pulled up with resistors.</p>
            <p>Here is a typical implementation of I2C:</p>
            <p><img src="img/embedded_arch/comms/i2c_implementation.png" width="400"></p>
            <p>An I2C chip example (used for controlling certain TV
            signals):</p>
            <p><img src="img/embedded_arch/comms/i2c_tv_control.jpg" width="100"></p>
            <p>I2C is half-duplex communication where only a single
            controller or a target device is sending data on the bus at
            a time. In comparison, the serial peripheral interface (SPI)
            is a full-duplex protocol where data can be sent to and
            received back at the same time. An I2C controller device
            starts and stops communication, which removes the potential
            problem of bus contention. Communication with a target
            device is sent through a unique address on the bus. This
            allows for both multiple controllers and multiple target
            devices on the I2C bus.</p>
            <p>I2C communication details (initiated from the controller
            device):</p>
            <table>
            <colgroup>
            <col style="width: 70%" />
            <col style="width: 29%" />
            </colgroup>
            <thead>
            <tr>
            <th>condition</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>I2C <code>START</code></td>
            <td>the controller device first pulls the SDA low and then
            pulls the SCL low</td>
            </tr>
            <tr>
            <td>I2C <code>STOP</code></td>
            <td>the SCL releases high and then SDA releases high</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><img src="img/embedded_arch/comms/i2c_start_stop.png" width="300"></p>
            <p><br></p>
            <p>I2C communication is split into: <strong>frames</strong>.
            Communciation starts when one controller sends an
            <code>address frame</code> after a <code>START</code>. This
            is followed by one or more <code>data frames</code>, each
            consisting of <strong>one byte</strong>. Each frame also has
            an <code>acknowledgement</code> bit. An example of two I2C
            communication frames:</p>
            <p><img src="img/embedded_arch/comms/i2c_frames.png"></p>
            <p><br></p>
            <p>You can read more at: <a
            href="https://www.ti.com/lit/an/sbaa565/sbaa565.pdf">I2C</a>.</p>
            </section>
            <section id="spi" class="level4" data-number="2.3.2.2">
            <h4 data-number="2.3.2.2"><span
            class="header-section-number">2.3.2.2</span> SPI</h4>
            <p>The <a
            href="https://www.analog.com/en/resources/analog-dialogue/articles/introduction-to-spi-interface.html">Serial
            Peripheral Interface</a> (SPI) has become the de facto
            standard for <em>synchronous</em> serial communication. It
            is used in embedded systems, especially between
            microcontrollers and peripheral ICs such as sensors, ADCs,
            DACs, shift registers, SRAM, <em>etc.</em></p>
            <p>The main aspect of SPI is that one main device
            <strong>orchestrates communication</strong> with one ore
            more sub/peripheral devices by <strong>driving the clock and
            chip select signals</strong>.</p>
            <p>SPI interface properties:</p>
            <ul>
            <li><em>synchronous</em></li>
            <li><em>full duplex</em></li>
            <li><em>main-subnode</em> (formerly called
            “master-slave”)</li>
            <li>data from the main or the subnode is synchronized on the
            rising or falling clock edge</li>
            <li>main and subnode can transmit data at the same time</li>
            <li>interface can be 3 or 4-wire (4 wire version is more
            popular)</li>
            </ul>
            <table>
            <colgroup>
            <col style="width: 46%" />
            <col style="width: 53%" />
            </colgroup>
            <thead>
            <tr>
            <th>microchip SPI</th>
            <th>basic SPI Interface</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/embedded_arch/comms/spi_microchip.avif" width="100"></td>
            <td><img src="img/embedded_arch/comms/spi_basic.png" width="500"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The SPI interface contains the following wires:</p>
            <table>
            <colgroup>
            <col style="width: 25%" />
            <col style="width: 41%" />
            <col style="width: 32%" />
            </colgroup>
            <thead>
            <tr>
            <th>signal</th>
            <th>description</th>
            <th>function</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><code>SCLK</code></td>
            <td>serial clock</td>
            <td>clock signal from main</td>
            </tr>
            <tr>
            <td><code>CS</code></td>
            <td>chip/serial select</td>
            <td>To select which host to communicate with</td>
            </tr>
            <tr>
            <td><code>MOSI</code></td>
            <td>main out, subnode In</td>
            <td>serial data out (SDO) for host to target
            communication</td>
            </tr>
            <tr>
            <td><code>MISO</code></td>
            <td>main in, subnode Out</td>
            <td>serial data in (SDI) for target to host
            communication</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The main node generates the clock signal. Data
            transmissions between main ahd sub nodes is synchronized by
            that clock signal generated by main. SPI devices support
            <em>much higher clock frequencies</em> than I2C. The
            <code>CS</code> signal is used to select the subnode. Note
            that this is an <strong>active low signal</strong>,
            <em>i.e.,</em> a low (<code>0</code>) is a selection and a
            high (<code>1</code>) is a disconnect. SPI is a full-duplex
            interface; both main and subnode can send data at the same
            time via the MOSI and MISO lines respectively. During SPI
            communication, the data is simultaneously transmitted
            (shifted out serially onto the MOSI/SDO bus) and received
            (the data on the bus (MISO/SDI) is sampled or read in).</p>
            <p><strong>Example</strong>: the <a
            href="https://www.analog.com/en/resources/analog-dialogue/articles/introduction-to-spi-interface.html">following
            example</a> demonstrates the significant savings and
            simplification in systems design (reduce the number of GPIO
            pins required).</p>
            <p>Consider the ADG1412 switch being managed by a
            microcontroller as follows:</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example1.svg" width="300"></p>
            <p>Now, as the number of switches increases, the requirement
            on GPIO pins also increases significantly. A
            <code>4x4</code> configuration requires <code>16</code> GPI
            pins, thus reducing the number of pins available for the
            microcontroller for other tasks, as follows:</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example2.svg" width="300"></p>
            <p>One approach to reduce the number of pins would be to use
            a serial-to-parallel convertor:</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example3.svg" width="300"></p>
            <p>This reduces the pressure on the number of GPIO pins but
            still introduces additional circuitry.</p>
            <p>Using an SPI-enabled microcontroller reduces the number
            of GPIOs required and and eliminates the overheads of the
            needing additional chips (serial-to-paralle convertor):</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example4.svg" width="300"></p>
            <p>In fact, using a different SPI configuration
            (“<strong>daisy-chain</strong>”), we can optimize the GPIO
            count even further!</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example5.svg" width="300" height="250"></p>
            <p>You can read more about <a
            href="https://www.analog.com/en/resources/analog-dialogue/articles/introduction-to-spi-interface.html">SPI
            here</a>.</p>
            </section>
            </section>
            <section id="general-purpose-io-gpio" class="level3"
            data-number="2.3.3">
            <h3 data-number="2.3.3"><span
            class="header-section-number">2.3.3</span> General-Purpose
            I/O (GPIO)</h3>
            <p>A GPIO is a <strong>signal pin</strong> on an integrated
            circuit or board that can be used to perform <em>digital I/O
            operations</em>. By design, it <strong>has no predefined
            purpose</strong> → can be used by hardware/software
            developers to perform functions <em>they choose</em>,
            <em>e.g.,</em></p>
            <ul>
            <li>GPIO pins can be enabled or disabled.</li>
            <li>GPIO pins can be configured to be input or output.</li>
            <li>input values are readable, often with a 1 representing a
            high voltage, and a 0 representing a low voltage.</li>
            <li>input GPIO pins can be used as “interrupt” lines, which
            allow a peripheral board connected via multiple pins to
            signal to the primary embedded board that it requires
            attention.</li>
            <li>output pin values are both readable and writable.</li>
            </ul>
            <p>GPIOs can be implemented in a variety of ways,</p>
            <ul>
            <li>as a <em>primary</em> function of the microcontrollers,
            <em>e.g.</em>, <a
            href="https://www.geeksforgeeks.org/programmable-peripheral-interface-8255/">Intel
            8255</a></li>
            <li>as an <em>accessory</em> to the chip</li>
            </ul>
            <p>While microcontrollers may use GPIOs are their primary
            external interface, many a time the pins may be capable of
            other functions as well. In such instances, it may be
            necessary to configure the pins using other functions.</p>
            <p>Some examples of chips with GPIO pins:</p>
            <table>
            <colgroup>
            <col style="width: 27%" />
            <col style="width: 31%" />
            <col style="width: 40%" />
            </colgroup>
            <thead>
            <tr>
            <th>Intel 8255</th>
            <th>PIC microchip</th>
            <th>ASUS Tinker</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/embedded_arch/comms/gpio_Ic-photo-Intel--D8255.JPG" width="250"></td>
            <td><img src="img/embedded_arch/comms/gpio_microchip_PIC18F8720.jpg" width="150"></td>
            <td><img src="img/embedded_arch/comms/gpio_Asus_Tinker_Board.jpg" width ="200"></td>
            </tr>
            <tr>
            <td>24 GPIO pins</td>
            <td>29 GPIO pins</td>
            <td>28 GPIO pins</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>GPIOs are used in a diverse variety of applications,
            limited only by the electrical and timing specifications of
            the GPIO interface and the ability of software to interact
            with GPIOs in a sufficiently timely manner.</p>
            <p>Some “properties”/applications of GPIOs:</p>
            <ul>
            <li>GPIOs use standard logic levels and cannot supply
            significant current to output loads</li>
            <li>high-current output buffers or relays can be used to
            control high-power devices</li>
            <li>input buffers, relays, or opto-isolators translate
            incompatible signals to GPIO logic levels</li>
            <li>GPIOs can control or monitor other circuitry on a board,
            such as enabling/disabling circuits, reading switch states,
            and driving LEDs</li>
            <li>multiple GPIOs can implement bit banging communication
            interfaces like I²C or SPI</li>
            <li>GPIOs can control analog processes via PWM, adjusting
            motor speed, light intensity, or temperature</li>
            <li>PWM signals from GPIOs can be converted to analog
            control voltages using RC filters</li>
            </ul>
            <p>GPIO interfaces vary widely. Most commonly, they’re
            simple <em>groups of pins</em> that can switch between
            input/output. On the other hand, each pin can be set up
            differently → set up/accept/source different voltages/drive
            strengths/pull ups and downs.</p>
            <p>Programming the GPIO:</p>
            <ul>
            <li>usually pin states are exposed via different interfaces,
            <em>e.g.,</em> <strong>memory-mapped I/O</strong>
            peripherals or dedicated I/O port instructions</li>
            <li>input values can be used as interrupts (IRQs)</li>
            </ul>
            <p>For more information on programming/using GPIOs, read
            these: <a
            href="https://docs.oracle.com/javame/8.0/me-dev-guide/gpio.htm">GPIO
            setup and use</a>, <a
            href="https://www.instructables.com/Raspberry-Pi-Python-scripting-the-GPIO/">Python
            scripting the GPIO in Raspberry Pis</a>, <a
            href="https://docs.nordicsemi.com/bundle/ps_nrf52810/page/gpio.html">general
            purpose I/O</a>, <a
            href="https://projects.raspberrypi.org/en/projects/physical-computing/1">GPIO
            setup in Raspberry Pi</a>.</p>
            </section>
            <section id="jtag-debugging-interface" class="level3"
            data-number="2.3.4">
            <h3 data-number="2.3.4"><span
            class="header-section-number">2.3.4</span> JTAG Debugging
            Interface</h3>
            <p>The JTAG standard (named after the “Joint Test Action
            Group”), technically the <a
            href="https://web.archive.org/web/20170830070123/http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/jtag-101-ieee-1149x-paper.pdf">IEEE
            Std 1149.1-1990 IEEE Standard Test Access Port and
            Boundary-Scan Architecture</a>, is an industry standard for
            <strong>testing and verification of printed circuit
            boards</strong>, <em>after manufacture</em>.</p>
            <p>“JTAG”, depending on the context, could stand for one or
            more of the following:</p>
            <ul>
            <li>implementation of IEEE 1149.x for Board Test, or
            Boundary Scan testing</li>
            <li>appliance used to program on board flash or eeprom
            devices on a circuit board</li>
            <li>hardware device used to debug microprocessor
            software</li>
            <li>hardware device used to test a board using Boundary
            Scan</li>
            </ul>
            <p>The basic building block of a JTAG OCD is the
            <strong>Test Access Point</strong> or <strong>TAP
            controller</strong>. This allows access to all the custom
            features within a specific processor, and must support a
            minimum set of commands. On-chip debugging is a
            <em>combination of hardware and software</em>.</p>
            <table>
            <thead>
            <tr>
            <th>type</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>hardaware</td>
            <td><strong>on chip debug</strong> (OCD)</td>
            </tr>
            <tr>
            <td>software</td>
            <td><strong>in-circuit-emulator</strong> (ICE)/JTAG
            emulator</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The off-chip parts are actually PC peripherals that need
            corresponding drivers running on a separate computer. On
            most systems, JTAG-based debugging is available from the
            very first instruction after CPU reset, letting it assist
            with development of early boot software which runs before
            anything is set up. The JTAG emulator allows developers to
            access the embedded system at the <strong>machine code
            level</strong> if needed! Many silicon architectures (Intel,
            ARM, PowerPC, etc.) have built entire infrastructures and
            extensions around JTAG.</p>
            <p>A high-level overview of the JTAG architecture/use:</p>
            <p><img src="img/embedded_arch/comms/jtag_high_level.png" width="400"></p>
            <p><br></p>
            <p>JTAG now allows for,</p>
            <ul>
            <li>processors can not be <em>halted</em>,
            <em>single-stepped</em> or <em>run freely</em></li>
            <li>can set code <em>breakpoints</em> for both, code in RAM
            as well as ROM/flash</li>
            <li><em>data breakpoints</em> are available</li>
            <li><em>bulk data download</em> to RAM</li>
            <li><em>access to registers and buses</em>, even without
            halting the processors!</li>
            <li><em>complex logic routines</em>, <em>e.g.,</em> ignore
            the first seven accesses to a register from one particular
            subroutine</li>
            </ul>
            <p>JTAG allows for <em>device programmer hardware</em>
            allows for transfering data into internal,
            <em>non-volatile</em> memory of the system! Hence, we can
            use JTAGs to <strong>program</strong> devices such as FPGAs.
            In fact, many memory chips also have JTAG interfaces. Some
            modern chips also allow access to the the (internal and
            external) data buses via JTAG.</p>
            <p><strong>JTAG interface</strong>: depending on the actual
            interface, JTAG has 2/4/5 pins. The 4/5 pin versions are
            designed so that <em>multiple chips</em> on a board can have
            their JTAG lines <strong>daisy-chained</strong> together if
            specific conditions are met.</p>
            <p>Schematic Diagram of a JTAG enabled device:</p>
            <p><img src="img/embedded_arch/comms/jtag_schematic_diagram.gif" width="300"></p>
            <p>The various pins signals in the JTAG TAP are:</p>
            <table>
            <colgroup>
            <col style="width: 38%" />
            <col style="width: 61%" />
            </colgroup>
            <thead>
            <tr>
            <th>signal</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><code>TCK</code></td>
            <td>synchronizes the internal state machine operations</td>
            </tr>
            <tr>
            <td><code>TMS</code></td>
            <td>sampled at the rising edge of <code>TCK</code> to
            determine the next state</td>
            </tr>
            <tr>
            <td><code>TDI</code></td>
            <td>data shifted into the device’s test or programming
            logic; sampled at the rising edge of <code>TCK</code> when
            the internal state machine is in the correct state</td>
            </tr>
            <tr>
            <td><code>TDO</code></td>
            <td>represents the data shifted out of the device’s test or
            programming logic and is valid on the falling edge of
            <code>TCK</code> when the internal state machine is in the
            correct state</td>
            </tr>
            <tr>
            <td><code>TRST</code></td>
            <td>optional pin which, when available, can reset the tap
            controller’s state machine</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The TAP controller implements the following state
            machine:</p>
            <p><img src="img/embedded_arch/comms/jtag_tap_state_machine.gif" width="300"></p>
            <p><br></p>
            <p>To use the JTAG interface,</p>
            <ul>
            <li>host is connected to the target’s JTAG signals
            (<code>TMS</code>, <code>TCK</code>, <code>TDI</code>,
            <code>TDO</code>, etc.) through some kind of JTAG
            adapter</li>
            <li>adapter connects to the host using some interface such
            as USB, PCI, Ethernet, etc.</li>
            <li>host communicates with the TAPs by manipulating
            <code>TMS</code> and <code>TDI</code> in conjunction with
            <code>TCK</code></li>
            <li>host reads results through <code>TDO</code> (which is
            the only standard host-side input)</li>
            <li><code>TMS</code>/<code>TDI</code>/<code>TCK</code>
            output transitions create the basic JTAG communication
            primitive on which higher layer protocols build</li>
            </ul>
            <p><br></p>
            <p>For more information about JTAG, read: <a
            href="https://web.archive.org/web/20170830070123/http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/jtag-101-ieee-1149x-paper.pdf">Intel
            JTAG Overview</a>, <a
            href="https://forums.raspberrypi.com/viewtopic.php?t=286115">Raspberry
            Pi JTAG programming</a>, <a
            href="https://www.xjtag.com/about-jtag/jtag-a-technical-overview/">Technical
            Guide to JTAG</a> and the <a
            href="https://en.wikipedia.org/wiki/JTAG">JTAG Wikipedia
            Entry</a> is quite detailed.</p>
            </section>
            <section id="controller-area-network-can" class="level3"
            data-number="2.3.5">
            <h3 data-number="2.3.5"><span
            class="header-section-number">2.3.5</span> Controller Area
            Network (CAN)</h3>
            <p>CAN is a vehicle bus standard to enable efficient
            communication between electronic control units (ECUs). CAN
            is,</p>
            <ul>
            <li>broadcast-based</li>
            <li>message-oriented</li>
            <li>uses arbitration → for data
            integrity/prioritization</li>
            </ul>
            <p>CAN <strong>does not</strong> need a a host controller.
            ECUs connected via the CAN bus can easily share information
            with each other. all ECUs are connected on a two-wire bus
            consisting of a twisted pair: CAN high and CAN low. The
            wires are often color coded:</p>
            <table>
            <tbody>
            <tr>
            <td>CAN high</td>
            <td>yellow</td>
            </tr>
            <tr>
            <td>CAN low</td>
            <td>green</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <table>
            <colgroup>
            <col style="width: 42%" />
            <col style="width: 57%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/embedded_arch/comms/can-twisted-can-bus-wiring-harness-high-low-green-yellow.svg" width="200"></td>
            <td><img src="img/embedded_arch/comms/CAN-bus_basic.svg" width="300"></td>
            </tr>
            <tr>
            <td>CAN wiring</td>
            <td>multi-ecu CAN setup</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>An ECU in a vehicle consists of:</p>
            <table>
            <tr>
            <th>
            components
            </th>
            <th>
            internal architecture
            </th>
            </tr>
            <tr>
            <td>
            <ul>
            <li>
            <b>microcontroller</b> to interpret/send out CAN messages
            </li>
            <li>
            <b>CAN controller</b> ensures all communication adheres to
            CAN protocols
            </li>
            <li>
            <b>CAN transceiver</b> connects CAN controller to the
            physical wires
            </li>
            </ul>
            </td>
            <td>
            <img src="img/embedded_arch/comms/can_ecu_internals.svg" width="250">
            </td>
            </tr>
            <tr>
            <td>
            </td>
            <td>
            </td>
            </tr>
            </table>
            <p><em>Any</em> ECU can broadcast on the CAN bus and the
            messages are accepted by <em>all</em> ECUs connected to it.
            Each ECU can either choose to ignore the message or act on
            it.</p>
            <blockquote>
            <p>what are the implications for
            <strong>security</strong>?</p>
            </blockquote>
            <p>While there is no “standard” CAN connector (each vehicle
            may use different ones), the <strong>CAN Bus DB9</strong>
            connector has become the de facto standard:</p>
            <p><img src="img/embedded_arch/comms/can-bus-db9-connector-pinout-d-sub.svg" width="350"></p>
            <p>The above figure shows the various pins and their
            signals.</p>
            <p><br></p>
            <p><strong>CAN Communication Protocols</strong>: CAN is
            split into:</p>
            <table>
            <tr>
            <th>
            layer
            </th>
            <th>
            relation to OSI stack
            </th>
            </tr>
            <tr>
            <td>
            <ul>
            <li>
            <b>data link</b>: CAN frame formats, <br>error handling,
            data transmission, <br>data integrity
            </li>
            <li>
            <b>physical</b>: cable types, <br>electrical signal levels,
            <br>node requirements, <br>cable impedance, etc.
            </li>
            </ul>
            </td>
            <td>
            <img src="img/embedded_arch/comms/can-bus-osi-model-7-layer-iso-11898-physical-data.svg" width="350">
            </td>
            </tr>
            <tr>
            <td>
            </td>
            <td>
            </td>
            </tr>
            </table>
            <p><br></p>
            <p>All communication over the CAN bus is done via the
            <strong>CAN frames</strong>. The <em>standard</em> CAN frame
            (with an <code>11-bit</code> identifier) is shown below:</p>
            <p><img src="img/embedded_arch/comms/CAN-bus-frame-standard-message-SOF-ID-RTR-Control-Data-CRC-ACK-EOF.svg" width="400"></p>
            <p><br></p>
            <p>While the lower-level CAN protocols described so far work
            on the two lowest layers of the OSI networking stack, it is
            still limiting. For instance, the CAN standard doesn’t
            discuss how to,</p>
            <ul>
            <li>decode RAW data</li>
            <li>handle larger data (more than 8 bytes)</li>
            </ul>
            <p>Hence, some <strong>higher-order</strong> protocols have
            been developed, <em>viz.,</em></p>
            <table>
            <colgroup>
            <col style="width: 42%" />
            <col style="width: 57%" />
            </colgroup>
            <thead>
            <tr>
            <th>protocol</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/obd2-explained-simple-intro">OBD2</a></td>
            <td>on-board diagnostics in cars/trucks for diagnostics,
            maintenance, emissions tests</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/uds-protocol-tutorial-unified-diagnostic-services">UDS</a></td>
            <td>Unified Diagnostic Services (UDS) used in automotive
            ECUs for diagnostics, firmware updates, routine testing</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/ccp-xcp-on-can-bus-calibration-protocol">CCP/XCP</a></td>
            <td>used in embedded control/industrial automation for
            <em>off-the-shelf interoperability</em> between CAN
            devices</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/j1939-explained-simple-intro-tutorial">SAE
            J1939</a></td>
            <td>for heavy-duty vehicles</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/nmea-2000-n2k-intro-tutorial">NMEA
            2000</a></td>
            <td> used in maritime industry for connecting e.g. engines,
            instruments, sensors on boats</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/isobus-introduction-tutorial-iso-11783">ISOBUS</a></td>
            <td>used in agriculture and forestry machinery to enable
            plug and play integration between vehicles/implements,
            <em>across brands</em></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>There also exist other higher-order protocols (numbering
            in the thousands) the most prominent of which are: ARINC,
            UAVCAN, DeviceNet, SafetyBUS p, MilCAN, HVAC CAN.</p>
            <p><br></p>
            <p>More details about CAN and its variants: <a
            href="https://www.csselectronics.com/pages/can-bus-simple-intro-tutorial">CAN
            Bus Explained</a>.</p>
            </section>
            <section id="other-broadly-used-protocols" class="level3"
            data-number="2.3.6">
            <h3 data-number="2.3.6"><span
            class="header-section-number">2.3.6</span> Other Broadly
            Used Protocols</h3>
            <p>Autonomous (and other embedded systems) use a variety of
            other communication protocols in order to interface with the
            external world and/or other systems (either other nodes in
            the system or external components such as back end
            clouds).</p>
            <p>Note that since many of these are well known and publicly
            documented, we won’t elaborate much here.</p>
            <p>Here are some of the well known communication protocols,
            also used in embedded systems:</p>
            <table>
            <colgroup>
            <col style="width: 57%" />
            <col style="width: 42%" />
            </colgroup>
            <thead>
            <tr>
            <th>protocol</th>
            <th>links</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>USB</td>
            <td>How USB works: <a
            href="https://www.circuitbread.com/tutorials/how-usb-works-introduction-part-1">part
            1</a>, <a
            href="https://www.circuitbread.com/tutorials/how-usb-works-communication-protocol-part-2">part2</a>,
            <a
            href="https://www.circuitbread.com/tutorials/how-usb-works-enumeration-and-configuration-part-3">part
            3</a>; <a
            href="https://www.beyondlogic.org/usbnutshell/usb1.shtml">USB
            in a Nutshell (very detailed)</a>.</td>
            </tr>
            <tr>
            <td>Ethernet</td>
            <td><a
            href="https://www.embedded.com/implement-reliable-embedded-ethernet-connectivity/">Reliable
            Embedded Ethernet</a>, <a
            href="https://www.google.com/books/edition/_/3ZPPBgAAQBAJ?hl=en&amp;gbpv=1&amp;pg=PA1">Embedded
            Ethernet and Internet (book, online)</a></td>
            </tr>
            <tr>
            <td>WiFi</td>
            <td><a
            href="https://ebulutvcu.github.io/COMST22_WiFi_Sensing_Survey.pdf">WiFi
            Sensing on the Edge (paper)</a></td>
            </tr>
            <tr>
            <td>Bluetooth</td>
            <td><a
            href="https://learn.sparkfun.com/tutorials/bluetooth-basics/all">Bluetooth
            Basics</a>, <a
            href="https://novelbits.io/bluetooth-low-energy-ble-complete-guide/">Bluetooth
            Low Energy</a></td>
            </tr>
            <tr>
            <td>Radio</td>
            <td><a
            href="https://wiki.gnuradio.org/index.php/Embedded_Development_with_GNU_Radio">Embedded
            Development with GNU Radio</a></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            <section id="raspberry-pi-and-navio2" class="level2"
            data-number="2.4">
            <h2 data-number="2.4"><span
            class="header-section-number">2.4</span> Raspberry Pi and
            Navio2</h2>
            <p>Let us look at the two architectures we use extensively
            in this course:</p>
            <ul>
            <li><a
            href="https://www.raspberrypi.com/products/raspberry-pi-4-model-b/specifications/">Raspberry
            Pi</a> model 4(b)</li>
            <li><a href="https://navio2.hipi.io">Navio2</a> → autopilot
            hat for the Raspberry Pi</li>
            </ul>
            <p>The high-level architecture of the Pi shows many of the
            components we have discussed so far:</p>
            <p><img src="img/embedded_arch/pi-4-architectural_features.png" width="400"></p>
            <p>In particular, the Pi has,</p>
            <table>
            <colgroup>
            <col style="width: 33%" />
            <col style="width: 66%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>description/details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>processor</td>
            <td>Broadcomm <strong>BCM2711</strong>, Quad core Cortex-A72
            (ARM v8) 64-bit SoC at 1.8GHz</td>
            </tr>
            <tr>
            <td>memory</td>
            <td>1GB, 2GB, 4GB or 8GB LPDDR4-3200 SDRAM</td>
            </tr>
            <tr>
            <td>network</td>
            <td>Wifi (2.4/5.0 GHz), Gigabit ethernet, Bluetooth/BLE</td>
            </tr>
            <tr>
            <td>I/O</td>
            <td>40 pin GPIO, USB 3.0/2.0/C</td>
            </tr>
            <tr>
            <td>storage</td>
            <td>Micro-SD Card</td>
            </tr>
            <tr>
            <td>misc</td>
            <td>micro-hdmi, stereo audio/video, displayport, camera
            port, power</td>
            </tr>
            <tr>
            <td>os</td>
            <td><a
            href="https://www.raspberrypi.com/software/">Raspberry Pi
            OS</a> (formerly called Raspbian)</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Read more about the Raspberry Pi: <a
            href="https://www.electronics-lab.com/project/raspberry-pi-4-look-hood-make/">Raspberry
            PI – A Look Under the Hood</a></p>
            <p><br></p>
            <p>The <strong>Navio2</strong> is a “hat” that adds the
            following to a Raspberry Pi:</p>
            <ul>
            <li>autopilot functionality</li>
            <li>multiple sensors</li>
            </ul>
            <p>The high-level architecture,</p>
            <p><img src="img/embedded_arch/navio2_features.jpg" width="400"></p>
            <p>As the figure shows, the Navio2 adds the following
            components:</p>
            <table>
            <colgroup>
            <col style="width: 32%" />
            <col style="width: 67%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>description/details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>GNSS receiver</td>
            <td>for GPS signals</td>
            </tr>
            <tr>
            <td>high-precision barometer</td>
            <td>for measuring pressure (and altitude)</td>
            </tr>
            <tr>
            <td>(dual) IMU</td>
            <td>two 9 DOF with gyroscope, accelerometer, magnetometer,
            each</td>
            </tr>
            <tr>
            <td>RC I/O co-processor</td>
            <td>PWM, ADC, SBUS, PPM</td>
            </tr>
            <tr>
            <td>extension ports</td>
            <td>ADC, I2C, UART</td>
            </tr>
            <tr>
            <td>power supply</td>
            <td>triple redundant</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>More details about the Navio2 and how to program it: <a
            href="https://docs.emlid.com/navio2/">Navio2
            Documentation</a>.</p>
            <p><br> <br></p>
            </section>
            <section id="references" class="level2" data-number="2.5">
            <h2 data-number="2.5"><span
            class="header-section-number">2.5</span> References</h2>
            </section>
            </section>
            <section id="sensors-and-sensing" class="level1"
            data-number="3">
            <h1 data-number="3"><span
            class="header-section-number">3</span> Sensors and
            Sensing</h1>
            <p>An embedded/autonomous system <em>perceives</em> the
            physical world via sensors – either to gather information
            about its environment or to model its <em>own</em> state.
            Hence it is a critical component in the <em>sensing →
            planning → actuation</em> loop and a critical component in
            the design of embedded and autonomous systems.</p>
            <table>
            <colgroup>
            <col style="width: 46%" />
            <col style="width: 53%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sense_planning_actuation.png" width="400"></td>
            <td><img src="img/stack_architecture/stack_overview.2.png" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Modern autonomous systems used a <em>wide array</em> of
            sensors. This is necessary due to:</p>
            <ul>
            <li>there is a need to measure <strong>different</strong>
            quantities, <em>e.g.,</em> GPS, velocity, objects,
            <em>etc.</em></li>
            <li>sensor measurements often have <strong>errors</strong> →
            hence, we need multiple sensors, often using
            <strong>different physical properties</strong> to measure
            the <em>same thing</em>; <em>e.g.,</em> LiDar and cameras
            can both be used to detect objects in front of, and around,
            an autonomous vehicle.</li>
            </ul>
            <p>At its core,</p>
            <blockquote>
            <p>a sensor captures a physical/chemical/environmental
            quantity and <strong>converts it to a digital
            quantity</strong>.</p>
            </blockquote>
            <p>(hence the need for an Analog-to-Digital Convertor (ADC)
            as we shall see later)</p>
            <p>By definition, sensors generate <strong>signals</strong>.
            A signal, <code>s</code>, is defined as a mapping from the
            <em>time</em> domain to a <em>value</em> domain:</p>
            <p><span
            class="math display"><em>s</em> : <em>D</em><sub><em>t</em></sub> ↦ <em>D</em><sub><em>v</em></sub></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>t</em></sub></span></td>
            <td>continuous or discrete <strong>time</strong> domain</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>v</em></sub></span></td>
            <td>continuous or discrete <strong>value</strong>
            domain</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><strong>Note:</strong> remember that computers require
            <strong>discrete</strong> sequences of physical values.
            Hence, we need to <strong>convert</strong> the above into
            the discrete domain. The way to achieve this:
            <strong>sampling</strong>:</p>
            <p><img src="img/sensors/discretization_sampled.signal.svg" title="Sampling image from Wikipedia" width="300"></p>
            <p>The figure shows a continuous signal being sampled (in
            <font color="red"><b>red</b></font> arrows). We will discuss
            sampling and related issues later in this topic.</p>
            <section id="types-of-sensors" class="level2"
            data-number="3.1">
            <h2 data-number="3.1"><span
            class="header-section-number">3.1</span> Types of
            Sensors</h2>
            <p>Sensors come in various shapes and sizes. Usually
            designers of autonomous systems will develop a
            “<strong>sensor plan</strong> that will consider,</p>
            <ul>
            <li>required functionality</li>
            <li>sensor range(s)</li>
            <li>cost</li>
            </ul>
            <p>Hence, each autonomous system will likely have its own
            set of sensors (or sensor plan). <em>Typical</em> sensors
            found on modern autonomous systems can be classified based
            on the underlying physics used:</p>
            <table>
            <colgroup>
            <col style="width: 70%" />
            <col style="width: 29%" />
            </colgroup>
            <thead>
            <tr>
            <th>physical property</th>
            <th>sensor</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><a
            href="#inertial-measurement-units-imu"><em>internal</em>
            measurements</a></td>
            <td>IMU</td>
            </tr>
            <tr>
            <td><em>external</em> measurements</td>
            <td>GPS</td>
            </tr>
            <tr>
            <td><a
            href="#bouncing-of-electromagnetic-waves--lidar-and-mmwave">“bouncing”
            electromagnetic waves</a></td>
            <td>LiDAR, RADAR, mmWave Radar</td>
            </tr>
            <tr>
            <td>optical</td>
            <td>cameras, infrared sensors</td>
            </tr>
            <tr>
            <td><a href="#ultrasonic">accoustic</a></td>
            <td>ultrasonic sensors</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Some of the above can be combined to generate other
            sensing patterns, <em>e.g.,</em> <strong>stereo
            vision</strong> using multiple cameras or camera+LiDAR.</p>
            <p>We will go over <strong>some</strong> of these sensors
            and their underlying physical principles.</p>
            <section id="inertial-measurement-units-imu" class="level3"
            data-number="3.1.1">
            <h3 data-number="3.1.1"><span
            class="header-section-number">3.1.1</span> Inertial
            Measurement Units (IMU)</h3>
            <p>These sensors define the <strong>movement of a
            vehicle</strong>, along the three axes, in addition to other
            behaviors like acceleration and directionality. An IMU
            typically includes the following sensors:</p>
            <table>
            <colgroup>
            <col style="width: 24%" />
            <col style="width: 21%" />
            <col style="width: 24%" />
            <col style="width: 29%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sensors/imu_exploded_view.jpg" width="600"></td>
            <td><img src="img/sensors/imu_accelerometer.png" width="400"></td>
            <td><img src="img/sensors/imu_gyro.png" width="400"></td>
            <td><img src="img/sensors/imu_magnetometer.png" width="400"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>As we see from the first picture above, an IMU also has a
            CPU (typically a microcontroller) to manage/collect/process
            the data from the sensors.</p>
            <p>The functions of the three sensors are:</p>
            <ol type="1">
            <li><strong>gyroscope</strong>: is an inertial sensor that
            measure an object’s angular rate with respect to an inertial
            reference frame. It measures the following movements:</li>
            </ol>
            <table>
            <colgroup>
            <col style="width: 29%" />
            <col style="width: 37%" />
            <col style="width: 33%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sensors/imu_yaw.gif"></td>
            <td><img src="img/sensors/imu_pitch.gif"></td>
            <td><img src="img/sensors/imu_roll.gif"></td>
            </tr>
            <tr>
            <td>“yaw”</td>
            <td>“pitch”</td>
            <td>“roll”</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>IMUs come in all shapes and sizes. These days they’re
            very small but the original IMU’s ver really large, as
            evidenced by the one used in the <a
            href="http://klabs.org/history/history_docs/mit_docs/1690.pdf">Apollo
            space missions</a>:</p>
            <p><img src="img/sensors/imu_apollo.jpg" width="300"></p>
            <p><br></p>
            <ol start="2" type="1">
            <li><p><strong>accelerometer</strong>: is the primary sensor
            responsible for measuring inertial acceleration, or the
            change in velocity over time.</p></li>
            <li><p><strong>magnetometer</strong>: measures the strength
            and direction of magnetic field – to find the magnetic
            north</p></li>
            </ol>
            </section>
            <section
            id="bouncing-of-electromagnetic-waves-lidar-and-mmwave"
            class="level3" data-number="3.1.2">
            <h3 data-number="3.1.2"><span
            class="header-section-number">3.1.2</span> Bouncing of
            Electromagnetic Waves | LiDAR and mmWave</h3>
            <p>A very common principle for measuring surroundings is to
            bounce electromagnetic waves off nearby objects and
            measuring the round trip times. Shorter times indicate
            closer objects while longer times indicate objects that are
            farther away. <a
            href="https://www.noaa.gov/jetstream/doppler/how-radar-works">RADAR</a>
            is a classic example of this type of sensor and its (basic)
            operation is shown in the following image (courtesy
            NOAA):</p>
            <p><img src="img/sensors/radar_doppler_ani.gif" width="400"></p>
            <p>While many autonomous vehicles use RADAR, we will focus
            on other technologies that are more prevalent and provide
            much higher precision, <em>viz.,</em></p>
            <ol type="1">
            <li><a
            href="#light-detection-and-ranging-lidar">LiDAR</a></li>
            <li>millimeter Wave RADAR (mmWave)</li>
            </ol>
            <section id="light-detection-and-ranging-lidar"
            class="level4" data-number="3.1.2.1">
            <h4 data-number="3.1.2.1"><span
            class="header-section-number">3.1.2.1</span> Light Detection
            and Ranging (LiDAR)</h4>
            <p><a
            href="https://web.stanford.edu/class/ee259/lectures/ee259_05_lidar.pdf">LiDAR</a>
            is a sensor that uses (<em>eye safe</em>) <strong>laser
            beams</strong> for mapping surroundings and creating
            <strong>3D representation</strong> of the environment. So
            lasers are used for,</p>
            <ul>
            <li>imaging</li>
            <li>detection</li>
            <li>ranging</li>
            </ul>
            <p>We can use LiDAR to distance, angle as well as the
            <em>radial velocity</em> of some objects – all relative to
            the autonomous system (rather the sensor). So, in practice,
            this is how it operates:</p>
            <p><img src="img/sensors/lidar_principle_operation.png" width="400"></p>
            <p>We define a <strong>roundtrip time</strong>, $ au$, as
            the time between when a pulse is sent out from the
            transmitter (<code>TX</code>) to when light reflected from
            the object is detected at the receiver
            (<code>RX</code>).</p>
            <p>So, the <strong>target range</strong> (<em>i.e.,</em> the
            distance to te object), <span
            class="math inline"><em>R</em></span>, is measured as:</p>
            <p><span
            class="math display"><em>R</em> = <em>r</em><em>a</em><em>c</em><em>c</em><em>a</em><em>u</em>2</span></p>
            <p>where, <code>c</code> is the speed of light.</p>
            <p>More details (from <a
            href="https://web.stanford.edu/class/ee259/lectures/ee259_05_lidar.pdf">Mahalati</a>):
            &gt; Lasers used in lidars have frequencies in the <span
            class="math inline">100<em>s</em></span> of Terahetrz.
            Compared to RF waves, lasers have significantly smaller
            wavelengths and can hence be easily collected into narrow
            beams using lenses. This makes DOA estimation almost trivial
            in lidar and gives it significantly better reso- lution than
            MIMO imaging radar.</p>
            <p>The <em>end product</em> of LiDAR is essentially a
            <strong>point cloud</strong>, defined as:</p>
            <blockquote>
            <p>a collection of points generated by a sensor. Such
            collections can be very dense and contain billions of
            points, which enables the creation of highly detailed 3D
            representations of an area.</p>
            </blockquote>
            <p><img src="img/sensors/lidar_point_cloud_torus.gif" title="3D point cloud of a Torus. Courtesy Wikipedia"></p>
            <p>In reality, point cloud representations around autonomous
            vehicles end up looking like:</p>
            <video controls width="500">
            <source src="https://sibin.github.io/teaching/csci6907_88-gwu-secure_autonomous/fall_2022/other_docs/What-is-Lidar-video.mp4">
            </video>
            <p><a
            href="https://www.yellowscan.com/knowledge/lidar-point-cloud-basics/">Point
            clouds</a> provide valuable information, <em>viz.,</em></p>
            <ul>
            <li>3D coordinates, <span
            class="math inline">(<em>x</em>, <em>y</em>, <em>z</em>)</span></li>
            <li><strong>strength</strong> of returned signal → provides
            valuable information about the <strong>density</strong> of
            the object (or even material composition)!</li>
            <li>additional attributes: return number, scan angle, scan
            direction, point density, RGB color values, and time stamps
            → each can be used for refining the scan.</li>
            </ul>
            <p>There are <strong>two types</strong> of <em>scene
            illumination</em> techniques for LiDAR:</p>
            <table>
            <colgroup>
            <col style="width: 20%" />
            <col style="width: 52%" />
            <col style="width: 27%" />
            </colgroup>
            <thead>
            <tr>
            <th>type</th>
            <th>illumination method</th>
            <th>detector</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>flash lidar</td>
            <td><em>entire</em> scene using wide laser</td>
            <td>receives all echoes on a photodetector array</td>
            </tr>
            <tr>
            <td>scanning lidar</td>
            <td>very narrow laser beams, scan illumination spot with
            laser beam scanner</td>
            <td>single photodetector to sequentially estimate $ au$ for
            each spot</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <table>
            <colgroup>
            <col style="width: 28%" />
            <col style="width: 28%" />
            <col style="width: 42%" />
            </colgroup>
            <thead>
            <tr>
            <th></th>
            <th>flash lidar</th>
            <th>scan lidar</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>architecture</strong></td>
            <td><img src="img/sensors/lidar_flash.png" width="400"></td>
            <td><img src="img/sensors/lidar_scan.png" width="400"></td>
            </tr>
            <tr>
            <td><strong>resolution</strong> determined by</td>
            <td>photodetector array pizel size (like camera)</td>
            <td>laser beam size and spot fixing</td>
            </tr>
            <tr>
            <td><strong>frame rates</strong></td>
            <td>higher (up to <code>100 fps</code>)</td>
            <td>lower (&lt; <code>30 fps</code>)</td>
            </tr>
            <tr>
            <td><strong>range</strong></td>
            <td>shorter (quick beam divergence, like photography)</td>
            <td>longer (<code>100m+</code>)</td>
            </tr>
            <tr>
            <td><strong>use</strong></td>
            <td>less common</td>
            <td><strong>most common</strong></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Now, consider the following scene (captured by a
            camera):</p>
            <p><img src="img/sensors/lidar_camera_image.png" width="400"></p>
            <p><br> <br></p>
            <p>Compare this to the LiDAR images captured by the two
            methods:</p>
            <table>
            <colgroup>
            <col style="width: 30%" />
            <col style="width: 30%" />
            <col style="width: 38%" />
            </colgroup>
            <thead>
            <tr>
            <th>flash lidar</th>
            <th>scan lidar (16 scan lines)</th>
            <th>scan lidar (32 scan lines)</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/sensors/lidar_flash_image.png" width="400"></td>
            <td><img src="img/sensors/lidar_scan_16.png" width="400"></td>
            <td><img src="img/sensors/lidar_scan_32.png" width="400"></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <blockquote>
            <p>A “LiDAR scan line” refers to a <strong>single horizontal
            line</strong> of laser pulses emitted by a LiDAR sensor,
            essentially capturing a cross-section of the environment at
            a specific angle as the sensor rotates, creating a 3D point
            cloud by combining multiple scan lines across the field of
            view; it’s the basic building block of a LiDAR scan, similar
            to how a single horizontal line is a building block of an
            image.</p>
            </blockquote>
            <p><strong>Potential Problems</strong>:</p>
            <p>Atmospheric/environmental conditions can
            <strong>negatively</strong> affect the quality of the data
            captured by the LiDAR. For instance, <strong>fog</strong>
            can scatter the laser photons resulting in <strong>false
            positives</strong>.</p>
            <p><img src="img/sensors/lidar_fog.png" width="400"></p>
            <p>As we see from the above image, the scattering due to the
            fog results in the system “identifying” multiple objects
            even though there is only <em>one</em> person in the
            scene.</p>
            <p>Here are additional examples from the <a
            href="https://www.mapix.com/lidar-scanner-sensors/velodyne/velodyne-vlp-32c/">Velodyne
            VLP-32C</a> sensor:</p>
            <ol type="1">
            <li><strong>light</strong> fog (camera vs LiDAR)</li>
            </ol>
            <p><img src="img/sensors/lidar_veoldyne_lightfog.png" width="600"></p>
            <p>The LiDAR does a good job isolating the main subject with
            very few false positives.</p>
            <ol start="2" type="1">
            <li><strong>heavy</strong> fog (camera vs LiDAR)</li>
            </ol>
            <p><img src="img/sensors/lidar_velodyne_heavyfog.png" width="600"></p>
            <p>The LiDAR <em>struggles</em> to isolate the main subject
            with very <em>high</em> false positives.</p>
            <p>In spite of these issues, LiDAR is one of the most
            popular sensors used in autonomous vehicles. They’re getting
            smaller and more precise by the day; also decreasing costs
            means that we will see a proliferation of these types of
            sensors in many autonomous systems.</p>
            <p>For an in-depth study on LiDARs, check this out: <a
            href="https://web.stanford.edu/class/ee259/lectures/ee259_05_lidar.pdf">Stanford
            EE 259 LiDAR Lecture</a>.</p>
            </section>
            <section id="millimeter-wave-radar-mmwave" class="level4"
            data-number="3.1.2.2">
            <h4 data-number="3.1.2.2"><span
            class="header-section-number">3.1.2.2</span> Millimeter Wave
            Radar [mmWave]</h4>
            <p>Short wavelengths like the *millimeter wave<strong>
            (</strong>mmWave**) in the electromagnetic spectrum allows
            for:</p>
            <ul>
            <li>smaller antennae</li>
            <li>integration of entire RADAR circuitry in a single
            chip!</li>
            <li>spectrum of 10 millimeters (<code>30 GHz</code>) to 1
            millimeter (<code>300 GHz</code>)</li>
            </ul>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sensors/mmwave.jpg" width="300"></td>
            <td><img src="img/sensors/mmwave_ucsdavif.avif" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>As we see from the above images, the sensors can be
            <strong>very small</strong>, yet <strong>very
            precise</strong> → some can detect movements up to <em>4
            millionths of a meter</em>!</p>
            <p><strong>Advantages</strong> of mmWave:</p>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <thead>
            <tr>
            <th>Advantage</th>
            <th>Description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>small antenna caliber</td>
            <td>narrow beam gives high tracking, accuracy; high-level
            resolution, high-resistance interference performance of
            narrow beam; high antenna gain; smaller object
            detection</td>
            </tr>
            <tr>
            <td>large bandwidth</td>
            <td>high information rate, details structural features of
            the target; reduces multipath, and enhances
            anti-interference ability; overcomes mutual interference;
            high-distance resolution</td>
            </tr>
            <tr>
            <td>high doppler frequency</td>
            <td>good detection and recognition ability of slow
            objectives and vibration targets; can work in snow
            conditions</td>
            </tr>
            <tr>
            <td>good anti-blanking performance</td>
            <td>works on the most used stealth material</td>
            </tr>
            <tr>
            <td>robustness to atmospheric conditions</td>
            <td>such as dust, smoke, and fog compared to other
            sensors</td>
            </tr>
            <tr>
            <td>operation under different lights</td>
            <td>radar can operate under bright lights, dazzling lights,
            or no lights</td>
            </tr>
            <tr>
            <td>insusceptible to ground clutter</td>
            <td>allowing for close-range observations; the low
            reflectivity can be measured using mmwave radar</td>
            </tr>
            <tr>
            <td>fine spatial resolution</td>
            <td>for the same range, mmwave radar offers finer spatial
            resolution than microwave radar &gt;</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>mmWave is also used for <strong>in-cabin monitoring of
            drivers</strong>!</p>
            <p><br></p>
            <p><strong>Limitations</strong>:</p>
            <ul>
            <li>line of sight operations</li>
            <li>affected by water content, gases in environments</li>
            <li>affected by contaminated environment and physical
            obstacles</li>
            </ul>
            <p><br></p>
            <p><strong>Resources</strong>:</p>
            <p>For a more detailed description of mmWave RADAR, read: <a
            href="https://www.design-reuse.com/articles/55851/mmwave-radar-principle-applications.html">Understanding
            mmWave RADAR, its Principle &amp; Applications</a></p>
            <p>For programming a LiDAR, see: <a
            href="h.ttps://www.engineersgarage.com/how-to-use-a-lidar-sensor-with-arduino/">how
            to program a LiDAR with an Arduino</a>.</p>
            </section>
            </section>
            <section id="ultrasonic" class="level3" data-number="3.1.3">
            <h3 data-number="3.1.3"><span
            class="header-section-number">3.1.3</span> Ultrasonic</h3>
            <p>Much like lidars, we can use reflected sounds waves to
            detect objects. They work by emitting high-frequency sound
            waves, typically above human hearing, and then listening for
            the echoes that bounce back from nearby objects. The sensor
            calculates the distance based on the time it takes for the
            echo to return, using the speed of sound. Popular modules
            like the HC-SR04 (Used in Lab#2) are easy to integrate with
            microcontrollers such as Arduino and Raspberry Pi. These
            sensors are widely used in robotics for obstacle avoidance,
            automated navigation, and liquid level sensing.</p>
            <p>However, unlike optical (electromagnetic waves)
            detectors, ultrasonic sensors, while useful for basic
            distance measurements, cannot replicate the functionalities
            of LiDAR systems due to several key limitations. Unlike
            LiDAR, which employs laser beams to generate
            high-resolution, three-dimensional point clouds, ultrasonic
            sensors emit sound waves that provide only limited,
            single-point distance data with lower precision. LiDAR
            offers greater accuracy and longer range, enabling detailed
            mapping and object recognition essential for applications
            like autonomous vehicles and advanced robotics.
            Additionally, LiDAR systems can cover a wider field of view
            and operate effectively in diverse environments by rapidly
            scanning multiple directions, whereas ultrasonic sensors
            typically have a narrow detection cone and struggle with
            complex or cluttered scenes. Furthermore, LiDAR’s ability to
            capture data at high speeds allows for real-time processing
            and dynamic obstacle detection, which ultrasonics cannot
            match. This is because comparitively, it sounds waves take a
            lot of time to return since they’re much slower in speed
            compared to light waves (360m/s vs 299,792,458m/s). These
            differences in data richness, accuracy, and versatility make
            ultrasonic sensors unsuitable substitutes for the
            sophisticated capabilities offered by LiDAR technology.</p>
            <p>We’ll be using ultrasonic distance finders in futures MPs
            to stop our rovers from colliding into objects. Since our
            rovers don’t moove to fast and complexity is relatively low,
            only a ultrasonic sensor would suffice.</p>
            </section>
            </section>
            <section id="errors-in-sensing" class="level2"
            data-number="3.2">
            <h2 data-number="3.2"><span
            class="header-section-number">3.2</span> Errors in
            Sensing</h2>
            <p>Since sensors deal with and measure the <em>physical</em>
            world, <strong>errors</strong> will creep in over time.</p>
            <p>Some typical errors in the use of physical sensors:</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 44%" />
            </colgroup>
            <thead>
            <tr>
            <th>error type</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>sensor drift</strong></td>
            <td>over time the sensor measurements will “drift”, i.e., a
            gradual change in its output → away from average values
            (e.g., due to wear and tear)</td>
            </tr>
            <tr>
            <td><strong>constant bias</strong></td>
            <td>bias of an accelerometer is the offset of its output
            signal from the actual acceleration value. A constant bias
            error causes an error in position which grows with time</td>
            </tr>
            <tr>
            <td><strong>calibration errors</strong></td>
            <td>‘calibration errors’ refers to errors in the scale
            factors, alignments and linearities of the gyros. Such
            errors tend to produce errors when the device is turning.
            These errors can result in additional drift</td>
            </tr>
            <tr>
            <td><strong>scale factor</strong></td>
            <td>scale factor is the relation of the accelerometer input
            to the actual sensor output for the measurement. Scale
            factor, expressed in ppm, is therefore the linear growth of
            input variation to actual measurement</td>
            </tr>
            <tr>
            <td><strong>vibration rectification errors</strong></td>
            <td>vibration rectification error (VRE) is the response of
            an accelerometer to current rectification in the sensor,
            causing a shift in the offset of the accelerometer. This can
            be a significant cumulative error, which propagates with
            time and can lead to over compensation in stabilization</td>
            </tr>
            <tr>
            <td><strong>noise</strong></td>
            <td>random variations in the sensor output that do not
            correspond to the actual measured value</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Each error type must be dealt with in different ways
            though one of the commomn ways to prevent sensor errors from
            causing harm to autonomous systems → <strong>sensor
            fusion</strong>, <em>i.e.,</em> use information from
            <strong>multiple sensors</strong> before making any
            decisions. We will dicuss sensor fusion later in this
            course.</p>
            </section>
            <section id="analog-to-digital-convertors-adcs"
            class="level2" data-number="3.3">
            <h2 data-number="3.3"><span
            class="header-section-number">3.3</span> Analog to Digital
            Convertors (ADCs)</h2>
            <p>As <a href="#sensors-and-sensing">mentioned earlier</a>,
            a sensor maps a physical quantity from the time domain to
            the value domain,</p>
            <p><span
            class="math display"><em>s</em> : <em>D</em><sub><em>t</em></sub> ↦ <em>D</em><sub><em>v</em></sub></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>t</em></sub></span></td>
            <td>continuous or discrete <strong>time</strong> domain</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>v</em></sub></span></td>
            <td>continuous or discrete <strong>value</strong>
            domain</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Remember that computers require <strong>discrete</strong>
            sequences of physical values since <strong>microcontrollers
            cannot read values unless it is digital data</strong>.
            Microcontrollers can only see “levels” of voltage, which
            depends on the resolution of the ADC and the system
            voltage.</p>
            <p>Hence, we need to <strong>convert</strong> the above into
            the discrete domain, <em>i.e.,</em> we require <span
            class="math inline"><em>D</em><sub><em>v</em></sub></span>
            to be composed of discrete values.</p>
            <p>According to <a
            href="https://en.wikipedia.org/wiki/Discrete_time_and_continuous_time#">Wikipedia</a>,</p>
            <blockquote>
            <p>A discrete signal or discrete-time signal is a time
            series consisting of a sequence of quantities. Unlike a
            continuous-time signal, a discrete-time signal is not a
            function of a continuous argument; however, it may have been
            obtained by sampling from a continuous-time signal. When a
            discrete-time signal is obtained by sampling a sequence at
            uniformly spaced times, it has an associated
            <strong>sampling rate</strong>.</p>
            </blockquote>
            <p><br></p>
            <p>A visual respresentation of the sampling rate and how it
            correlates to the sampling of an analog signal:</p>
            <table>
            <colgroup>
            <col style="width: 38%" />
            <col style="width: 38%" />
            <col style="width: 23%" />
            </colgroup>
            <thead>
            <tr>
            <th>analog signal</th>
            <th>sampling rate</th>
            <th>sampling</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/sensors/adc_analog_signal.png"></td>
            <td><img src="img/sensors/adc_sampling_rate.png"></td>
            <td><img src="img/sensors/adc_sampling.png"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, a device that converts analog signals to digital
            data values is called → an <strong>analog-to-digital
            convertor</strong> (<strong>ADC</strong>). This is one of
            the most common circuits/microcontrollers in embedded (and
            hence, autonomous) systems. <em>Any</em> sensor that
            measures a physical property must pass its values through an
            ADC so that the sensor values can be used by the system (the
            embedded processor/microcontroller, really).</p>
            <p>This is best described using an example:</p>
            <p><img src="img/sensors/adc_example.jpg" width="400"></p>
            <p>The <font color="blue"><b>analog</b></font> signal is
            <strong>discretized</strong> into the
            <font color="red"><b>digital</b></font> signal after passing
            through an ADC.</p>
            <p>ADCs follow a sequence:</p>
            <ul>
            <li><strong>sample</strong> the signal</li>
            <li><strong>quantify</strong> it to determine the resolution
            of the signal</li>
            <li>set <strong>binary values</strong></li>
            <li><strong>send it to the system</strong> to read the
            digital signal</li>
            </ul>
            <p>Hence, two important aspects of an ADC are:</p>
            <ul>
            <li><a href="#adc-sampling-rate">sampling rate</a></li>
            <li><a href="#adc-resolution">resolution</a></li>
            </ul>
            <section id="adc-sampling-rate" class="level3"
            data-number="3.3.1">
            <h3 data-number="3.3.1"><span
            class="header-section-number">3.3.1</span> ADC Sampling
            Rate</h3>
            <p>The sampling rate (aka Sampling Frequency) is measured in
            <strong>samples per second</strong> (SPS or S/s). It
            dictates <em>how many samples</em> (data points) are taken
            in one second. If an ADC records more samples, then it can
            handle higher frequencies.</p>
            <p>The sample rate, <span
            class="math inline"><em>f</em><sub><em>s</em></sub></span>
            is defined as,</p>
            <p><span
            class="math display"><em>f</em><sub><em>s</em></sub> = <em>r</em><em>a</em><em>c</em>1<em>T</em></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>definition</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>s</em></sub></span></td>
            <td>sampling rate/frequency</td>
            </tr>
            <tr>
            <td><span class="math inline"><em>T</em></span></td>
            <td>period of the sample</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, in the previous example,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>value</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>s</em></sub></span></td>
            <td><code>20 Hz</code></td>
            </tr>
            <tr>
            <td><span class="math inline"><em>T</em></span></td>
            <td><code>50 ms</code></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>While this looks slow (<code>20 Hz</code>), the digital
            signal tracks the original analog signal quite faithfully →
            the original signal itself is quite slow
            (<code>1 Hz</code>).</p>
            <p>Now, if the sampling signal is <em>considerably
            slower</em> than the analog signal, then it loses fidelity
            and we see <strong>aliasing</strong>, where the
            reconstructed signal (the digital one in the case)
            <strong>differs from the original</strong>. Consider the
            following example of such a case:</p>
            <p><img src="img/sensors/adc_aliasing_example.jpg" width="400"></p>
            <p>As we see from the above figure, the digital output is
            <strong>nothing</strong> like the original. Hence, this
            (digital) output will not be of much use to the system.</p>
            <p><br></p>
            <p><a
            href="https://fab.cba.mit.edu/classes/S62.12/docs/Shannon_noise.pdf"><strong>Nyquist-Shannon
            Sampling Theorem</strong></a>:</p>
            <blockquote>
            <p>to accurately reconstruct a signal from its samples, the
            sampling rate must be <strong>at least twice the highest
            frequency component</strong> present in the signal</p>
            </blockquote>
            <p>If the sampling frequency is less than the Nyquist rate,
            then aliasing starts to creep in.</p>
            <p>Hence,</p>
            <p><span
            class="math display"><em>f</em><sub><em>N</em><em>y</em><em>q</em><em>u</em><em>i</em><em>s</em><em>t</em></sub> = 2 * <em>f</em><sub><em>m</em><em>a</em><em>x</em></sub></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>definition</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>N</em><em>y</em><em>q</em><em>u</em><em>i</em><em>s</em><em>t</em></sub></span></td>
            <td>Nyquist sampling rate/frequency</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>m</em><em>a</em><em>x</em></sub></span></td>
            <td>the maximum frequency that appears in the signal</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>For instance, if your analog signal has a maximum
            frequency of <code>50 Hz</code> then your sampling frequency
            must be <em>at least</em>, <code>100 Hz</code>. If this
            principle is followed, then it is possible to
            <strong>accurately reconstruct</strong> the original signal
            and its values.</p>
            <p>Note that sometimes <em>noise</em> can introduce
            additonal (high) frequencies into the system but we don’t
            want to sample those (for obvious purposes). Hence, it is a
            good idea to add <a
            href="https://www.analog.com/en/resources/technical-articles/guide-to-antialiasing-filter-basics.html">anti-aliasing
            fitlers</a> to the analog signal <em>before</em> it is
            passed to the ADC.</p>
            </section>
            <section id="adc-resolution" class="level3"
            data-number="3.3.2">
            <h3 data-number="3.3.2"><span
            class="header-section-number">3.3.2</span> ADC
            Resolution</h3>
            <p>An ADC’s resolution is directly related to the
            <strong>precision</strong> of the ADC, determined by its
            <strong>bit length</strong>. The following examples shows
            the fidelity of the reconstruction, based on various bit
            lengths:</p>
            <p><img src="img/sensors/adc_resolution_example.jpg" width="400"></p>
            <p>Increasing bit lengths the digital signal more closely
            represents the analog one.</p>
            <p>There exists a correlation between the bit length and the
            <strong>voltage</strong> of the signal. Hence, the
            <strong>true resolution</strong> of the ADC is calculated
            using the bit length <strong>and</strong> the voltage as
            follows:</p>
            <p><span
            class="math display"><em>S</em><em>t</em><em>e</em><em>p</em><em>S</em><em>i</em><em>z</em><em>e</em> = <em>r</em><em>a</em><em>c</em><em>V</em><sub><em>r</em><em>e</em><em>f</em></sub><em>N</em></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>definition</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>S</em><em>t</em><em>e</em><em>p</em><em>S</em><em>i</em><em>z</em><em>e</em></span></td>
            <td>resolution of each level in terms of voltage</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>V</em><sub><em>r</em><em>e</em><em>f</em></sub></span></td>
            <td>voltage reference/range of voltages</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>N</em> = 2<sup><em>n</em></sup></span></td>
            <td>total “size” of the ADC</td>
            </tr>
            <tr>
            <td><span class="math inline"><em>n</em></span></td>
            <td>bit size</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>This is easier to understand with a concrete example:</p>
            <blockquote>
            <p>consider a sine wave with a voltage, <code>5 V</code>
            that must be digitized. <br> <br> If our ADC precision is
            <code>12 bits</code>, then we get <br> <span
            class="math inline"><em>N</em> = 2<sup>12</sup> = 4096</span>
            <br> <br> Hence, <span
            class="math inline"><em>S</em><em>t</em><em>e</em><em>p</em><em>S</em><em>i</em><em>z</em><em>e</em> = 5<em>V</em>/ 4096</span>
            which is <code>0.00122V</code> (or <code>1.22mV</code>)<br>
            <br> Hence, the system can tell when a voltage level changes
            by <code>1.22 mV</code>!</p>
            </blockquote>
            <p>(Repeat the exercise for say, bit length, <span
            class="math inline"><em>n</em> = 4</span>)</p>
            <p><br></p>
            <p><strong>Visual Example:</strong></p>
            <p>The above maybe intuitively understood as follows:</p>
            <p>Consider the following signal:</p>
            <p><img src="img/sensors/adc_bits/adc_bits.1.png" width="300"></p>
            <p>Now, if we want to sample this signal, we can obtain
            measurements at:</p>
            <p><img src="img/sensors/adc_bits/adc_bits.2.png" width="300"></p>
            <p><br></p>
            <p>The figure shows <code>9</code> measurements.</p>
            <p>Suppose, the ADC registers have a width of:
            <code>2 bits</code>. Hence it can store at most:
            <code>4 values</code>.</p>
            <p>Since is is <strong>not</strong> possible to store
            <code>9</code> values → <code>2</code> bits, we must select
            <strong>only <code>4</code> values</strong> omn the digital
            side.</p>
            <p>We then get the following representation:</p>
            <p><img src="img/sensors/adc_bits/adc_bits.3.png" width="300"></p>
            <p><br></p>
            <p>which, to be honest, is not really a good representation
            of the original signal!</p>
            <p>Now, consider the case where the ADC registers have a bit
            width: <strong><code>4 bits</code></strong> →
            <code>16 values</code>! Hence, we can easily store
            <strong>all <code>9 values</code></strong> easily.</p>
            <p>So, we can get a digital representation as follows:</p>
            <p><img src="img/sensors/adc_bits/adc_bits.4.png" width="300"></p>
            <p><br></p>
            <p>We see that this is a better representation, <em>but
            still not exact</em>. We can increase the bit length but at
            this point we are limited by the sampling as well. Since we
            only have <code>9</code> samples, adding more bits won’t
            help.</p>
            <p>Hence, to get a better fidelity representation of the
            original signal, we see that <strong>sampling
            frequency</strong> and <strong>resolution</strong> need to
            be increased, since they determine the quality of output we
            get from an ADC.</p>
            <p><strong>Resources</strong></p>
            <ul>
            <li>for more details about ADC, read: <a
            href="https://www.arrow.com/en/research-and-events/articles/engineering-resource-basics-of-analog-to-digital-converters">Analog-to-Digital
            Convertor Basics</a></li>
            <li>an <strong>in-depth</strong> explanation of how ADCs
            work: <a
            href="http://class.ece.iastate.edu/cpre288/lectures/lect12_13.pdf">Iowa
            State CpreE 288 Course Slides</a></li>
            <li>more details with videos: <a
            href="https://users.ece.utexas.edu/~valvano/Volume1/E-Book/C14_ADCdataAcquisition.htm">Analog
            to Digital Conversion, EE319K Univ. of Texas</a></li>
            <li>Programming an ADC: <a
            href="https://blog.embeddedexpert.io/?p=68">1</a>, <a
            href="https://labs.dese.iisc.ac.in/embeddedlab/tm4c123-adc-programming/">2</a>
            <!--link rel="stylesheet" href="./custom.sibin.css"--></li>
            </ul>
            </section>
            </section>
            </section>
            <section id="real-time-operating-systems" class="level1"
            data-number="4">
            <h1 data-number="4"><span
            class="header-section-number">4</span> Real-Time Operating
            Systems</h1>
            <p>Real-Time Operating Systems (RTOS) are specialized
            operating systems designed to manage hardware resources,
            execute applications and process data in a
            <strong>predictable</strong> manner. The main aim of this
            focus on “predictability” is to ensure that critical tasks
            complete in a <strong>timely</strong> fashion. Unlike
            general-purpose operating systems (GPOS) like Windows or
            Linux, which prioritize multitasking and user experience,
            RTOS focuses on meeting strict timing constraints, ensuring
            that tasks are completed within defined
            <strong>deadlines</strong>. This makes RTOS essential for
            systems where timing accuracy and reliability are critical,
            such as in embedded systems, autonomous driving, industrial
            automation, automotive systems, medical devices and
            aerospace applications, among others.</p>
            <p>Hence, real-time systems (RTS), and RTOSes in general,
            have <em>two</em> criteria for “correctness”:</p>
            <table>
            <colgroup>
            <col style="width: 23%" />
            <col style="width: 76%" />
            </colgroup>
            <thead>
            <tr>
            <th>criteria</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>functional</strong> correctness</td>
            <td>the system should work as expected, <em>i.e.</em>, carry
            out its intended function without errors</td>
            </tr>
            <tr>
            <td><strong>temporal</strong> correctness</td>
            <td>the functionally correct operations must be completed
            within a predefined timing constraint
            (<strong>deadline</strong>)</td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>To place ourselves in the context of this course, this is
            where we are:</p>
            <p><img src="img/stack_architecture/stack_overview.4.png" width="300"></p>
            <p><br></p>
            <p>We haven’t looked at the actuation part but we will come
            back to it later.</p>
            <section id="key-characteristics-for-rtos" class="level3"
            data-number="4.0.1">
            <h3 data-number="4.0.1"><span
            class="header-section-number">4.0.1</span> Key
            characteristics for RTOS</h3>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 44%" />
            </colgroup>
            <thead>
            <tr>
            <th>characteristic</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>determinism</strong></td>
            <td>primary feature of an RTOS is its ability to perform
            tasks within guaranteed time frames; this predictability
            ensures that high-priority tasks are executed without delay,
            even under varying system loads</td>
            </tr>
            <tr>
            <td><strong>task scheduling</strong></td>
            <td>RTOS uses advanced scheduling algorithms (e.g.,
            priority-based, round-robin or earliest-deadline-first) to
            manage task execution; RT tasks are often assigned
            priorities and the scheduler ensures that higher-priority
            tasks preempt lower-priority ones when necessary</td>
            </tr>
            <tr>
            <td><strong>low latency</strong></td>
            <td>RTOS minimizes interrupt response times and
            context-switching overhead, enabling rapid task execution
            and efficient handling of time-sensitive operations
            (<em>e.g.</em>, Linux spends <strong>many
            milliseconds</strong> handling interrupts such as disk
            access!)</td>
            </tr>
            <tr>
            <td><strong>resource management</strong></td>
            <td>RTOS provides mechanisms for efficient allocation and
            management of system resources, such as memory, CPU and
            peripherals, to ensure optimal performance</td>
            </tr>
            <tr>
            <td><strong>scalability</strong></td>
            <td>RTOS is often lightweight and modular, making it
            suitable for resource-constrained environments like
            microcontrollers and embedded systems</td>
            </tr>
            <tr>
            <td><strong>reliability and fault tolerance</strong></td>
            <td>many RTOS implementations include features to enhance
            system stability, such as error detection, recovery
            mechanisms and redundancy</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="kernels-in-rtos" class="level2"
            data-number="4.1">
            <h2 data-number="4.1"><span
            class="header-section-number">4.1</span> Kernels in
            RTOS</h2>
            <p>As with most operating systems, the kernel provides the
            essential services in an RTOS. In hard real-time systems,
            the kernel must guarantee predictable and deterministic
            behavior to ensure that all tasks meet their deadlines. In
            this chapter we focus on kernel aspects that are
            <em>specific to RTS</em>.</p>
            <p>The RTOS kernel deals with,</p>
            <ol type="1">
            <li><a href="#tasks-jobs-threads">task management</a></li>
            <li><a
            href="#inter-task-communication-and-synchronization">communication
            and synchronization</a></li>
            <li><a href="#memory-management">memory management</a></li>
            <li><a href="#timer-and-interrupt-management">timer and
            interrupt handling</a></li>
            <li><a href="#kernel-performance-metrics">performance
            metrics</a></li>
            </ol>
            <section id="tasks-jobs-threads" class="level3"
            data-number="4.1.1">
            <h3 data-number="4.1.1"><span
            class="header-section-number">4.1.1</span> Tasks, Jobs,
            Threads</h3>
            <p>The design of RTOSes (and RTS in general) deal with
            <strong>tasks</strong>, <strong>jobs</strong> and, for
            implementation-specific details,
            <strong>threads</strong>.</p>
            <p>A real-time <strong>task</strong>, <span
            class="math inline"><em>τ</em><sub><em>i</em></sub></span>
            is defined using the following parameters: <span
            class="math inline">(<em>ϕ</em><sub><em>i</em></sub>, <em>p</em><sub><em>i</em></sub>, <em>c</em><sub><em>i</em></sub>, <em>d</em><sub><em>i</em></sub>)</span>
            where,</p>
            <table>
            <thead>
            <tr>
            <th>Symbol</th>
            <th>Description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>ϕ</em><sub><em>i</em></sub></span></td>
            <td>Phase (offset for the first job of a task)</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>p</em><sub><em>i</em></sub></span></td>
            <td>Period</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>c</em><sub><em>i</em></sub></span></td>
            <td>Worst-case execution time</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>d</em><sub><em>i</em></sub></span></td>
            <td>Deadline</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, a real-time tast <em>set</em> (of size
            ‘<em>n</em>’) is collection of such tasks, <em>i.e.,</em>
            <span
            class="math inline"><em>τ</em> = <em>τ</em><sub>1</sub>, <em>τ</em><sub>2</sub>, ...<em>τ</em><sub><em>n</em></sub></span>.
            Given a real-time task set, the <em>first</em> step is to
            check if the task set is <strong>schedulable</strong>,
            <em>i.e.,</em> check whether all <strong>jobs</strong> of a
            task will meet their deadlines (a <strong>job</strong> is an
            <strong>instance</strong> of a task). For this purpose,
            multiple <strong>schedulability tests</strong> have been
            developed, each depending on the scheduling algorithm being
            used.</p>
            <blockquote>
            <ul>
            <li>remember that task is a set of parameters.</li>
            <li>We “release” multiple “<em>jobs</em>” of each task, each
            with its own deadline</li>
            <li>if all jobs of all tasks meet their deadlines, then the
            system remains <em>safe</em>.</li>
            </ul>
            </blockquote>
            <p>A <strong>thread</strong>, then, is an
            <strong>implementation</strong> of task/job – depending on
            the actual OS, it could be either, or both.</p>
            <p>At a high level, here is a comparison between tasks, jobs
            and threads (<strong>note:</strong> these details may vary
            depending on the <em>specific</em> RTOS):</p>
            <table>
            <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 18%" />
            <col style="width: 30%" />
            </colgroup>
            <thead>
            <tr>
            <th><strong>aspect</strong></th>
            <th><strong>task</strong></th>
            <th><strong>job</strong></th>
            <th><strong>thread</strong></th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>definition</strong></td>
            <td>a task is a <strong>unit of work</strong> that
            represents a program or function executing in the RTOS</td>
            <td>a job is a <strong>specific instance</strong> or
            execution of a task, often tied to a particular event or
            trigger</td>
            <td>a thread is the <strong>smallest unit of
            execution</strong> within a task, sharing the task’s
            resources</td>
            </tr>
            <tr>
            <td><strong>granularity</strong></td>
            <td>coarse-grained; represents a complete function or
            program</td>
            <td>fine-grained; represents a single execution of a
            task</td>
            <td>fine-grained; represents a single flow of execution
            within a task</td>
            </tr>
            <tr>
            <td><strong>resource ownership</strong></td>
            <td>owns its resources (e.g., stack, memory, state)</td>
            <td>does not own resources; relies on the task’s
            resources</td>
            <td>shares resources (e.g., memory, address space) with
            other threads in the same task</td>
            </tr>
            <tr>
            <td><strong>scheduling</strong></td>
            <td>scheduled by the RTOS kernel based on priority or
            scheduling algorithm</td>
            <td>not directly scheduled; executed as part of a task’s
            execution</td>
            <td>scheduled by the RTOS kernel, often within the context
            of a task</td>
            </tr>
            <tr>
            <td><strong>concurrency</strong></td>
            <td>tasks run concurrently, managed by the RTOS
            scheduler</td>
            <td>jobs are sequential within a task but may overlap across
            tasks</td>
            <td>threads run concurrently, even within the same task</td>
            </tr>
            <tr>
            <td><strong>state management</strong></td>
            <td>maintains its own state (e.g., ready, running,
            blocked)</td>
            <td>state is transient and tied to the task’s execution</td>
            <td>maintains its own state but shares the task’s overall
            context</td>
            </tr>
            <tr>
            <td><strong>isolation</strong></td>
            <td>high isolation; tasks do not share memory or resources
            by default <strong>++</strong></td>
            <td>no isolation; jobs are part of a task’s execution</td>
            <td>low isolation; threads share memory and resources within
            a task</td>
            </tr>
            <tr>
            <td><strong>overhead</strong></td>
            <td>higher overhead due to separate stacks and contexts</td>
            <td>minimal overhead, as it relies on the task’s
            resources</td>
            <td>moderate overhead, as threads share resources but
            require context switching</td>
            </tr>
            <tr>
            <td><strong>use case</strong></td>
            <td>used to model independent functions or processes (e.g.,
            control loops)</td>
            <td>used to represent a single execution of a task (e.g.,
            processing a sensor reading)</td>
            <td>used to parallelize work within a task (e.g., handling
            multiple i/o operations)</td>
            </tr>
            <tr>
            <td><strong>example</strong></td>
            <td>a task for controlling a motor</td>
            <td>a job for processing a specific motor command</td>
            <td>a thread for reading sensor data while another thread
            logs the data</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>(<strong>++</strong> sometimes tasks <strong>do</strong>
            contend for resources, so we need to mitigate access to
            them, via locks, semaphores, etc. and then have to deal with
            thorny issues such as <strong>priority
            inversions</strong>)</p>
            <p>A task is often described using a <strong>task control
            block</strong> (TCB):</p>
            <p><img src="img/rtos/tcb_sequence_png/tcb_12.png"></p>
            <p>Tasks typically cycle through a set of states, for
            instance (taken from the <a
            href="https://www.freertos.org/Documentation/02-Kernel/02-Kernel-features/01-Tasks-and-co-routines/02-Task-states">FreeRTOS</a>
            real-time OS):</p>
            <p><img src="img/rtos/free_rtos/freertos_taskstate.gif" width="300"></p>
            <p><br></p>
            <p>While the <code>READY</code>, <code>RUNNING</code> and
            <code>BLOCKED</code> states are similar to those in
            general-purpose operating systems (GPOS), <em>periodic</em>
            RTOSes must introduce an additional state:
            <strong><code>IDLE</code></strong> or
            <strong><code>SUSPENDED</code></strong>:</p>
            <ul>
            <li>periodic task enters this state when it (rather one
            ‘job’) completes its execution → has to wait for the
            beginning of the next period</li>
            <li>to be awakened by the timer (<em>i.e.,</em> to launch
            the next instance/job), the task must notify the end of its
            cycle by executing a specific system call,
            <code>end cycle</code> → puts the job in the IDLE state and
            assigns the processor to another ready job</li>
            <li>at the right time, each periodic task in IDLE state →
            awakened by kernel and inserted in the ready queue</li>
            </ul>
            <p>This operation is carried out by a routine
            <strong>activated by a timer</strong> → verifies, at each
            tick, whether some task(job) has to be awakened.</p>
            <p>TCBs are usually managed in kernel
            <strong>queues</strong> (the implementation details may vary
            depending on the particular RTOS).</p>
            <p><strong>Context Switch Overheads</strong>:</p>
            <p>One of the main issues with multitasking and preepmtion
            is that of <strong>context switch overheads</strong>,
            <em>i.e.,</em> the time and resources required to switch
            from one task to another. For instance, consider this
            example of two tasks running on an ARM Cortex-M4:</p>
            <div class="sourceCode" id="cb5"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> Task1<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Task 1 operations</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        LED_Toggle<span class="op">();</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        delay_ms<span class="op">(</span><span class="dv">100</span><span class="op">);</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>and</p>
            <div class="sourceCode" id="cb6"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> Task2<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Task 2 operations</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        ReadSensor<span class="op">();</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        delay_ms<span class="op">(</span><span class="dv">200</span><span class="op">);</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>When switching between Task1 and Task2, an RTOS might
            need to:</p>
            <ul>
            <li>save <code>16</code> general-purpose registers</li>
            <li>save the program counter and stack pointer</li>
            <li>update the memory protection unit settings</li>
            <li>load the new task’s context (program into memory,
            registers, cache, <em>etc.</em>)</li>
            </ul>
            <p>So, on the ARM Cortex-M4,</p>
            <table>
            <colgroup>
            <col style="width: 38%" />
            <col style="width: 61%" />
            </colgroup>
            <thead>
            <tr>
            <th>effect</th>
            <th>cost</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>basic context switch</td>
            <td><code>200-400</code> CPU cycles</td>
            </tr>
            <tr>
            <td>cache and pipeline effects, total overhead</td>
            <td><code>1000+</code> cycles</td>
            </tr>
            <tr>
            <td>frequent switching (e.g., every <code>1 ms</code>)</td>
            <td>could consume <code>1-2%</code> of CPU time!</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>These costs can add up, especially if the system has,</p>
            <ul>
            <li>many RT tasks and frequent
            <strong>preemption</strong></li>
            <li>high-frequency/short period jobs that execute
            frequently</li>
            <li>if tasks contend with each other for shared
            resources</li>
            </ul>
            <p>Hence and RTOS must not only be cognizant of such
            overheads but also <strong>actively manage/mitigate</strong>
            them. Some strategies could include:</p>
            <ol type="1">
            <li><strong>better task/schedule design</strong>:
            <em>e.g.,</em> group related operations to reduce context
            switches</li>
            </ol>
            <div class="sourceCode" id="cb7"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> Task_Sensors<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Handle multiple sensors in one task</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        ReadTemperature<span class="op">();</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        ReadPressure<span class="op">();</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        ReadHumidity<span class="op">();</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        delay_ms<span class="op">(</span><span class="dv">500</span><span class="op">);</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="2" type="1">
            <li><strong>priority-based scheduling</strong>:
            <em>e.g.,</em> high priority task gets more CPU</li>
            </ol>
            <div class="sourceCode" id="cb8"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> CriticalTask<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Set high priority</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    setPriority<span class="op">(</span>HIGH_PRIORITY<span class="op">);</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        ProcessCriticalData<span class="op">();</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        delay_ms<span class="op">(</span><span class="dv">50</span><span class="op">);</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="3" type="1">
            <li><strong>optimizing memory layouts</strong>:
            <em>e.g.</em>, align task stacks to cache line
            boundaries</li>
            </ol>
            <div class="sourceCode" id="cb9"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#define STACK_SIZE </span><span class="dv">1024</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="dt">static</span> __attribute__<span class="op">((</span>aligned<span class="op">(</span><span class="dv">32</span><span class="op">)))</span> </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="dt">uint8_t</span> task1_stack<span class="op">[</span>STACK_SIZE<span class="op">];</span></span></code></pre></div>
            <p><strong>Note:</strong> these are not comprehensive and
            other strategies could be followed, for instance
            <strong>avoiding multitasking altogether</strong>! All
            functions could be implemented in a <strong>single</strong>
            process that runs a giant, infinite loop known as a <a
            href="https://my.eng.utah.edu/~cs5785/slides-f10/22-1up.pdf"><strong>cyclic
            executive</strong></a>. Newer RTOSes shun ths cyclic
            executive in favor of the multitasking model since the
            latter provides more flexibility, control and adaptability
            but many critical systems (especially older, long-running
            ones) still use the cyclic executive. For instance, nuclear
            reactors, chemical plants, <em>etc.</em></p>
            <p>In any case, a <strong>precise</strong> understanding of
            these overheads is crucial for:</p>
            <ul>
            <li>setting appropriate task priorities</li>
            <li>determining minimum task periods</li>
            <li>calculating worst-case execution times</li>
            <li>meeting real-time deadlines</li>
            <li>optimizing system performance</li>
            </ul>
            <p>There is significant (ongoing) work, both in industry as
            well as academia, on how to get a handle on context switch
            overheads while still allowing for flexibility and
            modularity in the development of RTS.</p>
            </section>
            <section id="inter-task-communication-and-synchronization"
            class="level3" data-number="4.1.2">
            <h3 data-number="4.1.2"><span
            class="header-section-number">4.1.2</span> (Inter-Task)
            Communication and Synchronization</h3>
            <p>RTOSes use various mechanisms like semaphores, mutexes,
            message queues and event flags for communication and
            synchronization between tasks. Here are some examples:</p>
            <ol type="1">
            <li><strong>Semaphores</strong>:</li>
            </ol>
            <ul>
            <li>binary semaphores: work like a mutex, with values 0 or
            1</li>
            <li>counting semaphores: can have multiple values, useful
            for managing resource pools</li>
            </ul>
            <div class="sourceCode" id="cb10"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Example of binary semaphore usage</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>semaphore_t sem<span class="op">;</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>sem_init<span class="op">(&amp;</span>sem<span class="op">,</span> <span class="dv">1</span><span class="op">);</span>  <span class="co">// Initialize with 1</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> TaskA<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        sem_wait<span class="op">(&amp;</span>sem<span class="op">);</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Critical section</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        accessSharedResource<span class="op">();</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        sem_post<span class="op">(&amp;</span>sem<span class="op">);</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="2" type="1">
            <li><strong>Mutexes</strong> (mutual exclusion):</li>
            </ol>
            <ul>
            <li>mutexes provide exclusive access to shared
            resources</li>
            <li>they include <strong>priority inheritance</strong> to
            prevent <strong>priority inversion</strong></li>
            </ul>
            <div class="sourceCode" id="cb11"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>mutex_t mutex<span class="op">;</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>mutex_init<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> TaskB<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    mutex_lock<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Protected shared resource access</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    updateSharedData<span class="op">();</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    mutex_unlock<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="3" type="1">
            <li><strong>Message Queues</strong>:</li>
            </ol>
            <ul>
            <li>they allow <strong>ordered data transfer</strong>
            between tasks</li>
            <li>provide for buffering capabilities</li>
            </ul>
            <div class="sourceCode" id="cb12"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>queue_t msgQueue<span class="op">;</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>queue_create<span class="op">(&amp;</span>msgQueue<span class="op">,</span> MSG_SIZE<span class="op">,</span> MAX_MSGS<span class="op">);</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> SenderTask<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    message_t msg <span class="op">=</span> prepareMessage<span class="op">();</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    queue_send<span class="op">(&amp;</span>msgQueue<span class="op">,</span> <span class="op">&amp;</span>msg<span class="op">,</span> TIMEOUT<span class="op">);</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> ReceiverTask<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    message_t msg<span class="op">;</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    queue_receive<span class="op">(&amp;</span>msgQueue<span class="op">,</span> <span class="op">&amp;</span>msg<span class="op">,</span> TIMEOUT<span class="op">);</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    processMessage<span class="op">(&amp;</span>msg<span class="op">);</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="4" type="1">
            <li><strong>Event Flags</strong>:</li>
            </ol>
            <ul>
            <li>enable <strong>multiple tasks</strong> to wait for one
            or more events</li>
            <li>support <code>AND</code>/<code>OR</code> conditions for
            event combinations</li>
            </ul>
            <div class="sourceCode" id="cb13"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>event_flags_t events<span class="op">;</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#define EVENT_SENSOR_DATA </span><span class="bn">0x01</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#define EVENT_USER_INPUT  </span><span class="bn">0x02</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> TaskC<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Wait for both events</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    event_wait<span class="op">(&amp;</span>events<span class="op">,</span> EVENT_SENSOR_DATA <span class="op">|</span> EVENT_USER_INPUT<span class="op">,</span> </span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>               EVENT_ALL<span class="op">,</span> TIMEOUT<span class="op">);</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    processEvents<span class="op">();</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="5" type="1">
            <li><strong>Condition Variables</strong>:</li>
            </ol>
            <ul>
            <li>tasks can wait for <strong>specific
            conditions</strong></li>
            <li>used with mutexes for complex synchronization</li>
            </ul>
            <div class="sourceCode" id="cb14"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>mutex_t mutex<span class="op">;</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>cond_t condition<span class="op">;</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> ConsumerTask<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    mutex_lock<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span>bufferEmpty<span class="op">())</span> <span class="op">{</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        cond_wait<span class="op">(&amp;</span>condition<span class="op">,</span> <span class="op">&amp;</span>mutex<span class="op">);</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    processData<span class="op">();</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    mutex_unlock<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p><br></p>
            <p>Each mechanism has specific use cases:</p>
            <table>
            <thead>
            <tr>
            <th>mechanism</th>
            <th>use case</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>semaphores</strong></td>
            <td>resource management and simple synchronization</td>
            </tr>
            <tr>
            <td><strong>mutexes</strong></td>
            <td>exclusive access to shared resources</td>
            </tr>
            <tr>
            <td><strong>message queues</strong></td>
            <td>data exchange and task communication</td>
            </tr>
            <tr>
            <td><strong>event flags</strong></td>
            <td>multiple event synchronization</td>
            </tr>
            <tr>
            <td><strong>condition variables</strong></td>
            <td>complex state-dependent synchronization</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Common considerations:</p>
            <ol type="1">
            <li>Priority Inversion Prevention: a high-priority (HP) task
            is <strong>indirectly preempted</strong> by a lower-priority
            (LP) task; HP → needs resource (R); R held by → LP, LP
            preempted by medium-priority (MP) task. So <strong>HP waits
            for MP</strong> → inversion of priorities! We will discuss
            solutions (priority inheritance/priority ceiling)
            later.</li>
            <li>Deadlock Avoidance: tasks are *permanently blocked**
            waiting on resources from each other; <span
            class="math inline"><em>τ</em><sub>1</sub></span> holds
            resource <span
            class="math inline"><em>R</em><sub><em>A</em></sub></span>
            and waits for <span
            class="math inline"><em>R</em><sub><em>B</em></sub></span>;
            <span class="math inline"><em>τ</em><sub>2</sub></span>
            holds resource <span
            class="math inline"><em>R</em><sub><em>B</em></sub></span>
            and waits for <span
            class="math inline"><em>R</em><sub><em>A</em></sub></span>.</li>
            <li>Timeout Handling: <em>every</em> synchronization
            mechanism should have a <strong>timeout</strong> to avoid
            indefinite blocking of critical tasks.</li>
            <li>Error Handling: detecting errors and handling them in a
            <strong>robust</strong> manner is critical to maintain
            system reliability; RTOSes use <em>retry mechanisms</em>,
            <em>logging</em> and, most importantly, have <strong>clear
            recovery procedures</strong> for failure scenarios.</li>
            </ol>
            <p>These considerations are crucial for ensuring system
            reliability, maintaining real-time performance, preventing
            system deadlocks, managing system resources effectively and
            handling error conditions gracefully.</p>
            </section>
            <section id="memory-management" class="level3"
            data-number="4.1.3">
            <h3 data-number="4.1.3"><span
            class="header-section-number">4.1.3</span> Memory
            Management</h3>
            <p>Real-time systems require <strong>predictable memory
            allocation and deallocation</strong> to avoid delays or
            fragmentation. Hence, they often use <strong>limited memory
            management techniques</strong> often eschewing even the use
            of dynamic memory allocation in favor of <strong>static
            memory allocation</strong>. For instance, many RTS don’t
            even use <code>malloc()</code> or <code>new</code>
            (<em>i.e.,</em> no heap allocated memory) and very often
            avoid garbage collection. The main goal is for tight control
            of the memory management → this makes <em>timing behavior
            more predictable</em>. Hence, the following become
            easier:</p>
            <ul>
            <li>wcet analysis</li>
            <li>schedulability and other analyses</li>
            <li>runtime monitoring and management</li>
            <li>recovery/restart</li>
            </ul>
            <p>Some <strong>goals</strong> for memory management in
            RTOSes:</p>
            <ol type="1">
            <li>predictable execution times for memory operations</li>
            <li>fast allocation/deallocation</li>
            <li>minimal fragmentation, if any</li>
            <li>protection mechanisms between tasks</li>
            </ol>
            <p>In fact, to achieve these goals, many RTSes <strong>don’t
            even use caches</strong> since they can be a major source of
            non-determinism in terms of timing behavior,
            <em>e.g.,</em></p>
            <blockquote>
            <p>if we cannot <strong>exactly calculate</strong> when some
            data/code will hit/miss in cache, then we cannot estimate
            its true timing behavior, leading to a lot of uncertainty →
            <strong>bad</strong>!</p>
            </blockquote>
            <p>Some RTSes use <a
            href="http://www.irisa.fr/alf/downloads/puaut/papers/date07.pdf"><strong>scratchpads</strong></a>
            since they provide cache-like performance but have higher
            predictability since the data onboarding/offloading is
            <strong>explicitly managed</strong> (either by the program
            or the <a
            href="https://cs-people.bu.edu/rmancuso/files/papers/SPM-OS_RTSJ19.pdf">RTOS</a>).</p>
            <p><strong>Some common memory-management techniques for
            RTOSes</strong>:</p>
            <ol type="1">
            <li><strong>static memory allocation</strong>: all memory
            used is allocated/deallocated at <strong>compile
            time</strong>.</li>
            <li><strong>memory pools</strong>: fixed-size blocks are
            pre-allocated for specific purposes → fragmentation and
            provides deterministic allocation times.</li>
            <li><strong>careful stack management</strong>: careful
            sizing/placing/management of the stack</li>
            <li><strong>limited heap memory</strong>: using “safe”
            versions of <code>malloc()</code> for instance</li>
            <li><strong>memory protection</strong>: using hardware such
            as memory protection units (MPUs)</li>
            <li><strong>memory partitioning</strong>: explicitly
            partition memory/caches so that tasks cannot read/write in
            each others’ memory regions</li>
            <li><strong>runtime mechanisms</strong>: such as memory
            usage monitoring, leak detection and managing the
            fragmentation</li>
            </ol>
            <blockquote>
            <p>Of course, each of these mechanisms have their own
            problems and a deliberation on those is left as an exercise
            for the reader.</p>
            </blockquote>
            </section>
            <section id="timer-and-interrupt-management" class="level3"
            data-number="4.1.4">
            <h3 data-number="4.1.4"><span
            class="header-section-number">4.1.4</span> Timer and
            Interrupt Management</h3>
            <p>Timer and interrupt management are crucial components of
            an RTOS, ensuring that tasks are <strong>executed at precise
            intervals</strong> and that the system responds promptly to
            (internal and) external events. The role between timers and
            interrupts is closely related, since they offer the very
            <strong>basic</strong> timing mechanism in RTOSes (from <a
            href="https://link.springer.com/book/10.1007/978-1-4614-0676-1">Hard
            Real-Time Computing Systems: Predictable Scheduling
            Algorithms and Applications</a>):</p>
            <blockquote>
            <p>to generate a <strong>time reference</strong>, a timer
            circuit is programmed to interrupt the processor at a
            <strong>fixed rate</strong> and the internal system time is
            represented by an integer variable, which is reset at system
            initialization and is incremented at each <strong>timer
            interrupt</strong>. The interval of time with which the
            timer is programmed to interrupt defines the unit of time in
            the system; that is, the minimum interval of time handled by
            the kernel (time resolution). The unit of time in the system
            is also called a system
            <strong><code>tick</code></strong>.</p>
            </blockquote>
            <p><br></p>
            <p>Timers, in general, play important roles in such systems,
            <em>viz.,</em></p>
            <table>
            <thead>
            <tr>
            <th>role</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>task scheduling</strong></td>
            <td>enable periodic execution of tasks</td>
            </tr>
            <tr>
            <td><strong>timeout management</strong></td>
            <td>prevent indefinite blocking of resources</td>
            </tr>
            <tr>
            <td><strong>event timing</strong></td>
            <td>measure intervals between events</td>
            </tr>
            <tr>
            <td><strong>system timing</strong></td>
            <td>maintain system clock and timestamps</td>
            </tr>
            <tr>
            <td><strong>watchdog functions</strong></td>
            <td>monitor system health and detect lockups</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Typically these systems have the following <em>three</em>
            types of timers:</p>
            <table>
            <colgroup>
            <col style="width: 29%" />
            <col style="width: 70%" />
            </colgroup>
            <thead>
            <tr>
            <th>type</th>
            <th>properties</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>hardware</strong></td>
            <td>- direct access to hardware timing resources<br>-
            highest precision and accuracy<br>- limited in number
            (hardware dependent)<br>- used for critical timing
            functions</td>
            </tr>
            <tr>
            <td><strong>software</strong></td>
            <td>- implemented in software, using hardware timer as
            base<br>- more flexibility, less precise<br>- limited only
            by memory<br>- more suitable for non-critical timing
            functions</td>
            </tr>
            <tr>
            <td><strong>system <code>tick</code></strong></td>
            <td>- <strong>core</strong> timer for RTOS <br> - drives
            task scheduling <br> - fixed frequency</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p><img src="img/mermaid_figs/6.realtime.system_tick.png" width="400"></p>
            <p>There are various <strong>design considerations</strong>
            for timers in an RTOS, <em>viz.,</em></p>
            <ol type="1">
            <li><strong>resolution</strong> → the smaller the
            resolution, the higher the system/hardware/software/runtime
            overheads</li>
            <li><strong>accuracy</strong> → need to understand and
            manage <em>drift</em> and <em>jitter</em>; timers may need
            to be calibrated often++</li>
            <li><strong>power consumption</strong> → more
            accurate/high-precision a timer, higher the power
            consumption; also the <code>tick</code> can result in
            significant power consumption if not implemented/managed
            well</li>
            </ol>
            <p>(++ drift indicates a <em>gradual, long-term change</em>
            in the timer’s frequency over time, whereas jitter refers to
            <em>short-term, random fluctuations</em> in the timing of
            individual clock pulses)</p>
            <p><strong>Interrupt Latencies</strong> → time from when an
            interrupt occurs to when the corresponding interrupt service
            routine (ISR) starts executing. As interrupts are integral
            to the operation of an RTOS, from the implementation of the
            system <code>tick</code> to notifcations of internal
            (watchdog timers) and external events (new sensor data), it
            is important to <strong>minimize interrupt
            latencies</strong>.</p>
            <p>Optimization Techniques (to minimize latencies):</p>
            <ul>
            <li>minimize interrupt frequency → oftean an RTOS will
            disable interrupts in critical sections</li>
            <li>efficient timer and interrupt queue management →
            “nesting” interrupts,</li>
            <li>power-aware timing strategies → “<em>tickless</em>”
            operating systems have been tried</li>
            <li>optimize ISRs → keep them short, use other methods (<a
            href="https://www.osr.com/nt-insider/2009-issue1/deferred-procedure-call-details/">deferred
            procedure calls</a> or “<a
            href="http://www.cs.otago.ac.nz/cosc440/labs/lab08.pdf">bottom
            halves</a>”).</li>
            </ul>
            </section>
            <section id="kernel-performance-metrics" class="level3"
            data-number="4.1.5">
            <h3 data-number="4.1.5"><span
            class="header-section-number">4.1.5</span> Kernel
            Performance Metrics</h3>
            <blockquote>
            <p>Essentially, the kernel must be designed to
            <strong>minimize jitter</strong> and ensure that all
            operations have bounded and predictable execution times.</p>
            </blockquote>
            <p>Hence, we can try to evaluate whether an RTOS kernel
            meets these goals using the following metrics
            (<strong>note</strong>: not exhaustive):</p>
            <table>
            <colgroup>
            <col style="width: 48%" />
            <col style="width: 52%" />
            </colgroup>
            <thead>
            <tr>
            <th>metric</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>interrupt latency</strong></td>
            <td>the time taken to respond to an interrupt</td>
            </tr>
            <tr>
            <td><strong>context switch time</strong></td>
            <td>time to switch between tasks</td>
            </tr>
            <tr>
            <td><strong>dispatch latency</strong></td>
            <td>time difference between task being ready and when it
            starts executing</td>
            </tr>
            <tr>
            <td><strong>throughput</strong></td>
            <td>number of tasks?operations kernel can handle per unit
            time</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            <section id="examples-of-rtos" class="level2"
            data-number="4.2">
            <h2 data-number="4.2"><span
            class="header-section-number">4.2</span> Examples of
            RTOS</h2>
            <table>
            <colgroup>
            <col style="width: 24%" />
            <col style="width: 41%" />
            <col style="width: 34%" />
            </colgroup>
            <thead>
            <tr>
            <th><strong>name</strong></th>
            <th><strong>description</strong></th>
            <th><strong>features</strong></th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><a href="https://www.freertos.org">FreeRTOS</a></td>
            <td>a widely used, <strong>open-source</strong> RTOS for
            embedded systems</td>
            <td>small footprint, portable, supports a wide range of
            microcontrollers</td>
            </tr>
            <tr>
            <td><a
            href="https://www.windriver.com/products/vxworks">VxWorks</a></td>
            <td><strong>commercial</strong> RTOS used in aerospace,
            defense, applications</td>
            <td>high reliability, real-time performance, and support for
            multi-core processors</td>
            </tr>
            <tr>
            <td><a href="https://blackberry.qnx.com/en">QNX</a></td>
            <td>a <strong>commercial</strong> RTOS known for its
            reliability and use in automotive and medical systems</td>
            <td>microkernel architecture, high security, support for
            posix apis</td>
            </tr>
            <tr>
            <td><a href="https://www.zephyrproject.org">Zephyr</a></td>
            <td><strong>open-source</strong> RTOS designed for IoT and
            Edge devices</td>
            <td>modular, scalable, supports a wide range of hardware
            architectures</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Why is Linux not on the list? While it has many
            (increasing) <a
            href="https://www.zdnet.com/article/real-time-linux-leads-kernel-v6-12s-list-of-new-features/">list
            of real-time features</a>, it is still far from a
            <strong>hard real-time system</strong>, mainly due to its
            complexity. It is difficult to analyze WCETs on Linux or
            completely control its timers → the list is endless. It
            still sees use in many real-time and embedded systems and we
            will (brielfy) explore its real-time capabilities soon.</p>
            <section id="freertos" class="level3" data-number="4.2.1">
            <h3 data-number="4.2.1"><span
            class="header-section-number">4.2.1</span> FreeRTOS</h3>
            <p>As mentioned earlier, FreeRTOS is one of the most popular
            open-source RTOS options, widely used in embedded systems
            due to its simplicity, portability and extensive community
            support. It supports,</p>
            <ul>
            <li>creation of multiple tasks, each with its own
            priority</li>
            <li>preemptive and cooperative scheduling</li>
            <li>mechanisms like queues, semaphores, and mutexes for
            communication and synchronization between tasks</li>
            <li>several memory management schemes, including heap_1,
            heap_2, heap_3, heap_4, and heap_5, to suit different
            application requirements</li>
            <li><strong>highly portable</strong> and supports a wide
            range of microcontrollers and development boards, including
            ARM Cortex-M, ESP32 and STM32</li>
            <li>a large and active community, with [extensive
            documentation, tutorials and examples available online</li>
            </ul>
            <p>Here is an example that uses FreeRTOS to blink the LEDs
            on a microcontroller:</p>
            <div class="sourceCode" id="cb15"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;FreeRTOS.h&gt;</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;task.h&gt;</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;gpio.h&gt;</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">// Task to blink an LED</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> vBlinkTask<span class="op">(</span><span class="dt">void</span> <span class="op">*</span>pvParameters<span class="op">)</span> <span class="op">{</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        GPIO_TogglePin<span class="op">(</span>LED_PIN<span class="op">);</span>  <span class="co">// Toggle LED</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        vTaskDelay<span class="op">(</span>pdMS_TO_TICKS<span class="op">(</span><span class="dv">500</span><span class="op">));</span>  <span class="co">// Delay for 500ms</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Initialize hardware</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    GPIO_Init<span class="op">(</span>LED_PIN<span class="op">,</span> GPIO_MODE_OUTPUT<span class="op">);</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Create the blink task</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    xTaskCreate<span class="op">(</span>vBlinkTask<span class="op">,</span> <span class="st">&quot;Blink&quot;</span><span class="op">,</span> configMINIMAL_STACK_SIZE<span class="op">,</span> NULL<span class="op">,</span> <span class="dv">1</span><span class="op">,</span> NULL<span class="op">);</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Start the scheduler</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    vTaskStartScheduler<span class="op">();</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">// The program should never reach here</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(;;);</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p><strong>Resources</strong>:</p>
            <ol type="1">
            <li><a
            href="https://www.freertos.org/Documentation/RTOS_book.html">FreeRTOS
            Documentation</a></li>
            <li><a
            href="https://www.freertos.org/Why-FreeRTOS/Features-and-demos/RAM_constrained_design_tutorial/Real-time-application-design">FreeRTOS
            Tutorials</a></li>
            <li><a
            href="https://forums.freertos.org/t/using-freertos-with-the-raspberry-pi-pico-blog-series/16497"><strong>Raspberry
            Pi and FreeRTOS</strong></a> [<a
            href="https://github.com/aws-iot-builder-tools/freertos-pi-pico">GitHub
            Repo</a>]</li>
            </ol>
            </section>
            <section id="linuxreal-time" class="level3"
            data-number="4.2.2">
            <h3 data-number="4.2.2"><span
            class="header-section-number">4.2.2</span>
            Linux+Real-Time</h3>
            <p>As mentioned earlier, Linux, as a general-purpose
            operating system, is not inherently a real-time operating
            system (RTOS). However, it does provide several features and
            mechanisms that can be used to achieve real-time
            performance, especially when combined with real-time patches
            or specialized configurations.</p>
            <p>Some of the real-time features of Linux include:</p>
            <ul>
            <li><p><strong><a
            href="https://wiki.linuxfoundation.org/realtime/start">Preempt-RT
            Patch</a></strong>: a set of patches that convert the Linux
            kernel into a fully preemptible kernel, reducing latency and
            improving real-time performance; the Preempt-RT patch
            achieves this by:</p>
            <ul>
            <li>making almost <strong>all kernel code
            preemptible</strong>: allows higher-priority tasks to
            preempt lower-priority tasks, even when the lower-priority
            tasks are executing kernel code</li>
            <li><strong>converting interrupt handlers to kernel
            threads</strong>: reduces time spent with interrupts
            disabled, for better predictability and lower latency</li>
            <li><strong>implementing priority inheritance</strong>:
            helps prevent priority inversion by temporarily elevating
            priority of lower-priority tasks holding a resource needed
            by higher-priority tasks</li>
            <li><strong>reducing non-preemptible sections</strong>:
            minimizes time during which preemption is disabled, further
            reducing latency</li>
            <li><strong>enhancing timer granularity</strong>: allows for
            more precise timing and scheduling of tasks, crucial for
            real-time applications</li>
            </ul>
            <p>the Preempt-RT patch is widely used in industries such as
            telecommunications, industrial automation and audio
            processing. It is actively maintained and supported by the
            Linux Foundation’s <a
            href="https://wiki.linuxfoundation.org/realtime/rtl/start">Real-Time
            Linux</a> (RTL) collaborative project</p></li>
            <li><p><strong><a
            href="https://man7.org/linux/man-pages/man7/sched.7.html">Real-Time
            scheduling policies</a></strong>: support for real-time
            scheduling policies such as <code>SCHED_FIFO</code> and
            <code>SCHED_RR</code>, which provide deterministic
            scheduling behavior</p></li>
            <li><p><strong><a
            href="https://www.kernel.org/doc/html/latest/timers/hrtimers.html">High-resolution
            timers</a></strong>: support for high-resolution timers that
            allow for precise timing and scheduling of tasks</p></li>
            <li><p>basic <strong><a
            href="https://www.kernel.org/doc/Documentation/locking/priority-inheritance.txt">priority
            inheritance</a></strong>: mechanism to prevent priority
            inversion by temporarily elevating the priority of
            lower-priority tasks holding a resource needed by
            higher-priority tasks</p></li>
            <li><p><strong><a
            href="https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.html#isolcpus">CPU
            isolation</a></strong>: ability to isolate CPUs from the
            general scheduler, dedicating them to specific real-time
            tasks; also pinning processes to certain cores</p></li>
            <li><p><strong><a
            href="https://www.kernel.org/doc/Documentation/core-api/genericirq.rst">Threaded
            interrupts</a></strong>: support for handling interrupts in
            kernel threads, reducing interrupt latency and improving
            predictability</p></li>
            <li><p><strong><a
            href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/8/html/understanding_rhel_for_real_time/assembly_memory-management-on-rhel-for-real-time-_understanding-rhel-for-real-time-core-concepts#con_demand-paging_assembly_memory-management-on-rhel-for-real-time-">Memory
            management</a></strong> techniques: such as <a
            href="https://linux.die.net/man/2/mlock"><strong>memory
            locking</strong></a> to prevent pages from being swapped,
            the use of “<a
            href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/performance_tuning_guide/s-memory-transhuge"><strong>huge</strong></a>”
            pages and memory <a
            href="https://docs.kernel.org/core-api/memory-allocation.html"><strong>pre-allocation</strong></a></p></li>
            <li><p><strong><a
            href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt">Control
            groups (cgroups)</a></strong>: mechanism to allocate CPU,
            memory and I/O resources to specific groups of tasks,
            ensuring resource availability for real-time tasks</p></li>
            </ul>
            <p>These features, when properly configured, can help
            achieve real-time performance on Linux, making it suitable
            for certain real-time and embedded applications.</p>
            </section>
            <section id="raspberry-pi-osreal-time" class="level3"
            data-number="4.2.3">
            <h3 data-number="4.2.3"><span
            class="header-section-number">4.2.3</span> Raspberry Pi
            OS+Real-Time</h3>
            <p>The <a
            href="https://www.raspberrypi.com/software/">Raspberry Pi
            OS</a> can also be made “real-time” in the same manner as
            decribed above, since it is a Linux variant.</p>
            <p>Though, there are some attempts at getting the Pi to
            behave in a real-time fashion, <em>e.g.,</em>: <a
            href="https://www.socallinuxexpo.org/sites/default/files/presentations/Steven_Doran_SCALE_13x.pdf"><strong>1</strong></a>,
            <a
            href="https://all3dp.com/2/rtos-raspberry-pi-real-time-os/#google_vignette"><strong>2</strong></a>,
            <a
            href="https://floating.io/2023/04/raspberry-pi-in-real-time/"><strong>3</strong></a>.</p>
            <p><br></p>
            </section>
            </section>
            <section id="robot-operating-system-ros" class="level2"
            data-number="4.3">
            <h2 data-number="4.3"><span
            class="header-section-number">4.3</span> Robot Operating
            System (ROS)</h2>
            <p>ROS is an <strong>open source middleware</strong>
            framework built for robotics applications. The main goal →
            develop <strong>standards</strong> for robotic software. ROS
            provides many <strong>reusable modules</strong> for
            developing robotic applications.</p>
            <p>Embedded/autonomous programs that do simple tasks (or
            operate with a single sensor/motor) are relatively easy to
            program. As more sensing, actuation, functionality is added
            (consider a larege industrial robot or even an autonomous
            car), programs quickly become quite complex – coordination
            of the data and system states becomes challenging.</p>
            <p><img src="img/rtos/ros/ros.complexity.webp" width="400"></p>
            <p><br></p>
            <p>ROS helps to develop and <strong>scale</strong> such
            applications and also <strong>manages
            communications</strong> between various parts of the
            software. As mentioned earlier, ROS is <a
            href="https://www.redhat.com/en/topics/middleware/what-is-middleware"><strong>middleware</strong></a>:</p>
            <blockquote>
            <p>Middleware is a software layer that connects the
            operating system to applications, data, and users. It
            provides common services and capabilities, like single-sign
            on (SSO), easy communication/coordination (like ROS) or
            application programming interface (API) management.
            Developers can rely on middleware to provide consistent,
            simplified integrations between application components. This
            frees up developers to build core features of applications,
            rather than spend time connecting those features to
            different endpoints and environments, including legacy
            systems.</p>
            </blockquote>
            <p>At a high level, ROS,</p>
            <ul>
            <li>creates a <em>separation</em> of code blocks → into
            reusable blocks</li>
            <li>provides <em>tools</em> → easy communication between
            sub-programs</li>
            <li>is <em>language agnostic</em> → allows different
            components to be written in, say Python and C and yet
            communicate using the <strong>ROS communication
            protocol</strong></li>
            </ul>
            <p>A simple example: <a
            href="https://dilipkumar.medium.com/ros-v1-robot-operating-system-88039990e913">control
            of a robotic arm+camera</a>:</p>
            <p><img src="img/rtos/ros/ros.robot_camera_example.webp" width="400"></p>
            <p><br></p>
            <p>To write a ROS application to control this robotic arm,
            we first create a few <strong>subprograms</strong>:</p>
            <ul>
            <li>one for the camera → <code>node</code></li>
            <li>another for → <code>motion planning</code></li>
            <li>one for → <code>hardware drivers</code></li>
            <li>finally one for → <code>joystick</code></li>
            </ul>
            <p>Now we use ROS → <strong>communication</strong> between
            these nodes.</p>
            <p>ROS even provides <strong>plug and play
            libraries</strong> for designing your system, <em>e.g.,</em>
            <a
            href="https://moveit.ai/moveit/ros2/2020/02/18/moveit-2-beta-feature-list.html">inverse
            kinematics libraries</a>, <a
            href="https://roboticseabass.com/2024/06/30/how-do-robot-manipulators-move/">trajectory
            planning for robotic arms</a>, <em>etc.</em></p>
            <section id="ros-components" class="level3"
            data-number="4.3.1">
            <h3 data-number="4.3.1"><span
            class="header-section-number">4.3.1</span> ROS
            Components</h3>
            <p>Some important <strong>components</strong> of ROS:</p>
            <p><img src="img/mermaid_figs/6.realtime.ros_architecture_legends.png" width="400">
            <br>
            <img src="img/mermaid_figs/6.realtime.ros_architecture.png" width="400"></p>
            <ol type="1">
            <li><a href="http://wiki.ros.org/Nodes">node</a></li>
            </ol>
            <ul>
            <li>a process that performs <strong>computation</strong> (a
            program/subprogram)</li>
            <li>combined together into a graph</li>
            <li>communicate via “topics”</li>
            <li>operate at a fine-grained scale</li>
            <li>a full system will have <em>multiple</em> nodes,
            <em>e.g.,</em>
            <ul>
            <li>one node controls a laser range-finder</li>
            <li>one Node controls the robot’s wheel motors</li>
            <li>one node performs localization</li>
            <li>one node performs path planning</li>
            <li>one node provides a graphical view of the system</li>
            </ul></li>
            </ul>
            <p>The use of nodes has several benefits such as
            <strong>fault tolerance</strong>, <strong>reduced
            complexity</strong> and <strong>modularity</strong>.</p>
            <ol start="2" type="1">
            <li><a href="http://wiki.ros.org/Topics">topics</a></li>
            </ol>
            <ul>
            <li>they’re <strong>named buses</strong> over which nodes
            exchange “messages”</li>
            <li><strong>anonymous publish/subscribe semantics</strong> →
            decouples production of information from its
            consumption</li>
            <li>nodes are not aware of who they are communicating
            with</li>
            <li>nodes that are interested in data
            <strong>subscribe</strong> to the <em>relevant
            topic</em></li>
            <li>nodes that <em>generate</em> data
            <strong>publish</strong> to the relevant topic</li>
            <li>can be <strong>multiple</strong> publishers and
            subscribers to a topic</li>
            <li>topic is <strong>strongly typed</strong> by publisher →
            nodes can only receive messages with a matching type</li>
            </ul>
            <p>Topics are meant for <em>unidirectional</em>,
            <em>streaming</em> communication. ROS includes other
            mechanisms such as <a
            href="http://wiki.ros.org/Services">services</a> and
            [parameter servers]http://wiki.ros.org/Parameter%20Server)
            for different types of communciations.</p>
            <ol start="3" type="1">
            <li><a href="http://wiki.ros.org/Messages">messages</a></li>
            </ol>
            <ul>
            <li>nodes communicate with each other by publishing messages
            to topics</li>
            <li>simple text files</li>
            <li>simple data structure → <strong>typed
            fields</strong></li>
            <li>support standard primitives (<code>int</code>,
            <code>float</code>, <code>boolean</code>)</li>
            <li>can include arbitrarily nested <code>structs</code> and
            <code>arrays</code></li>
            <li>nodes can exchange → <code>request</code> an
            <code>response</code> messages</li>
            </ul>
            <p>A simple ROS message:</p>
            <pre class="ros"><code>std_msgs/Header header
  uint32 seq
  time stamp
  string frame_id
geometry_msgs/Point point
  float64 x
  float64 y
  float64 z</code></pre>
            <p>Example: <a
            href="https://classes.cs.uchicago.edu/archive/2022/spring/20600-1/ros_intro.html">our
            first ROS message</a>.</p>
            <ol start="4" type="1">
            <li><a href="http://wiki.ros.org/Master">ROS Master</a></li>
            </ol>
            <ul>
            <li>provides naming and registration services to the rest of
            the nodes in the ROS system</li>
            <li>also runs the <a
            href="http://wiki.ros.org/Parameter%20Server">parameter
            server</a> → a shared, multi-variate dictionary that is
            accessible via network APIs, used by nodes to
            <strong>store/retrieve parameters</strong></li>
            <li>tracks publishers and subscribers to topics as well as
            services</li>
            <li>enable individual ROS nodes to locate one anothe</li>
            <li>once located, they communicate in a
            <strong>peer-to-peer</strong> fashion</li>
            </ul>
            <p>Example:</p>
            <ol type="1">
            <li>consider two nodes → <code>camera</code> node and
            <code>image_viewer</code> node</li>
            <li><code>camera</code> notifies <code>master</code> → wants
            to publish images on the topic, <code>images</code></li>
            </ol>
            <p><img src="img/rtos/ros/ROS_master_example_english_1.png"></p>
            <ol start="3" type="1">
            <li>no one is subscribing to the topic, yet → <strong>no
            images sent</strong></li>
            <li><code>image viewer</code> → subscribe to
            <code>images</code> topic</li>
            </ol>
            <p><img src="img/rtos/ros/ROS_master_example_english_2.png"></p>
            <ol start="5" type="1">
            <li>topic, <code>images</code> has both → publisher and
            subscriber</li>
            <li><code>master</code> notifies both → of each others’
            existence</li>
            </ol>
            <p><img src="img/rtos/ros/ROS_master_example_english_3.png"></p>
            <ol start="7" type="1">
            <li>both start <strong>communicating with each
            other</strong>, directly</li>
            </ol>
            <p><br></p>
            <p>A more intricate example of the same:</p>
            <p><img src="img/mermaid_figs/6.realtime.ros_publish_subscribe.png" width="400"></p>
            <ol start="5" type="1">
            <li><a href="http://wiki.ros.org/tf2">ROS transform</a></li>
            </ol>
            <ul>
            <li>robotic system typically has many 3D coordinate frames
            that change over time
            <ul>
            <li><em>e.g.,</em> world frame, base frame, gripper frame,
            head frame, <em>etc.</em></li>
            </ul></li>
            <li>lets the user keep track of multiple coordinate frames
            over time</li>
            <li>maintains the relationship between coordinate frames →
            manages <strong>spatial relationships</strong></li>
            <li>in a tree structure buffered in time</li>
            <li>lets the user transform points, vectors, <em>etc.</em> →
            at any desired point in time</li>
            <li><strong>distributed</strong> → coordinate frames of
            robot available to <strong>all</strong> ROS components on
            any computer in the system</li>
            <li>sensor fusion, motion planning, and navigation</li>
            <li>organizes all coordinate frames and their relationships
            into a <strong>transform tree</strong></li>
            </ul>
            <p>An example of a ROS transform and tree:</p>
            <p><img src="img/mermaid_figs/6.realtime.ros_transform.png" width="400"></p>
            </section>
            <section id="ros-and-real-time" class="level3"
            data-number="4.3.2">
            <h3 data-number="4.3.2"><span
            class="header-section-number">4.3.2</span> ROS and
            Real-time?</h3>
            <p>ROS (the first version) is <strong>not</strong>
            real-time. Hence, systems that requires <strong>hard
            real-time guarantees</strong> shoud not use it. But ROS can
            be itegrated into systems that require <em>some</em> latency
            guarantees. If needed, ROS can be run on top of the
            <code>RT_PREEMPT</code> real-time patch on Linux. In
            addition, <strong>specific nodes</strong> can be designed to
            handle real-time functions or programmed to behave as
            real-time control systems.</p>
            <p>If better real-time guarantees are required on ROS, then
            <a
            href="https://roscon.ros.org/2015/presentations/RealtimeROS2.pdf"><strong>ROS
            2</strong></a> if your best bet.</p>
            <p><strong>Resources</strong>: more information on real-time
            and ROS2 can be found at <a
            href="https://xilinx.github.io/KRS/sphinx/build/html/docs/features/realtime_ros2.html">RT
            ROS2 Xilinx</a> and <a
            href="https://github.com/ros-realtime">RT ROS
            Github</a>.</p>
            </section>
            <section id="rosnavio2" class="level3" data-number="4.3.3">
            <h3 data-number="4.3.3"><span
            class="header-section-number">4.3.3</span> Ros+Navio2</h3>
            <p>We use ROS (the original version, not ROS2) in our class.
            <strong>Note:</strong> while ROS has no real-time
            capabilities, one some embedded systems, if it <em>fast
            enough</em> that we can use it to control safety-critical
            systems such as drones and other small autonomous
            systems.</p>
            <p>In fact, the basic Raspbian image comes installed with
            ROS. We can use it communicate between the Navio2 and the
            controller running on the Pi to exchange critical
            information, <em>e.g.</em>, sensor data.</p>
            <p><img src="img/rtos/ros/ros.ardupilot_navio.png" width="400"></p>
            <p><strong>Resources</strong>: please read the <a
            href="https://docs.emlid.com/navio2/ros/">step-by-step
            instructions</a> on how to connect/use the Navio2 and the Pi
            using ROS.</p>
            <!--link rel="stylesheet" href="./custom.sibin.css"-->
            </section>
            </section>
            </section>
            <section id="scheduling-for-real-time-systems"
            class="level1" data-number="5">
            <h1 data-number="5"><span
            class="header-section-number">5</span> Scheduling for
            Real-Time Systems</h1>
            <p>Consider an engine control system that cycles through the
            various phases of operation for an <a
            href="http://automobile-us.blogspot.com">automotive
            engine</a>:</p>
            <p><img src="img/scheduling/engine_animation.gif"></p>
            <p><br></p>
            <p>This system <strong>periodically</strong> cycles through
            multiple tasks, <em>viz.</em>,</p>
            <ol type="1">
            <li>air intake</li>
            <li>pressure</li>
            <li>fuel injection+combustion</li>
            <li>exhaust</li>
            </ol>
            <p>If we correlate this to task “actiations”, then we may
            see the <a
            href="https://retis.sssup.it/~a.biondi/papers/ERIKA_AVR_RTAS16.pdf">following</a>:</p>
            <table>
            <colgroup>
            <col style="width: 50%" />
            <col style="width: 50%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/scheduling/engine_animation.gif" width="180"></td>
            <td><img src="img/scheduling/angular_task.png" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>We see that for each <strong>cycle</strong>, the same set
            of tasks <strong>repeat</strong> (<em>i.e.</em>., “periodic
            behavior”). Note though that the tasks <em>need not</em>
            execute in parallel – rather, they must execute sequentially
            for this application. Usually such applications use a
            scheduling mechanism known as a “<a href="">cyclic
            executive</a>” that we shall discuss soon.</p>
            <p><br> <br> <br> <br> <br> <br> <br> <br> <br> <br></p>
            <p>TODOs:</p>
            <ul>
            <li>cyclic executives</li>
            <li>simple task example – how would you schedule this?</li>
            <li>hard vs soft RTS – explain with deadline diagrams</li>
            <li>task model</li>
            <li>more on cyclic executives, round robin, etc. [static
            table-driven]</li>
            <li>static vs dynamic</li>
            <li>priority-based [static v dynamic]</li>
            <li>dynamic best effort?</li>
            </ul>
            <!--link rel="stylesheet" href="./custom.sibin.css"-->
            </section>
            <section id="introduction-1" class="level1" data-number="6">
            <h1 data-number="6"><span
            class="header-section-number">6</span> introduction</h1>
            <section id="autonomy-1" class="level2" data-number="6.1">
            <h2 data-number="6.1"><span
            class="header-section-number">6.1</span> autonomy</h2>
            <p>what is “<em>autonomy</em>”?</p>
            <p>we see various examples of it…</p>
            <p><img src="img/philippine_uav.png" height="100" width = "200" style="display: inline-block; margin-right: 10px;">
            <img src="img/white_tesla.png" height="100" width = "200"  style="display: inline-block;"></p>
            <section id="what-are-the-aspects-of-autonomy-1"
            class="level3" data-number="6.1.1">
            <h3 data-number="6.1.1"><span
            class="header-section-number">6.1.1</span> what are the
            <em>aspects</em> of autonomy?</h3>
            <table>
            <colgroup>
            <col style="width: 13%" />
            <col style="width: 86%" />
            </colgroup>
            <tbody>
            <tr>
            <td><strong>perception</strong></td>
            <td>how do you “<em>see</em>” the world around you?</td>
            </tr>
            <tr>
            <td><strong>sensing</strong></td>
            <td>various ways to perceive the world around you
            (<em>e.g</em>, camera, LiDar)</td>
            </tr>
            <tr>
            <td><strong>compute</strong></td>
            <td>what do you “<em>do</em>” with the information about the
            world?</td>
            </tr>
            <tr>
            <td><strong>motion</strong></td>
            <td>do your computations result in any “<em>physical</em>”
            changes?</td>
            </tr>
            <tr>
            <td><strong>actuation</strong></td>
            <td>what “<em>actions</em>”, if any, do you take for said
            physical changes?</td>
            </tr>
            <tr>
            <td><strong>planning</strong></td>
            <td>can you do some “<em>higher order</em>” thinking <br>
            (<em>i.e.,</em> not just your immediate next move)</td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            <section id="let-us-define-autonomy-1" class="level2"
            data-number="6.2">
            <h2 data-number="6.2"><span
            class="header-section-number">6.2</span> let us define
            <strong>autonomy</strong></h2>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <tbody>
            <tr>
            <td>Autonomy is the ability to <br> <strong>perform given
            tasks</strong> <br> based on the systems perception <br>
            <scb>without</scb> human intervention</td>
            <td><img src="img/robot_profile_view.jpg" height="275"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="autonomous-systems-1" class="level2"
            data-number="6.3">
            <h2 data-number="6.3"><span
            class="header-section-number">6.3</span> autonomous
            systems</h2>
            <table>
            <colgroup>
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            </colgroup>
            <tbody>
            <tr>
            <td><strong>cyber</strong></td>
            <td><img src="img/cps_software.png" width="275"></td>
            <td><img src="img/cps_networking.png" height="275"></td>
            <td><img src="img/cps_ecus.png" height="275"></td>
            </tr>
            <tr>
            <td><strong>physical</strong></td>
            <td><img src="img/cps_sensors.png" height="275"></td>
            <td><img src="img/cps_actuators.png" height="275"></td>
            <td><img src="img/cps_plants.png" height="275"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>hence, they fall under the class of systems →
            <strong>cyber-physical</strong> systems</p>
            </section>
            <section id="sensors-and-actuators-1" class="level2"
            data-number="6.4">
            <h2 data-number="6.4"><span
            class="header-section-number">6.4</span> sensors and
            actuators…</h2>
            <table>
            <colgroup>
            <col style="width: 50%" />
            <col style="width: 50%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/cps_sensors.png" width="150" style="border: 2px solid purple; display: inline-block; padding: 10px; background-color:rgb(236, 219, 250);"></td>
            <td><img src="img/cps_actuators.png" width="125" style="border: 2px solid purple; display: inline-block; padding: 10px; background-color:rgb(236, 219, 250);"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>…are <strong>everywhere</strong>!</p>
            <p>the <strong>embedded</strong> components → interactions
            with the real world</p>
            </section>
            <section id="sensing-and-actuation-in-the-real-world-1"
            class="level2" data-number="6.5">
            <h2 data-number="6.5"><span
            class="header-section-number">6.5</span> sensing and
            actuation in the real world</h2>
            <p>consider the following example of two cars… <img
            src="img/cars_sensing/cars_sensing_1.png"
            alt="Two cars, one behind the over, top view" /></p>
            <p>the second car is approaching the first <img
            src="img/cars_sensing/cars_sensing_2.png"
            alt="Two cars, one behind the over, top view, an arror to the left on top of the car on the right" /></p>
            <p><strong>sensors</strong> → constantly gathering
            data/sensing</p>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/cars_sensing/cars_sensing_3.png" width="400"></p>
            </div>
            </div>
            <p>on detection (of other car) → quickly
            <strong>compute</strong> what to do</p>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            <li>
            computation
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/cars_sensing/cars_sensing_4.png" width="400"></p>
            </div>
            </div>
            <p>take <strong>physical action</strong> (actuation) → say
            by braking <em>in time</em></p>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            <li>
            computation
            </li>
            <li>
            actuation
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/cars_sensing/cars_sensing_5.png" width="400"></p>
            </div>
            </div>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            <li>
            computation
            </li>
            <li>
            actuation
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/sense_planning_actuation.png" width="400"></p>
            </div>
            </div>
            <p>“<strong>control</strong>”</p>
            <p>Remember this → on detection (of other car) →
            <scb>quickly</scb> <strong>compute</strong> what to do</p>
            <p><img src="img/cars_sensing/cars_sensing_4.png" width="400"></p>
            <p>“quickly” compute → complete computation/actuation →
            before a <strong>deadline</strong></p>
            <p>This is a <strong>real-time system</strong>.</p>
            <section id="come-back-to-sensing-1" class="level3"
            data-number="6.5.1">
            <h3 data-number="6.5.1"><span
            class="header-section-number">6.5.1</span> Come back to
            <strong>sensing</strong></h3>
            <!--div class="multicolumn">
            <div>
            <br>
            <ul>
                <li>we see <i>one</i> sensor (maybe LiDAR)</li>
                <li>reality &rarr; <b>multiple</b> sensors</li>
                <li>cameras, radars, lidar, etc.</li>
            <ul>
            </div>
            <div>
            <img src="img/autonomous_cars_sensors.png">
            </div>
            </div-->
            <p>Multiple sensors in an autonomous vehicle → need to
            <em>combine</em> them somehow</p>
            <p><strong>sensor fusion</strong></p>
            <p>Once we have information from the sensors (fused or
            otherwise)…</p>
            <p><img src="img/kalman_statistical_view.png" width="400"></p>
            <p>We need <strong>state estimation</strong>
            (<strong>kalman</strong> filter, <strong>ekf</strong>).</p>
            </section>
            </section>
            <section id="overviewarchitecture-of-autonomous-systems-1"
            class="level2" data-number="6.6">
            <h2 data-number="6.6"><span
            class="header-section-number">6.6</span>
            Overview/Architecture of Autonomous Systems</h2>
            <p>So far, we have (briefly) talked about…</p>
            <p>Sensing:</p>
            <p><img src="img/stack_architecture/stack_overview.2.png" width="200"></p>
            <p>Actuation:</p>
            <p><img src="img/stack_architecture/stack_overview.3.png" width="200"></p>
            <p>But the system includes…an <strong>operating
            system</strong> (OS) in there</p>
            <p><img src="img/stack_architecture/stack_overview.4.png" width="300"></p>
            <p>and it includes <strong>real-time</strong>
            mechanisms.</p>
            <p>We have briefly discussed, <strong>EKF</strong>:</p>
            <p><img src="img/stack_architecture/stack_overview.5.png" width="300"></p>
            <p><strong>note</strong>: ekf is versatile; can be used for
            sensor fusion, slam, etc.</p>
            <p>All of it integrates with…<strong>control</strong>:</p>
            <p><img src="img/stack_architecture/stack_overview.6.png" width="300"></p>
            <p>There are some <strong>real-time</strong> functions in
            there…</p>
            <p><img src="img/stack_architecture/stack_overview.7.png" width="300"></p>
            <p>like <em>braking</em>, <em>engine control</em>.</p>
            <p>Question: if we design such a system…</p>
            <p><img src="img/stack_architecture/stack_overview.7.png" width="300"></p>
            <p>is it “<strong>autonomous</strong>”?</p>
            <p>We are missing some “higher order” functionss from the
            perspective of the autonomous system:</p>
            <ul>
            <li><em>where</em> am I?</li>
            <li><em>where</em> do I need to go?</li>
            <li><em>how</em> do I get there?</li>
            <li><em>what</em> obstacles may I face?</li>
            <li><em>how</em> do I avoid them?</li>
            </ul>
            <p>let us not forget the most important question of all…</p>
            <p><img src="img/drax_gamora.avif" width="400"></p>
            <p><strong>why</strong> is gamora?</p>
            <section id="high-order-functions-1" class="level3"
            data-number="6.6.1">
            <h3 data-number="6.6.1"><span
            class="header-section-number">6.6.1</span> high-order
            functions</h3>
            <p>In order to answer the following, we need
            <strong>additional functionality</strong>. Let us go through
            what that might be.</p>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <tbody>
            <tr>
            <td></td>
            <td><img src="img/stack_architecture/stack_overview.7.png" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="slam-1" class="level3" data-number="6.6.2">
            <h3 data-number="6.6.2"><span
            class="header-section-number">6.6.2</span> slam</h3>
            <p>Simultaneous localization and mapping → figure out
            <strong>where</strong> we are.</p>
            <p><img src="img/stack_architecture/stack_overview.8.png" width="300"></p>
            </section>
            <section id="waypoint-detection-1" class="level3"
            data-number="6.6.3">
            <h3 data-number="6.6.3"><span
            class="header-section-number">6.6.3</span> waypoint
            detection</h3>
            <p>Understand how to move in the <em>right</em> direction at
            the <strong>micro</strong> level, <em>i.e.,</em> find
            <strong>waypoints</strong>.</p>
            <p><img src="img/stack_architecture/stack_overview.9.png" width="300"></p>
            </section>
            <section id="yolo-1" class="level3" data-number="6.6.4">
            <h3 data-number="6.6.4"><span
            class="header-section-number">6.6.4</span> yolo</h3>
            <p>Is it “you only live once”? Actually this stands for:
            “you only <strong>look</strong> once”. It is an object
            <strong>detection</strong> model that uses convolutional
            neural networks (cnns)</p>
            <p><img src="img/stack_architecture/stack_overview.10.png" width="300"></p>
            </section>
            <section id="object-avoidance-1" class="level3"
            data-number="6.6.5">
            <h3 data-number="6.6.5"><span
            class="header-section-number">6.6.5</span> object
            avoidance</h3>
            <p>The objective is to avoid objects in the
            <strong>immediate path</strong>.</p>
            <p><img src="img/stack_architecture/stack_overview.11.png" width="300"></p>
            </section>
            <section id="path-planning-1" class="level3"
            data-number="6.6.6">
            <h3 data-number="6.6.6"><span
            class="header-section-number">6.6.6</span> path
            planning</h3>
            <p>i.e., how to get to <strong>destination</strong> at the
            <strong>macro</strong> level → uses waypoints.</p>
            <p><img src="img/stack_architecture/stack_overview.12.png" width="300"></p>
            </section>
            <section id="compute-platform-1" class="level3"
            data-number="6.6.7">
            <h3 data-number="6.6.7"><span
            class="header-section-number">6.6.7</span> compute
            platform</h3>
            <p>To run all of these functions, we need low power,
            embedded platforms.</p>
            <p><img src="img/stack_architecture/stack_overview.13.png" width="300"></p>
            </section>
            <section
            id="still-some-non-functional-requirements-remain-1"
            class="level3" data-number="6.6.8">
            <h3 data-number="6.6.8"><span
            class="header-section-number">6.6.8</span> still some
            <strong>non-functional</strong> requirements remain</h3>
            <p>any guesses what they could be?</p>
            </section>
            <section id="safety-1" class="level3" data-number="6.6.9">
            <h3 data-number="6.6.9"><span
            class="header-section-number">6.6.9</span> safety!</h3>
            <p>Essentially safety of → operator, other people, the
            vehicle, environment This is <strong>cross-cutting</strong>
            issue → affected <scb>by</scb> <strong>all</strong> parts of
            system.</p>
            <p><img src="img/stack_architecture/stack_overview.14.png" width="300"></p>
            </section>
            <section id="security-1" class="level3"
            data-number="6.6.10">
            <h3 data-number="6.6.10"><span
            class="header-section-number">6.6.10</span> security</h3>
            <p>Security is another cross-cutting issue → <scb>can
            affect</scb> <strong>all</strong> components.</p>
            <p><img src="img/stack_architecture/stack_overview.png" width="300"></p>
            </section>
            <section id="course-structure-1" class="level3"
            data-number="6.6.11">
            <h3 data-number="6.6.11"><span
            class="header-section-number">6.6.11</span> Course
            Structure</h3>
            <p>Hence this figure is a (loose) map of this course:</p>
            <p><img src="img/stack_architecture/stack_overview.png" width="300">
            <!--link rel="stylesheet" href="./custom.sibin.css"--></p>
            </section>
            </section>
            </section>
            <section id="embedded-architectures-1" class="level1"
            data-number="7">
            <h1 data-number="7"><span
            class="header-section-number">7</span> Embedded
            Architectures</h1>
            <p>Just like “autonomy” describing and “embedded system” is
            hard. What (typically) distinguishes it from other types of
            computer systems (e.g., laptops, servers or GPUs even) is
            that such systems are typically created for
            <em>specific</em> functionality and often remain fixed and
            operational for years, decades even.</p>
            <p>Embedded systems often trade off between performance and
            other considerations such as power (or battery life), less
            memory, fewer peripherals, limited applications, smaller
            operating system (OS) and so on. There are numerous reasons
            for this – chief among them is <em>predictability</em> –
            designers need to guarantee that the system works correctly,
            and remains safe, all the time. Hence, it must be easy to
            <em>certify</em> <a href="#fn4" class="footnote-ref"
            id="fnref4" role="doc-noteref"><sup>4</sup></a> the
            <em>entire</em> system. This process ensures that the system
            operates <strong>safely</strong>.</p>
            <section id="the-wcet-problem-1" class="level2"
            data-number="7.1">
            <h2 data-number="7.1"><span
            class="header-section-number">7.1</span> The
            <strong>wcet</strong> problem</h2>
            <p>One piece of information that is required to ensure
            predictability and guarentee safety is <strong><a
            href="https://www.cs.fsu.edu/~whalley/papers/tecs07.pdf">worst-case
            execution time</a></strong> (WCET). The WCET/BCET is the
            <strong>longest</strong>/shortest execution time possible
            for a program, <strong>on a specific hardware
            platform</strong> – and it has to consider <em>all possible
            inputs</em>. WCET is necessary to ensure the
            “schedulability”, resource requirements and performance
            limits of embedded and real-time programs. There are lots of
            approaches to computing the WCET, <em>e.g.,</em></p>
            <ul>
            <li><a
            href="https://www.cs.fsu.edu/~whalley/papers/tecs07.pdf">dynamic/empirical</a>
            analysis → run the program lots of times (thousands,
            millions?) on the platform and measure it</li>
            <li><a
            href="https://www.cs.fsu.edu/~whalley/papers/tecs07.pdf">static</a>
            analysis → analyze the program at <em>compile time</em> to
            compute the <em>worst-case paths</em> through the
            program</li>
            <li><a
            href="https://sibin.github.io/papers/2008_NCSU-Dissertation_CheckerMode_SibinMohan.pdf">hybrid</a>
            → a combination of the two</li>
            <li><a
            href="https://people.ac.upc.edu/fcazorla/articles/jabella_ecrts2014_2.pdf">probabilistic</a>
            → a combination of dynamic analysis+statistical methods</li>
            <li><a
            href="https://dl.acm.org/doi/10.1145/3570361.3615740">ML-based
            methods</a> → applying machine-learning to the problem</li>
            </ul>
            <p>At a high-level, the execution time distributions of
            applications look like:</p>
            <p><img src="./img/embedded_arch/wcet_wilhelm.png" width="400" style="display: inline-block;" title="https://www.inf.ed.ac.uk/teaching/courses/es/PDFs/lecture_11.pdf" /></p>
            <p>WCET analysis is a very active area of research and
            hundreds of papers have been written about it, since it
            directly affects the safety of many critical systems
            (aircraft, power systems, nuclear reactors, space vehicles
            and…autonomous systems).</p>
            <p>There are structural challenges (both in software and
            hardware) that prevent the computation of <em>proper</em>
            wcet for anything but trivial examples. For instance,
            consider,</p>
            <div class="sourceCode" id="cb17"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> main<span class="op">()</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> max <span class="op">=</span> <span class="dv">10</span> <span class="op">;</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> max <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        sum <span class="op">+=</span> i <span class="op">;</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>How do you compute the WCET for this code? Say running on
            some known processor, P?</p>
            <p>Well, there’s some information we need,</p>
            <ul>
            <li>how long each instruction takes to execute on P</li>
            <li>how many loop iterations?</li>
            <li>what is the startup/cleanup times for the program on
            P?</li>
            </ul>
            <p>Let’s assume (from the manual for P), we get the
            following information,</p>
            <div class="sourceCode" id="cb18"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>   <span class="dt">void</span> main<span class="op">()</span>         <span class="co">// startup cost = 100 cycles</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>   <span class="op">{</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>       <span class="dt">int</span> max <span class="op">=</span> <span class="dv">15</span> <span class="op">;</span>  <span class="co">// 10 cycles</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>       <span class="dt">int</span> sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>    <span class="co">// 10 cycles </span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>       <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> max <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span> <span class="co">// 5 cycles, once</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>            sum <span class="op">+=</span> i <span class="op">;</span> <span class="co">// 20 cycles each iteration</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>   <span class="op">}</span>                   <span class="co">// cleanup cost = 120 cycles</span></span></code></pre></div>
            <p>So, based on this, we can calculate the total time to
            execute this program:</p>
            <p><span
            class="math display"><em>w</em><em>c</em><em>e</em><em>t</em> = <em>s</em><em>t</em><em>a</em><em>r</em><em>t</em><em>u</em><em>p</em>_<em>c</em><em>o</em><em>s</em><em>t</em> + <em>l</em><em>i</em><em>n</em><em>e</em>_3 + <em>l</em><em>i</em><em>n</em><em>e</em>_4 + <em>l</em><em>o</em><em>o</em><em>p</em>_<em>s</em><em>t</em><em>a</em><em>r</em><em>t</em><em>u</em><em>p</em>_<em>c</em><em>o</em><em>s</em><em>t</em> + (<em>l</em><em>i</em><em>n</em><em>e</em>_6 * <em>m</em><em>a</em><em>x</em>)  [1]</span></p>
            <p><span
            class="math display"><em>w</em><em>c</em><em>e</em><em>t</em> = 100 + 10 + 10 + 5 + (20 * 15)</span></p>
            <p><span
            class="math display"><em>w</em><em>c</em><em>e</em><em>t</em> = 425 <em>c</em><em>y</em><em>c</em><em>l</em><em>e</em><em>s</em></span></p>
            <p>Now consider this slight change to the above code:</p>
            <div class="sourceCode" id="cb19"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> main<span class="op">(</span> <span class="dt">int</span> argc<span class="op">,</span> <span class="dt">char</span><span class="op">*</span> argv<span class="op">[]</span> <span class="op">)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> max <span class="op">=</span> atoi<span class="op">(</span> argv<span class="op">[</span><span class="dv">1</span><span class="op">]</span> <span class="op">)</span> <span class="op">;</span>     <span class="co">// convert the command line arg to max</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> max <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span> <span class="co">// how many iterations?</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        sum <span class="op">+=</span> i <span class="op">;</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>The problem is that equation [1] above fails since we no
            longer know the value of <code>max</code>. Hence the
            <em>program can run for any arbitrary amount of time,
            depending on the given input!</em> Note that
            <strong>none</strong> of the aforemention wcet methods will
            help in this case since the input can be completely
            arbitrary. Hence, the structure of the software code can
            affect wcet calculations.</p>
            <p>Another problem is that of <strong>hardware</strong> (and
            interactions between hardware and software). Now consider if
            we modify the original code as,</p>
            <div class="sourceCode" id="cb20"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#define VERY_LARGE_ARRAY</span><span class="op">+</span><span class="pp">SIZE </span><span class="dv">1</span><span class="op">&gt;&gt;</span><span class="dv">18</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> main<span class="op">()</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> first_array<span class="op">[</span>VERY_LARGE_ARRAY_SIZE<span class="op">]</span> <span class="op">;</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> second_array<span class="op">[</span>VERY_LARGE_ARRAY_SIZE<span class="op">]</span> <span class="op">;</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum_first <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum_second <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> VERY_LARGE_ARRAY_SIZE <span class="op">*</span> <span class="dv">2</span> <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span><span class="op">(</span> i<span class="op">%</span><span class="dv">2</span> <span class="op">)</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>            first_sum <span class="op">+=</span> first_array<span class="op">[</span>i<span class="op">/</span><span class="dv">2</span><span class="op">]</span> <span class="op">;</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>            second_sum <span class="op">+=</span> second_array<span class="op">[(</span><span class="dt">int</span><span class="op">)((</span>i<span class="op">/</span><span class="dv">2</span><span class="op">)+</span><span class="dv">1</span><span class="op">)]</span> <span class="op">;</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>Now, while we can compute, using equation [1] the wcet
            from the code perspective (since we know the loop runs for
            <code>VERY_LARGE_ARRAY_SIZE * 2</code> iterations), there
            will be significant non-obvious hardware issues, in the
            <strong>cache</strong>. Each iteration is accessing a
            <em>different</em> large array. Hence, it will load the
            cache with lines from that array and in the <em>very next
            iteration</em> the other array will be loaded, also missing
            in the cache. For instance,</p>
            <table>
            <colgroup>
            <col style="width: 14%" />
            <col style="width: 25%" />
            <col style="width: 17%" />
            <col style="width: 41%" />
            </colgroup>
            <thead>
            <tr>
            <th>iteration</th>
            <th>operation</th>
            <th>cache state</th>
            <th>reason</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>1</td>
            <td><code>first_array</code> loaded</td>
            <td>miss</td>
            <td>evicts whatever was previously in cache</td>
            </tr>
            <tr>
            <td>2</td>
            <td><code>second_array</code> loaded</td>
            <td>miss</td>
            <td><strong>evicts <code>first_array</code></strong> due to
            lack of space</td>
            </tr>
            <tr>
            <td>3</td>
            <td><code>first_array</code> loaded again</td>
            <td>miss</td>
            <td><strong>evicts <code>second_array</code></strong> due to
            lack of space</td>
            </tr>
            <tr>
            <td>…</td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, this program will <em>constantly</em> sufffer
            cache misses and since caches misses (and reloads) are
            expensive (in terms of time), the loop’s execution time will
            balloon out of control! Hence, even though we fixed the code
            issue (upper bound on number of iterations, hardware
            artifacts can change the wcet calculations). So now, we need
            to <em>model cache behavior</em> for each program and data
            variable! This is <a
            href="https://user.it.uu.se/~wangyi/pdf-files/2015/lgyrw-acm15.pdf">notoriously
            complicated</a> even for the simplest of programs.</p>
            <p>Other hardware designs further complicate matters,
            e.g.,</p>
            <ul>
            <li>processor pipelining</li>
            <li>prefetching</li>
            <li>branch prediction</li>
            <li>multithreading</li>
            <li>multicore systems</li>
            <li>memory buses</li>
            <li>networks-on-chip</li>
            <li>and too many others to recount here…</li>
            </ul>
            <p>Any contemporary processor design that improves
            performance, <em>turns out to be bad for wcet analysis</em>.
            So, the fewer (or simpler versions of) these features, the
            better it is for the (eventual) safety and certification of
            the system.</p>
            <p>This is one of the main reasons why embedded (and
            especially real-time) systems <strong>prefer simpler
            processors</strong> (simple pipelines, fewer complex
            features, simpler memory/cache architectures, if any) since
            they’re easier to analyze. In fact, many critical systems
            (e.g., aircraft, cars, etc.) <strong>use older
            processors</strong> (often designed in the 1980s and 1990s)
            – even the ones beind design today!</p>
            </section>
            <section id="embedded-processors-1" class="level2"
            data-number="7.2">
            <h2 data-number="7.2"><span
            class="header-section-number">7.2</span> Embedded
            Processors</h2>
            <p>Just as embedded systems are varied, embedded processors
            come in a myriad of shapes and sizes as well. From the very
            small and simple (e.g., DSPs) to the very large and complex
            (modern multicore chips, some with GPUs!). Here is a
            (non-exhaustive) list of the types of embedded
            processors/architectures in use today:</p>
            <ol type="1">
            <li><a href="#microcontrollers">Microcontrollers</a></li>
            <li><a href="#digital-signal-processors-dsps">Digital Signal
            Processors</a> (DSPs)</li>
            <li><a href="#microprocessors">Microprocessors</a> of
            various designs and architectures (e.g., ARM, x86)</li>
            <li><a href="#system-on-a-chip-soc">System-on-a-Chip</a>
            (SoC)</li>
            <li><a
            href="#embedded-accelarators-eg-gpu-enabled-systems">Embedded
            accelerators</a></li>
            <li><a href="#asics-and-fpgas">ASICs and FPGAs</a></li>
            </ol>
            <section id="microcontrollers-1" class="level3"
            data-number="7.2.1">
            <h3 data-number="7.2.1"><span
            class="header-section-number">7.2.1</span>
            Microcontrollers</h3>
            <p>According to <a
            href="https://en.wikipedia.org/wiki/Microcontroller">Wikipedia</a>,</p>
            <blockquote>
            <p>“A microcontroller (MC, UC, or μC) or microcontroller
            unit (MCU) is a small computer on a single integrated
            circuit.”</p>
            </blockquote>
            <p>These may be among the most common type of “processors”
            used in embedded systems. According to many studies,
            <strong><a
            href="https://www.embedded.com/the-two-percent-solution/">more
            than 55%</a></strong> of the world’s processors are
            microntrollers! Microcontrollers are typically used in
            small, yet critical, systems such as car engine control,
            implantable medical devices, thermal monitoring, <a
            href="https://sibin.github.io/papers/2021_BuildSys_PIRMedic_AshishKashinath.pdf">fault
            detection and classification</a> among millions of other
            applications.</p>
            <p>Microcontrollers hardware features typically include,</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 45%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>one (sometimes more) CPU cores</td>
            <td>typically simple <code>4</code> or <code>8</code> bit
            chips</td>
            </tr>
            <tr>
            <td>small pipelined architectues</td>
            <td>sometimes <code>2</code> or <code>4</code> stage
            pipelines</td>
            </tr>
            <tr>
            <td>some limited memory</td>
            <td>typically a few hundred kilobytes, perhaps in the form
            of EEPROMs or FLASH</td>
            </tr>
            <tr>
            <td>some programmable I/O</td>
            <td>to interact with the real world</td>
            </tr>
            <tr>
            <td>low operating frequencies</td>
            <td>e.g., <code>4 KHz</code>; simpler/older processors, yet
            more predictable</td>
            </tr>
            <tr>
            <td>low power consumption</td>
            <td>in the <strong>milliwatts</strong> or
            <strong>microwatts</strong> ranges; might even be
            <strong>nanowatts</strong> when the system is
            <em>sleeping</em></td>
            </tr>
            <tr>
            <td>interrupts (some programmable)</td>
            <td>often <em>real-time</em> (ficed/low latency)</td>
            </tr>
            <tr>
            <td>several general-purpose I/O (GPIO) pins</td>
            <td>for I/O</td>
            </tr>
            <tr>
            <td>timers</td>
            <td>e.g., a programmable interval timer (PIT)</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>There are some <strong>additional features</strong> found
            on some microcontrollers, viz.,</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 45%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>analog to digital (ADC) signal convertors</td>
            <td>to convert incoming (real-world, sensor) data to a
            digital form that the uC can operate on</td>
            </tr>
            <tr>
            <td>digital-to-analog (DAC) convertor</td>
            <td>to do the opposite, convert from digital to analog
            signals to send outputs in that form</td>
            </tr>
            <tr>
            <td>universal asynchronous transmitter/receiver (UART)</td>
            <td>to receive/send data over a <em>serial</em> line</td>
            </tr>
            <tr>
            <td>pulse width modulation (PWM)</td>
            <td>so that the CPU can control <strong>motors</strong>
            (significant for us in autonomous/automotive systems), power
            systems, resistive loads, etc.</td>
            </tr>
            <tr>
            <td>JTAG interace</td>
            <td>debugging interface</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Some examples of popular microcontroller families:</p>
            <table>
            <colgroup>
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="./img/embedded_arch/ATmega169-MLF.jpg" height="100"><br>Atmel
            ATmega</td>
            <td><img src="./img/embedded_arch/Microchip_PIC24HJ32GP202.jpg" height="100">
            <br> Microchip Technology</td>
            <td><img src="./img/embedded_arch/Motorola_68HC11.jpg" height="100">
            <br> Motorola (Freescale)</td>
            <td><img src="./img/embedded_arch/NXP_LPC2387FBD100-5543.jpg" height="100">
            <br> NXP</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Microcontroller programs and data,</p>
            <ul>
            <li>are small –&gt; must fit in memory (since very little
            expandable memory exists)</li>
            <li>often directly programmed in <strong>assembly</strong>!
            <ul>
            <li>sometimes the assembly code might need <em>hand
            tuning</em> –&gt; for both, performance as well as fitting
            into the limited memory</li>
            </ul></li>
            <li><strong>C</strong> is another popular language</li>
            <li><strong>no operating systems</strong> (or very
            rare)!</li>
            <li>sometimes have their own special-purpose programming
            languages or instructions</li>
            </ul>
            </section>
            <section id="digital-signal-processors-dsps-1"
            class="level3" data-number="7.2.2">
            <h3 data-number="7.2.2"><span
            class="header-section-number">7.2.2</span> Digital Signal
            Processors (DSPs)</h3>
            <p>DSPs are specialized microcontrollers optimized for
            <em>digital signal processing</em>. They find wide use in
            audio processing, radar and sonar, speech recognition
            systems, image processing, satellites, telecommunications,
            mobile phones, televisions, etc. Their main goals are to
            isoloate, measure, compress and filter <em>analog</em>
            signals in the real world. They often have <strong>stringent
            real-time constraints</strong>.</p>
            <p>The Texas Instruments DSP chip, <a
            href="https://www.ti.com/lit/ug/spruh79c/spruh79c.pdf?ts=1736945981001">TMS320
            Series</a> is one of the most famous example of this type of
            system:</p>
            <p><img src="./img/embedded_arch/TI_DSP.jpg" height="100" title="Texas Instruments DSP Chip"></p>
            <p>Typical digital signal processing (of any kind) requires
            repetitive mathematical operations over a large number of
            samples, in real-time, viz., - analog to digital conversion
            - maniupulation (the core algorithm) - digital to analog
            conversion</p>
            <p>Often, the <em>entire</em> process must be completed with
            low latency, even within a fixed deadline. They also have
            <strong>low power</strong> requirements since DSPs are often
            used in battery-constrained devices such as mobile phones.
            Hence, the proliferation of specialized DSP chips (instead
            of pure <a href="https://liquidsdr.org">software
            implementations</a>, which also exist; MATLAB has an entire
            <a href="https://www.mathworks.com/help/dsp/index.html">DSP
            System Toolbox</a>).</p>
            <p><strong>Typical DSP architecture</strong>/flow (credit:
            <a
            href="https://en.wikipedia.org/wiki/Digital_signal_processor">Wikipedia</a>):</p>
            <p><img src="./img/embedded_arch/dsp_architecture.png" height="100" title="https://en.wikipedia.org/wiki/Digital_signal_processor"></p>
            <p>These types of chips typically have custom instructions
            for optimizing certain (mathematical) operations (apart from
            the typical <code>add</code>, <code>subtract</code>,
            <code>multiply</code> and <code>divide</code>), e.g., -
            <code>saturate</code>; caps the minimum or maximum value
            that can be held in a fixed-point representation -
            <code>ed</code> ; euclidian distance -
            <code>accumulate</code> instructions ; for <a
            href="https://skills.microchip.com/dsp-features-of-the-microchip-dspic-dsc/693207"><em>multiply-and-accumulate</em></a>
            operations, i.e., <span
            class="math inline"><em>a</em> ← <em>a</em> + (<em>b</em> * <em>c</em>)</span></p>
            <blockquote>
            <p>See the <a
            href="https://ww1.microchip.com/downloads/en/DeviceDoc/sect2.pdf">Microchip
            instruction set</a> details for more information for a
            typical DSP ISA.</p>
            </blockquote>
            <p>DSPs require <em>optimization of streaming data</em> and
            hence, - require <strong>optimized memories and
            caches</strong> → fetch multiple data elements at the same
            time - code may need to be aware of, and
            <strong>explicitly</strong> manipulate caches - may have
            rudimentary OS but <strong>no virtual memory</strong></p>
            </section>
            <section id="microprocessors-1" class="level3"
            data-number="7.2.3">
            <h3 data-number="7.2.3"><span
            class="header-section-number">7.2.3</span>
            Microprocessors</h3>
            <p>Microprocessors are, then,
            <strong>general-purpose</strong> chips (as opposed to
            microcontrollers and DSPs) that are also used extensively in
            embedded systems. They are used in systems that need more
            heavy duty computing/memory and/or more flexibility in terms
            of programming and management of the system. They use a
            number of commodity processor architectures (e.g,, ARM,
            Intel x86).</p>
            <p>Main features of microprocessors:</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 45%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>cores</td>
            <td>single or multicore; powerful</td>
            </tr>
            <tr>
            <td>pipelines</td>
            <td>more complex pipelines; better performance, harder to
            analyze (e.g., wcet)</td>
            </tr>
            <tr>
            <td>clock speeds</td>
            <td>higher clock speeds; <code>100s</code> of khz, or even
            GHz</td>
            </tr>
            <tr>
            <td>ISA</td>
            <td>common ISA; well understood, not custom</td>
            </tr>
            <tr>
            <td>memory</td>
            <td>significant memory; megabytes, even gigabytes</td>
            </tr>
            <tr>
            <td>cache hierarchies</td>
            <td>multiple levels, optimized</td>
            </tr>
            <tr>
            <td>power consumption</td>
            <td>much higher, but can be reduced (e.g., via <a
            href="https://developer.arm.com/documentation/ddi0375/a/functional-overview/intelligent-energy-management--iem-/dynamic-voltage-scaling--dvs-">voltage
            and frequency scaling</a>)</td>
            </tr>
            <tr>
            <td>size, cost</td>
            <td>often higher</td>
            </tr>
            <tr>
            <td>interrupts, timers</td>
            <td>more varied, easily programmable</td>
            </tr>
            <tr>
            <td>I/O</td>
            <td>more interfaces, including commodity ones like USB</td>
            </tr>
            <tr>
            <td>security</td>
            <td>often includes additional hardware security features,
            e.g., <a
            href="https://sefcom.asu.edu/publications/trustzone-explained-cic2016.pdf">ARM
            TrustZone</a>.</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The <a
            href="https://armkeil.blob.core.windows.net/developer/Files/pdf/product-brief/arm-cortex-m85-product-brief.pdf">ARM
            M-85</a> Embedded Microprocessor architecture:</p>
            <p><img src="./img/embedded_arch/arm_cortex_m85.png" width="300" title="Arm M-85"></p>
            <p>When compared to microcontrollers (or even SoCs), most
            microprpcessors <strong>do not</strong> include components
            such as DSPs, ADCs, DACs, etc. It is possible to
            <em>augment</em> the microprocessor to include this
            functionality → usually by <em>connecting one or more
            microcontrollers to it</em>!</p>
            <p>On the software side, microprocessors typically have the
            <strong>most flexibility</strong>:</p>
            <ul>
            <li>general purpose operating systems (e.g., Linux, Android,
            Windows, UNIX, etc.)</li>
            <li>most programming languages and infrastructures (even <a
            href="https://www.docker.com/blog/getting-started-with-docker-for-arm-on-linux/">Docker</a>!)</li>
            <li>large number of tooling, analysis, debugging
            capabilities</li>
            <li>complex code can run, but <strong>increases analysis
            difficulty</strong></li>
            </ul>
            <p>Due to their power (and cost) these types of systems are
            only used when really necessary or in higher-end systems
            such as mobile phones and autonomous cars.</p>
            </section>
            <section id="system-on-a-chip-soc-1" class="level3"
            data-number="7.2.4">
            <h3 data-number="7.2.4"><span
            class="header-section-number">7.2.4</span> System-on-a-Chip
            (SoC)</h3>
            <p>An SoC <strong>integrates</strong> most components in and
            around a processor into a <strong>single</strong> circuit,
            viz.,</p>
            <ul>
            <li>processor/chip → could be a microcontroller or even a
            microprocessor</li>
            <li>memory and memory interfaces</li>
            <li>I/O devices</li>
            <li>buses (memory and I/O)</li>
            <li>storage (e.g., flash) and sometimes even secondary
            storage</li>
            <li>radio modems</li>
            <li>(sometimes) accelerators such as GPUs</li>
            </ul>
            <p>All of these are placed on a <strong>single
            substrate</strong>.</p>
            <p>SoCs are often designed in <code>C++</code>,
            <code>MATLAB</code>, <code>SystemC</code>, etc. Once the
            hardware architectures are defined, additional hardware
            elements are written in hardware description languages,
            e.g., register transfer levels (<code>RTL</code>) <a
            href="#fn5" class="footnote-ref" id="fnref5"
            role="doc-noteref"><sup>5</sup></a>.</p>
            <p>Additional components could include,</p>
            <ul>
            <li>DAC</li>
            <li>ADC</li>
            <li>radio and signal processing</li>
            <li>wireless modems</li>
            <li><a
            href="https://www.amd.com/en/products/adaptive-socs-and-fpgas/soc/zynq-7000.html"><em>programmable
            logic</em></a>.</li>
            <li>networks on chip (NoC) <a href="#fn6"
            class="footnote-ref" id="fnref6"
            role="doc-noteref"><sup>6</sup></a></li>
            </ul>
            <p>In some sense, an SoC is an <em>integration of a
            processor with peripherals</em>. New hardware elements</p>
            <p>Some examples of modern SoCs:</p>
            <div class="multicolumn">
            <div>
            <p><img src="./img/embedded_arch/broadcom_pi_chip.png" width="200" title="Broadcom SoC chip used in the Raspberry Pi"></p>
            <p>Broadcom Soc from Raspberry Pi</p>
            </div>
            <div>
            <p><img src="./img/embedded_arch/Apple_M1.jpg" width="200" title="Apple M1 SoC"></p>
            <p>Apple M1 SoC</p>
            </div>
            </div>
            <p>The integration of all hardware components has some
            interesting side-effects:</p>
            <table>
            <colgroup>
            <col style="width: 34%" />
            <col style="width: 31%" />
            <col style="width: 34%" />
            </colgroup>
            <thead>
            <tr>
            <th>effect</th>
            <th>benefit</th>
            <th>problems</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>tight integration</td>
            <td>better performance, fewer latencies</td>
            <td>cannot replace individual components</td>
            </tr>
            <tr>
            <td>custom code/firmware</td>
            <td>better use of hardware</td>
            <td>not reusable in other systems</td>
            </tr>
            <tr>
            <td>custom software libraries</td>
            <td>easier programming of SoC</td>
            <td>reduces code reusability in other systems</td>
            </tr>
            <tr>
            <td>low power consumption</td>
            <td>better battery life, less heat</td>
            <td>(potentially) slower</td>
            </tr>
            </tbody>
            </table>
            <p>Depending on the processor/microcontroller that sits at
            the center of the SoC, the software stack/capabilities can
            vary. Many commons SoCs exhibit the following software
            properties:</p>
            <ul>
            <li>usually use contemporary operating systems, though
            optimized for embedded/SoC systems → e.g., <a
            href="http://www.raspbian.org">Raspbian</a> aka Rasberry Pi
            OS. Hence, they can handle multiprocessing, virtual memory,
            different scheduling policies, etc.</li>
            <li>can be programmed using most common programming
            languages → <code>C</code>, <code>C++</code>,
            <code>python</code>, <code>java</code>, even <a
            href="https://medium.com/@kenichisasagawa/rediscovering-the-joy-of-hardware-hacking-with-raspberry-pi-and-lisp-574c833ab20e"><code>lisp</code></a>!</li>
            </ul>
            <p>The Raspberry Pi is a common example of a system that
            uses a <a
            href="https://www.raspberrypi.com/documentation/computers/processors.html">Broadcom
            BCM series of SoCs</a>. We use the <a
            href="https://www.raspberrypi.com/documentation/computers/processors.html#bcm2711">BCM2711</a>
            SoC in our course for the Raspberry Pi 4-B.</p>
            </section>
            <section
            id="embedded-accelarators-e.g.-gpu-enabled-systems-1"
            class="level3" data-number="7.2.5">
            <h3 data-number="7.2.5"><span
            class="header-section-number">7.2.5</span> Embedded
            Accelarators (e.g. GPU-enabled systems)</h3>
            <p>There are hardware platforms that include
            <strong>accelerators</strong> in embedded systems, e.g., <a
            href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">GPUs</a>,
            <a
            href="https://www.nature.com/articles/s41928-022-00778-y">AI-enabled
            silicon</a>, <a
            href="https://www.amd.com/en/products/adaptive-socs-and-fpgas/soc/zynq-7000.html">extra
            programmable FPGA fabric</a>, <a
            href="https://developer.arm.com/documentation/100230/0002/functional-description/external-coprocessors/configuring-which-coprocessors-are-included-in-secure-and-non-secure-states">security
            features</a>, etc. The main idea is that certain computation
            can be <em>offloaded</em> to these accelerators while the
            main CPU continues to process other code/requests. The
            accelerators are specialized for certain computations (e.g.,
            parallel matrix multiplications on GPUs, AES encryption).
            Some chips include FPGA fabric where the designer/user can
            <em>implement their own custom logic/accelerators</em>.</p>
            <p>In a loose sense, the <a
            href="https://navio2.hipi.io">Navio2</a> can be considered
            as a hardware coprocessor for the Raspbery Pi.</p>
            <p>The <a
            href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVidia
            Jetson Orin</a> is a good example of an AI/GPU focussed
            embedded processor:</p>
            <p><img src="./img/embedded_arch/jetson-agx-orin-4c25-d-2x.png" width="300" title="NVIDIA Jetson AGX Orin 64 GB"></p>
            <p><br></p>
            <p>This system’s <a
            href="https://www.techpowerup.com/gpu-specs/jetson-agx-orin-64-gb.c4085">specifications</a>:</p>
            <ul>
            <li>1300 MHz clock speeds</li>
            <li>64 GB Memory</li>
            <li>256 bit memory bus</li>
            <li>204 GB/s bandwidth</li>
            <li>supports a variety of graphics features (DirectX,
            OpenGL, OpenCL, CUDA, Vulkan and Shader Models )</li>
            <li>maximum of 60W power</li>
            <li><strong>275 trillion</strong> operations/s (TOPS)!</li>
            </ul>
            <p>These systems are finding a lot of use in autonomous
            systems since they pack so much processing power into such a
            small form factor</p>
            </section>
            <section id="asics-and-fpgas-1" class="level3"
            data-number="7.2.6">
            <h3 data-number="7.2.6"><span
            class="header-section-number">7.2.6</span> ASICs and
            FPGAs</h3>
            <p>Application-specific integrated circuits (ASICs) and
            field programmable gate arrays (FPGAs). These platforms
            combine the advantages of both, hardware (<em>speed</em>)
            and software (<em>flexibility/programmability</em>). They
            are similar, yet different. Both are semiconductor devices
            that include <strong>programmable logic gates</strong> but
            an ASIC is <em>static</em> – i.e., once the board has been
            “programmed” it cannot be changed while an FPGA, as the name
            implies, allows for “reprogramming”.</p>
            <p>ASICs are <strong>custom-designed</strong> for specific
            applications and provide high efficiency and performance.
            FPGAs are <strong>reprogramamble</strong> devices that
            provide significant flexibility. Many designers also used it
            for prototyping hardware components (before they are
            eventually included either in the processors or custom
            ASICs). The <a
            href="https://www.wevolver.com/article/asic-vs-fpga">choice
            between ASICs and FPGAs</a> depends entirely on the
            application requirements and other factors such as cost.</p>
            <table>
            <colgroup>
            <col style="width: 50%" />
            <col style="width: 50%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="./img/embedded_arch/asic.webp" width="200"></td>
            <td><img src="./img/embedded_arch/xilinx_spartan_fpga.webp" width="200"></td>
            </tr>
            <tr>
            <td>An ASIC</td>
            <td>Xilinx Spartan FPGA</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <section id="asics-1" class="level4" data-number="7.2.6.1">
            <h4 data-number="7.2.6.1"><span
            class="header-section-number">7.2.6.1</span> ASICs</h4>
            <p>These are specialized semiconductor devices – to
            implement a <em>custom</em> function, e.g., cryptocurrency
            mining, nuclear reactor control, televisions. ASICs are
            tailored to their specific applications. Once created, it
            cannot be reprogrammed or modified. ASICs are created using
            a process known as <a
            href="https://www.sciencedirect.com/topics/physics-and-astronomy/photolithography">photolithography</a>,
            a method to prepare nanoparticles, that allows components to
            be “etched” on to a silicon wafer.</p>
            <p>The <a
            href="https://www.wevolver.com/article/the-ultimate-guide-to-asic-design-from-concept-to-production">ASIC
            design process</a>, while expensive and time consuming,
            becomes valuable for <em>high-volume</em> products as the
            per-unit cost decrease when production nunbers increase.</p>
            <table>
            <thead>
            <tr>
            <th>advantages</th>
            <th>disadvantages</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>high performance</td>
            <td>lack of flexibility</td>
            </tr>
            <tr>
            <td>low power consumption</td>
            <td>high initial costs</td>
            </tr>
            <tr>
            <td>small form factor</td>
            <td>long development time</td>
            </tr>
            <tr>
            <td>ip protection</td>
            <td>obsolescence risk</td>
            </tr>
            <tr>
            <td>good for mass production</td>
            <td>risks with manufacturing yields</td>
            </tr>
            <tr>
            <td>can integrate multiple functions</td>
            <td>design complexity</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="fpgas-1" class="level4" data-number="7.2.6.2">
            <h4 data-number="7.2.6.2"><span
            class="header-section-number">7.2.6.2</span> FPGAs</h4>
            <p>These are also semiconductor devices but they can be
            <strong>preprogrammed</strong> to implement various circuits
            and functions. Designers can change the functionality
            <strong>after</strong> the curcuits have been embossed onto
            the hardware. Hence, they’re good for systems that might
            require changes at design time and rapid prototyping. An
            FPGA is a collection of programmable logic and
            interconnects. They include lookup tables (LUTs) and other
            parts that can be used to develop multiple, fairly
            wide-ranging, functions. The programmable blocks can be
            connected to each other via the interconnects. Some FPGAs
            even come with additional flash memory.</p>
            <p><a href="https://www.wevolver.com/article/fpga">FPGAs are
            programmed</a> using hardware description languages such as
            Verilog/VHDL.</p>
            <table>
            <thead>
            <tr>
            <th>advantages</th>
            <th>disadvantages</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>flexibility</td>
            <td>lower performance</td>
            </tr>
            <tr>
            <td>shorter development time</td>
            <td>higher power consumption</td>
            </tr>
            <tr>
            <td>upgradability</td>
            <td>high design complexity</td>
            </tr>
            <tr>
            <td>lower (initial) costs</td>
            <td>higher per-unit costs</td>
            </tr>
            <tr>
            <td>better processing capabilities</td>
            <td>design complexity</td>
            </tr>
            <tr>
            <td>lower obsolescence risks</td>
            <td>larger form factor</td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            </section>
            <section id="communication-and-io-1" class="level2"
            data-number="7.3">
            <h2 data-number="7.3"><span
            class="header-section-number">7.3</span> Communication and
            I/O</h2>
            <p>Embedded systems need to <strong>communicate</strong>
            and/or <strong>interface</strong> with various elements:</p>
            <ul>
            <li>the physical world via sensors and actuators</li>
            <li>computers for programming (of the embedded system) or
            for data transfer</li>
            <li>with other embedded systems/nodes</li>
            <li>handheld devices</li>
            <li>with the internet (either public or to access back end
            servers)</li>
            <li>satellites?</li>
            </ul>
            <p>Hence a large number of communication standards and I/O
            interfaces have been developed over the years. Let’s look at
            a few of them:</p>
            <ol type="1">
            <li><a href="#uart--rs-232">serial (UART)</a> → e.g., RS
            232</li>
            <li><a href="#synchronous--i2c-and-spi">synchronous</a> →
            I2C, SPI</li>
            <li><a href="#general-purpose-io-gpio">general-purpose
            I/O</a> → GPIO</li>
            <li><a href="#jtag-debugging-interface">debugging
            interface</a> → JTAG</li>
            <li><a href="#controller-area-network-can">embedded internal
            communication</a> → CAN</li>
            <li><a href="#other-broadly-used-protocols">other broadly
            used protocols</a> → USB, Ethernet/WiFi, Radio,
            Bluetooth</li>
            </ol>
            <section id="uart-rs-232-1" class="level3"
            data-number="7.3.1">
            <h3 data-number="7.3.1"><span
            class="header-section-number">7.3.1</span> UART |
            RS-232</h3>
            <p>Serial communication standards are used extensively
            across many domains, mainly due to their
            <strong>simplicity</strong> and <strong>low hardware
            overheads</strong>. The most common among these are the
            <em>asynchronous serial communication systems</em>.</p>
            <p>From <a
            href="https://en.wikipedia.org/wiki/Asynchronous_serial_communication">Wikipedia</a>:</p>
            <blockquote>
            <p>Asynchronous serial communication is a form of serial
            communication in which the communicating endpoints’
            interfaces are not continuously synchronized by a common
            clock signal. Instead of a common synchronization signal,
            the data stream contains synchronization information in form
            of start and stop signals, before and after each unit of
            transmission, respectively. The start signal prepares the
            receiver for arrival of data and the stop signal resets its
            state to enable triggering of a new sequence.</p>
            </blockquote>
            <p>The following figure shows a communication sample that
            demonstrates these principles:</p>
            <p><img src="img/embedded_arch/comms/Puerto_serie_Rs232.png" width="300"></p>
            <p>We see that each byte has a <code>start</code> bit,
            <code>stop</code> bit and eight <code>data</code> bits. The
            last bit is often used as a <code>parity</code> bit. All of
            these “standards” (i.e., the start/stop/parity bits) must be
            <em>agreed upon ahead of time</em>.</p>
            <p>A <strong>universal asynchronous
            receiver-transmitter</strong> (<strong>UART</strong>) then
            is a peripheral device for such asynchronous commnication;
            the data format and transmission speeds are configurable. It
            sends data bits <em>one-by-one</em> (from least significant
            to most). The precise timing is handlded by the
            communication channel.</p>
            <p>The electric <em>signalling levels</em> are handled by an
            external driver circuit. Common signal levels:</p>
            <ul>
            <li><a
            href="https://www.analog.com/en/resources/technical-articles/fundamentals-of-rs232-serial-communications.html">RS
            232</a></li>
            <li><a
            href="https://www.renkeer.com/what-is-rs485/">RS-485</a></li>
            <li>raw <a
            href="https://www.seeedstudio.com/blog/2019/12/11/rs232-vs-ttl-beginner-guide-to-serial-communication">TTL</a></li>
            </ul>
            <p>Here we will focus on the <strong>RS-232</strong>
            standard since it is most widely used UART signaling level
            standard today. The full name of the standard is:
            “EIA/TIA-232-E Interface Between Data Terminal Equipment and
            Data Circuit-Termination Equipment Employing Serial Binary
            Data Interchange” (“EIA/TIA” stands for the Electronic
            Industry Association and the Telecommunications Industry
            Association). It was introduced in 1962 and has since been
            updated <em>four</em> times to meet evolving needs.</p>
            <p>The RS-232 is a <em>complete</em> standard in that it
            specifies,</p>
            <ul>
            <li>(common) voltage and signal levels</li>
            <li>(common) pin and wiring configurations</li>
            <li>(minimal) control information between
            host/peripherals</li>
            </ul>
            <p>The RS-232 specifies the electrical, functional and
            mechanical characteristics to meet all of the above
            criteria.</p>
            <p>For instance, the <em>electrical</em> characteristics are
            defined in the following figure:</p>
            <p><img src="img/embedded_arch/comms/rs232-electrical.gif" width="400"></p>
            <p>Details:</p>
            <ul>
            <li><strong>high</strong> level [<strong>logical
            <code>0</code></strong>] (aka “marking”) → <code>+5V</code>
            to <code>+15V</code> (realistically <code>+3V</code> to
            <code>+15V</code>)</li>
            <li><strong>low</strong> level [<strong>logical
            <code>1</code></strong>] (aka “spacing”) → <code>-5V</code>
            to <code>-15V</code> (realistically <code>-3V</code> to
            <code>-15V</code>)</li>
            </ul>
            <p>Other properties also defined, <em>e.g.</em>, “<a
            href="https://en.wikipedia.org/wiki/Slew_rate">slew
            rate</a>”, impedance, capacitive loads, etc.</p>
            <p>The standard also defines the mechanical interfaces,
            i.e., the <em>pin connector</em>:</p>
            <p><img src="img/embedded_arch/comms/rs232_pins.gif" width="400"></p>
            <p>While the official standard calls for a 25-pin connector,
            it is rarely used. Instead, the <strong>9-pin</strong>
            connector (shown on the right in the above figure) is in
            common use.</p>
            <p>You can read more details about the standard here: <a
            href="https://www.analog.com/en/resources/technical-articles/fundamentals-of-rs232-serial-communications.html">RS
            232</a></p>
            </section>
            <section id="synchronous-i2c-and-spi-1" class="level3"
            data-number="7.3.2">
            <h3 data-number="7.3.2"><span
            class="header-section-number">7.3.2</span> Synchronous |
            I<sup>2</sup>C and SPI</h3>
            <p>Synchronous Serial Interfaces (SSIs) are a widely used in
            industrial applications between a master device
            (e.g. controller) and a slave device (e.g. sensor). It is
            based on the <a
            href="https://www.analog.com/media/en/technical-documentation/tech-articles/guide-to-selecting-and-using-rs232-rs422-and-rs485-serial-data-standards--maxim-integrated.pdf">RS-422</a>
            standards and has a high protocol efficiency as well
            multiple hardware implementations.</p>
            <p>SSI properties:</p>
            <ul>
            <li><a
            href="https://en.wikipedia.org/wiki/Differential_signalling">differential
            signalling</a></li>
            <li>simplex (i.e., unidirectional communication only)</li>
            <li>non-multiplexed</li>
            <li>point-to-point and</li>
            <li>uses time-outs to frame the data.</li>
            </ul>
            <section id="i2c-1" class="level4" data-number="7.3.2.1">
            <h4 data-number="7.3.2.1"><span
            class="header-section-number">7.3.2.1</span>
            I<sup>2</sup>C</h4>
            <p>The <a
            href="https://www.ti.com/lit/an/sbaa565/sbaa565.pdf">Inter-Integrated
            Circuit</a> (I<sup>2</sup>C, IIC, I2C) is a synchronous,
            multi-controller/multi-target (historically termed as
            multi-master/multi-slave), single-ended, serial
            communication bus. I2C systems are used for <em>attaching
            low-power integrated circuits to processors and
            microcontrollers</em> – usually for short distance or
            <em>intra-board communication</em>.</p>
            <p>I2C components are found in a wide variety of products,
            <em>e.g.,</em></p>
            <ul>
            <li>EEPROMs</li>
            <li>VGA/DVI/HDMI connectors</li>
            <li>NVRAM chips</li>
            <li>real-time clocks</li>
            <li>reading hardware monitors and sensors</li>
            <li>controlling actuators</li>
            <li>DAC/ADC</li>
            <li>controlling LCD/OLEDs displays</li>
            <li>changing computer display settings (contrast,
            brightness, etc.)</li>
            <li>controlling speaker volume</li>
            <li>and many many more</li>
            </ul>
            <p>The main advantage of I2C is that a microcontroller can
            control a <em>network</em> of chips with just
            <strong>two</strong> general-purpose I/O pins (serial data
            line and a serial clock line) and software. A controller
            device can communicate with any target device through a
            unique I2C address sent through the serial data line. Hence
            the two signals are:</p>
            <table style="width:100%;">
            <colgroup>
            <col style="width: 30%" />
            <col style="width: 35%" />
            <col style="width: 35%" />
            </colgroup>
            <thead>
            <tr>
            <th>line</th>
            <th>voltage</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>serial data line (SDL)</td>
            <td><code>+5V</code></td>
            <td>transmit data to or from target devices</td>
            </tr>
            <tr>
            <td>serial clock line (SCL)</td>
            <td><code>+3V</code></td>
            <td>synchronously clock data in or out of the target
            device</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Both are bidirectional and pulled up with resistors.</p>
            <p>Here is a typical implementation of I2C:</p>
            <p><img src="img/embedded_arch/comms/i2c_implementation.png" width="400"></p>
            <p>An I2C chip example (used for controlling certain TV
            signals):</p>
            <p><img src="img/embedded_arch/comms/i2c_tv_control.jpg" width="100"></p>
            <p>I2C is half-duplex communication where only a single
            controller or a target device is sending data on the bus at
            a time. In comparison, the serial peripheral interface (SPI)
            is a full-duplex protocol where data can be sent to and
            received back at the same time. An I2C controller device
            starts and stops communication, which removes the potential
            problem of bus contention. Communication with a target
            device is sent through a unique address on the bus. This
            allows for both multiple controllers and multiple target
            devices on the I2C bus.</p>
            <p>I2C communication details (initiated from the controller
            device):</p>
            <table>
            <colgroup>
            <col style="width: 70%" />
            <col style="width: 29%" />
            </colgroup>
            <thead>
            <tr>
            <th>condition</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>I2C <code>START</code></td>
            <td>the controller device first pulls the SDA low and then
            pulls the SCL low</td>
            </tr>
            <tr>
            <td>I2C <code>STOP</code></td>
            <td>the SCL releases high and then SDA releases high</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><img src="img/embedded_arch/comms/i2c_start_stop.png" width="300"></p>
            <p><br></p>
            <p>I2C communication is split into: <strong>frames</strong>.
            Communciation starts when one controller sends an
            <code>address frame</code> after a <code>START</code>. This
            is followed by one or more <code>data frames</code>, each
            consisting of <strong>one byte</strong>. Each frame also has
            an <code>acknowledgement</code> bit. An example of two I2C
            communication frames:</p>
            <p><img src="img/embedded_arch/comms/i2c_frames.png"></p>
            <p><br></p>
            <p>You can read more at: <a
            href="https://www.ti.com/lit/an/sbaa565/sbaa565.pdf">I2C</a>.</p>
            </section>
            <section id="spi-1" class="level4" data-number="7.3.2.2">
            <h4 data-number="7.3.2.2"><span
            class="header-section-number">7.3.2.2</span> SPI</h4>
            <p>The <a
            href="https://www.analog.com/en/resources/analog-dialogue/articles/introduction-to-spi-interface.html">Serial
            Peripheral Interface</a> (SPI) has become the de facto
            standard for <em>synchronous</em> serial communication. It
            is used in embedded systems, especially between
            microcontrollers and peripheral ICs such as sensors, ADCs,
            DACs, shift registers, SRAM, <em>etc.</em></p>
            <p>The main aspect of SPI is that one main device
            <strong>orchestrates communication</strong> with one ore
            more sub/peripheral devices by <strong>driving the clock and
            chip select signals</strong>.</p>
            <p>SPI interface properties:</p>
            <ul>
            <li><em>synchronous</em></li>
            <li><em>full duplex</em></li>
            <li><em>main-subnode</em> (formerly called
            “master-slave”)</li>
            <li>data from the main or the subnode is synchronized on the
            rising or falling clock edge</li>
            <li>main and subnode can transmit data at the same time</li>
            <li>interface can be 3 or 4-wire (4 wire version is more
            popular)</li>
            </ul>
            <table>
            <colgroup>
            <col style="width: 46%" />
            <col style="width: 53%" />
            </colgroup>
            <thead>
            <tr>
            <th>microchip SPI</th>
            <th>basic SPI Interface</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/embedded_arch/comms/spi_microchip.avif" width="100"></td>
            <td><img src="img/embedded_arch/comms/spi_basic.png" width="500"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The SPI interface contains the following wires:</p>
            <table>
            <colgroup>
            <col style="width: 25%" />
            <col style="width: 41%" />
            <col style="width: 32%" />
            </colgroup>
            <thead>
            <tr>
            <th>signal</th>
            <th>description</th>
            <th>function</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><code>SCLK</code></td>
            <td>serial clock</td>
            <td>clock signal from main</td>
            </tr>
            <tr>
            <td><code>CS</code></td>
            <td>chip/serial select</td>
            <td>To select which host to communicate with</td>
            </tr>
            <tr>
            <td><code>MOSI</code></td>
            <td>main out, subnode In</td>
            <td>serial data out (SDO) for host to target
            communication</td>
            </tr>
            <tr>
            <td><code>MISO</code></td>
            <td>main in, subnode Out</td>
            <td>serial data in (SDI) for target to host
            communication</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The main node generates the clock signal. Data
            transmissions between main ahd sub nodes is synchronized by
            that clock signal generated by main. SPI devices support
            <em>much higher clock frequencies</em> than I2C. The
            <code>CS</code> signal is used to select the subnode. Note
            that this is an <strong>active low signal</strong>,
            <em>i.e.,</em> a low (<code>0</code>) is a selection and a
            high (<code>1</code>) is a disconnect. SPI is a full-duplex
            interface; both main and subnode can send data at the same
            time via the MOSI and MISO lines respectively. During SPI
            communication, the data is simultaneously transmitted
            (shifted out serially onto the MOSI/SDO bus) and received
            (the data on the bus (MISO/SDI) is sampled or read in).</p>
            <p><strong>Example</strong>: the <a
            href="https://www.analog.com/en/resources/analog-dialogue/articles/introduction-to-spi-interface.html">following
            example</a> demonstrates the significant savings and
            simplification in systems design (reduce the number of GPIO
            pins required).</p>
            <p>Consider the ADG1412 switch being managed by a
            microcontroller as follows:</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example1.svg" width="300"></p>
            <p>Now, as the number of switches increases, the requirement
            on GPIO pins also increases significantly. A
            <code>4x4</code> configuration requires <code>16</code> GPI
            pins, thus reducing the number of pins available for the
            microcontroller for other tasks, as follows:</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example2.svg" width="300"></p>
            <p>One approach to reduce the number of pins would be to use
            a serial-to-parallel convertor:</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example3.svg" width="300"></p>
            <p>This reduces the pressure on the number of GPIO pins but
            still introduces additional circuitry.</p>
            <p>Using an SPI-enabled microcontroller reduces the number
            of GPIOs required and and eliminates the overheads of the
            needing additional chips (serial-to-paralle convertor):</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example4.svg" width="300"></p>
            <p>In fact, using a different SPI configuration
            (“<strong>daisy-chain</strong>”), we can optimize the GPIO
            count even further!</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example5.svg" width="300" height="250"></p>
            <p>You can read more about <a
            href="https://www.analog.com/en/resources/analog-dialogue/articles/introduction-to-spi-interface.html">SPI
            here</a>.</p>
            </section>
            </section>
            <section id="general-purpose-io-gpio-1" class="level3"
            data-number="7.3.3">
            <h3 data-number="7.3.3"><span
            class="header-section-number">7.3.3</span> General-Purpose
            I/O (GPIO)</h3>
            <p>A GPIO is a <strong>signal pin</strong> on an integrated
            circuit or board that can be used to perform <em>digital I/O
            operations</em>. By design, it <strong>has no predefined
            purpose</strong> → can be used by hardware/software
            developers to perform functions <em>they choose</em>,
            <em>e.g.,</em></p>
            <ul>
            <li>GPIO pins can be enabled or disabled.</li>
            <li>GPIO pins can be configured to be input or output.</li>
            <li>input values are readable, often with a 1 representing a
            high voltage, and a 0 representing a low voltage.</li>
            <li>input GPIO pins can be used as “interrupt” lines, which
            allow a peripheral board connected via multiple pins to
            signal to the primary embedded board that it requires
            attention.</li>
            <li>output pin values are both readable and writable.</li>
            </ul>
            <p>GPIOs can be implemented in a variety of ways,</p>
            <ul>
            <li>as a <em>primary</em> function of the microcontrollers,
            <em>e.g.</em>, <a
            href="https://www.geeksforgeeks.org/programmable-peripheral-interface-8255/">Intel
            8255</a></li>
            <li>as an <em>accessory</em> to the chip</li>
            </ul>
            <p>While microcontrollers may use GPIOs are their primary
            external interface, many a time the pins may be capable of
            other functions as well. In such instances, it may be
            necessary to configure the pins using other functions.</p>
            <p>Some examples of chips with GPIO pins:</p>
            <table>
            <colgroup>
            <col style="width: 27%" />
            <col style="width: 31%" />
            <col style="width: 40%" />
            </colgroup>
            <thead>
            <tr>
            <th>Intel 8255</th>
            <th>PIC microchip</th>
            <th>ASUS Tinker</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/embedded_arch/comms/gpio_Ic-photo-Intel--D8255.JPG" width="250"></td>
            <td><img src="img/embedded_arch/comms/gpio_microchip_PIC18F8720.jpg" width="150"></td>
            <td><img src="img/embedded_arch/comms/gpio_Asus_Tinker_Board.jpg" width ="200"></td>
            </tr>
            <tr>
            <td>24 GPIO pins</td>
            <td>29 GPIO pins</td>
            <td>28 GPIO pins</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>GPIOs are used in a diverse variety of applications,
            limited only by the electrical and timing specifications of
            the GPIO interface and the ability of software to interact
            with GPIOs in a sufficiently timely manner.</p>
            <p>Some “properties”/applications of GPIOs:</p>
            <ul>
            <li>GPIOs use standard logic levels and cannot supply
            significant current to output loads</li>
            <li>high-current output buffers or relays can be used to
            control high-power devices</li>
            <li>input buffers, relays, or opto-isolators translate
            incompatible signals to GPIO logic levels</li>
            <li>GPIOs can control or monitor other circuitry on a board,
            such as enabling/disabling circuits, reading switch states,
            and driving LEDs</li>
            <li>multiple GPIOs can implement bit banging communication
            interfaces like I²C or SPI</li>
            <li>GPIOs can control analog processes via PWM, adjusting
            motor speed, light intensity, or temperature</li>
            <li>PWM signals from GPIOs can be converted to analog
            control voltages using RC filters</li>
            </ul>
            <p>GPIO interfaces vary widely. Most commonly, they’re
            simple <em>groups of pins</em> that can switch between
            input/output. On the other hand, each pin can be set up
            differently → set up/accept/source different voltages/drive
            strengths/pull ups and downs.</p>
            <p>Programming the GPIO:</p>
            <ul>
            <li>usually pin states are exposed via different interfaces,
            <em>e.g.,</em> <strong>memory-mapped I/O</strong>
            peripherals or dedicated I/O port instructions</li>
            <li>input values can be used as interrupts (IRQs)</li>
            </ul>
            <p>For more information on programming/using GPIOs, read
            these: <a
            href="https://docs.oracle.com/javame/8.0/me-dev-guide/gpio.htm">GPIO
            setup and use</a>, <a
            href="https://www.instructables.com/Raspberry-Pi-Python-scripting-the-GPIO/">Python
            scripting the GPIO in Raspberry Pis</a>, <a
            href="https://docs.nordicsemi.com/bundle/ps_nrf52810/page/gpio.html">general
            purpose I/O</a>, <a
            href="https://projects.raspberrypi.org/en/projects/physical-computing/1">GPIO
            setup in Raspberry Pi</a>.</p>
            </section>
            <section id="jtag-debugging-interface-1" class="level3"
            data-number="7.3.4">
            <h3 data-number="7.3.4"><span
            class="header-section-number">7.3.4</span> JTAG Debugging
            Interface</h3>
            <p>The JTAG standard (named after the “Joint Test Action
            Group”), technically the <a
            href="https://web.archive.org/web/20170830070123/http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/jtag-101-ieee-1149x-paper.pdf">IEEE
            Std 1149.1-1990 IEEE Standard Test Access Port and
            Boundary-Scan Architecture</a>, is an industry standard for
            <strong>testing and verification of printed circuit
            boards</strong>, <em>after manufacture</em>.</p>
            <p>“JTAG”, depending on the context, could stand for one or
            more of the following:</p>
            <ul>
            <li>implementation of IEEE 1149.x for Board Test, or
            Boundary Scan testing</li>
            <li>appliance used to program on board flash or eeprom
            devices on a circuit board</li>
            <li>hardware device used to debug microprocessor
            software</li>
            <li>hardware device used to test a board using Boundary
            Scan</li>
            </ul>
            <p>The basic building block of a JTAG OCD is the
            <strong>Test Access Point</strong> or <strong>TAP
            controller</strong>. This allows access to all the custom
            features within a specific processor, and must support a
            minimum set of commands. On-chip debugging is a
            <em>combination of hardware and software</em>.</p>
            <table>
            <thead>
            <tr>
            <th>type</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>hardaware</td>
            <td><strong>on chip debug</strong> (OCD)</td>
            </tr>
            <tr>
            <td>software</td>
            <td><strong>in-circuit-emulator</strong> (ICE)/JTAG
            emulator</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The off-chip parts are actually PC peripherals that need
            corresponding drivers running on a separate computer. On
            most systems, JTAG-based debugging is available from the
            very first instruction after CPU reset, letting it assist
            with development of early boot software which runs before
            anything is set up. The JTAG emulator allows developers to
            access the embedded system at the <strong>machine code
            level</strong> if needed! Many silicon architectures (Intel,
            ARM, PowerPC, etc.) have built entire infrastructures and
            extensions around JTAG.</p>
            <p>A high-level overview of the JTAG architecture/use:</p>
            <p><img src="img/embedded_arch/comms/jtag_high_level.png" width="400"></p>
            <p><br></p>
            <p>JTAG now allows for,</p>
            <ul>
            <li>processors can not be <em>halted</em>,
            <em>single-stepped</em> or <em>run freely</em></li>
            <li>can set code <em>breakpoints</em> for both, code in RAM
            as well as ROM/flash</li>
            <li><em>data breakpoints</em> are available</li>
            <li><em>bulk data download</em> to RAM</li>
            <li><em>access to registers and buses</em>, even without
            halting the processors!</li>
            <li><em>complex logic routines</em>, <em>e.g.,</em> ignore
            the first seven accesses to a register from one particular
            subroutine</li>
            </ul>
            <p>JTAG allows for <em>device programmer hardware</em>
            allows for transfering data into internal,
            <em>non-volatile</em> memory of the system! Hence, we can
            use JTAGs to <strong>program</strong> devices such as FPGAs.
            In fact, many memory chips also have JTAG interfaces. Some
            modern chips also allow access to the the (internal and
            external) data buses via JTAG.</p>
            <p><strong>JTAG interface</strong>: depending on the actual
            interface, JTAG has 2/4/5 pins. The 4/5 pin versions are
            designed so that <em>multiple chips</em> on a board can have
            their JTAG lines <strong>daisy-chained</strong> together if
            specific conditions are met.</p>
            <p>Schematic Diagram of a JTAG enabled device:</p>
            <p><img src="img/embedded_arch/comms/jtag_schematic_diagram.gif" width="300"></p>
            <p>The various pins signals in the JTAG TAP are:</p>
            <table>
            <colgroup>
            <col style="width: 38%" />
            <col style="width: 61%" />
            </colgroup>
            <thead>
            <tr>
            <th>signal</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><code>TCK</code></td>
            <td>synchronizes the internal state machine operations</td>
            </tr>
            <tr>
            <td><code>TMS</code></td>
            <td>sampled at the rising edge of <code>TCK</code> to
            determine the next state</td>
            </tr>
            <tr>
            <td><code>TDI</code></td>
            <td>data shifted into the device’s test or programming
            logic; sampled at the rising edge of <code>TCK</code> when
            the internal state machine is in the correct state</td>
            </tr>
            <tr>
            <td><code>TDO</code></td>
            <td>represents the data shifted out of the device’s test or
            programming logic and is valid on the falling edge of
            <code>TCK</code> when the internal state machine is in the
            correct state</td>
            </tr>
            <tr>
            <td><code>TRST</code></td>
            <td>optional pin which, when available, can reset the tap
            controller’s state machine</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The TAP controller implements the following state
            machine:</p>
            <p><img src="img/embedded_arch/comms/jtag_tap_state_machine.gif" width="300"></p>
            <p><br></p>
            <p>To use the JTAG interface,</p>
            <ul>
            <li>host is connected to the target’s JTAG signals
            (<code>TMS</code>, <code>TCK</code>, <code>TDI</code>,
            <code>TDO</code>, etc.) through some kind of JTAG
            adapter</li>
            <li>adapter connects to the host using some interface such
            as USB, PCI, Ethernet, etc.</li>
            <li>host communicates with the TAPs by manipulating
            <code>TMS</code> and <code>TDI</code> in conjunction with
            <code>TCK</code></li>
            <li>host reads results through <code>TDO</code> (which is
            the only standard host-side input)</li>
            <li><code>TMS</code>/<code>TDI</code>/<code>TCK</code>
            output transitions create the basic JTAG communication
            primitive on which higher layer protocols build</li>
            </ul>
            <p><br></p>
            <p>For more information about JTAG, read: <a
            href="https://web.archive.org/web/20170830070123/http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/jtag-101-ieee-1149x-paper.pdf">Intel
            JTAG Overview</a>, <a
            href="https://forums.raspberrypi.com/viewtopic.php?t=286115">Raspberry
            Pi JTAG programming</a>, <a
            href="https://www.xjtag.com/about-jtag/jtag-a-technical-overview/">Technical
            Guide to JTAG</a> and the <a
            href="https://en.wikipedia.org/wiki/JTAG">JTAG Wikipedia
            Entry</a> is quite detailed.</p>
            </section>
            <section id="controller-area-network-can-1" class="level3"
            data-number="7.3.5">
            <h3 data-number="7.3.5"><span
            class="header-section-number">7.3.5</span> Controller Area
            Network (CAN)</h3>
            <p>CAN is a vehicle bus standard to enable efficient
            communication between electronic control units (ECUs). CAN
            is,</p>
            <ul>
            <li>broadcast-based</li>
            <li>message-oriented</li>
            <li>uses arbitration → for data
            integrity/prioritization</li>
            </ul>
            <p>CAN <strong>does not</strong> need a a host controller.
            ECUs connected via the CAN bus can easily share information
            with each other. all ECUs are connected on a two-wire bus
            consisting of a twisted pair: CAN high and CAN low. The
            wires are often color coded:</p>
            <table>
            <tbody>
            <tr>
            <td>CAN high</td>
            <td>yellow</td>
            </tr>
            <tr>
            <td>CAN low</td>
            <td>green</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <table>
            <colgroup>
            <col style="width: 42%" />
            <col style="width: 57%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/embedded_arch/comms/can-twisted-can-bus-wiring-harness-high-low-green-yellow.svg" width="200"></td>
            <td><img src="img/embedded_arch/comms/CAN-bus_basic.svg" width="300"></td>
            </tr>
            <tr>
            <td>CAN wiring</td>
            <td>multi-ecu CAN setup</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>An ECU in a vehicle consists of:</p>
            <table>
            <tr>
            <th>
            components
            </th>
            <th>
            internal architecture
            </th>
            </tr>
            <tr>
            <td>
            <ul>
            <li>
            <b>microcontroller</b> to interpret/send out CAN messages
            </li>
            <li>
            <b>CAN controller</b> ensures all communication adheres to
            CAN protocols
            </li>
            <li>
            <b>CAN transceiver</b> connects CAN controller to the
            physical wires
            </li>
            </ul>
            </td>
            <td>
            <img src="img/embedded_arch/comms/can_ecu_internals.svg" width="250">
            </td>
            </tr>
            <tr>
            <td>
            </td>
            <td>
            </td>
            </tr>
            </table>
            <p><em>Any</em> ECU can broadcast on the CAN bus and the
            messages are accepted by <em>all</em> ECUs connected to it.
            Each ECU can either choose to ignore the message or act on
            it.</p>
            <blockquote>
            <p>what are the implications for
            <strong>security</strong>?</p>
            </blockquote>
            <p>While there is no “standard” CAN connector (each vehicle
            may use different ones), the <strong>CAN Bus DB9</strong>
            connector has become the de facto standard:</p>
            <p><img src="img/embedded_arch/comms/can-bus-db9-connector-pinout-d-sub.svg" width="350"></p>
            <p>The above figure shows the various pins and their
            signals.</p>
            <p><br></p>
            <p><strong>CAN Communication Protocols</strong>: CAN is
            split into:</p>
            <table>
            <tr>
            <th>
            layer
            </th>
            <th>
            relation to OSI stack
            </th>
            </tr>
            <tr>
            <td>
            <ul>
            <li>
            <b>data link</b>: CAN frame formats, <br>error handling,
            data transmission, <br>data integrity
            </li>
            <li>
            <b>physical</b>: cable types, <br>electrical signal levels,
            <br>node requirements, <br>cable impedance, etc.
            </li>
            </ul>
            </td>
            <td>
            <img src="img/embedded_arch/comms/can-bus-osi-model-7-layer-iso-11898-physical-data.svg" width="350">
            </td>
            </tr>
            <tr>
            <td>
            </td>
            <td>
            </td>
            </tr>
            </table>
            <p><br></p>
            <p>All communication over the CAN bus is done via the
            <strong>CAN frames</strong>. The <em>standard</em> CAN frame
            (with an <code>11-bit</code> identifier) is shown below:</p>
            <p><img src="img/embedded_arch/comms/CAN-bus-frame-standard-message-SOF-ID-RTR-Control-Data-CRC-ACK-EOF.svg" width="400"></p>
            <p><br></p>
            <p>While the lower-level CAN protocols described so far work
            on the two lowest layers of the OSI networking stack, it is
            still limiting. For instance, the CAN standard doesn’t
            discuss how to,</p>
            <ul>
            <li>decode RAW data</li>
            <li>handle larger data (more than 8 bytes)</li>
            </ul>
            <p>Hence, some <strong>higher-order</strong> protocols have
            been developed, <em>viz.,</em></p>
            <table>
            <colgroup>
            <col style="width: 42%" />
            <col style="width: 57%" />
            </colgroup>
            <thead>
            <tr>
            <th>protocol</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/obd2-explained-simple-intro">OBD2</a></td>
            <td>on-board diagnostics in cars/trucks for diagnostics,
            maintenance, emissions tests</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/uds-protocol-tutorial-unified-diagnostic-services">UDS</a></td>
            <td>Unified Diagnostic Services (UDS) used in automotive
            ECUs for diagnostics, firmware updates, routine testing</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/ccp-xcp-on-can-bus-calibration-protocol">CCP/XCP</a></td>
            <td>used in embedded control/industrial automation for
            <em>off-the-shelf interoperability</em> between CAN
            devices</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/j1939-explained-simple-intro-tutorial">SAE
            J1939</a></td>
            <td>for heavy-duty vehicles</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/nmea-2000-n2k-intro-tutorial">NMEA
            2000</a></td>
            <td> used in maritime industry for connecting e.g. engines,
            instruments, sensors on boats</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/isobus-introduction-tutorial-iso-11783">ISOBUS</a></td>
            <td>used in agriculture and forestry machinery to enable
            plug and play integration between vehicles/implements,
            <em>across brands</em></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>There also exist other higher-order protocols (numbering
            in the thousands) the most prominent of which are: ARINC,
            UAVCAN, DeviceNet, SafetyBUS p, MilCAN, HVAC CAN.</p>
            <p><br></p>
            <p>More details about CAN and its variants: <a
            href="https://www.csselectronics.com/pages/can-bus-simple-intro-tutorial">CAN
            Bus Explained</a>.</p>
            </section>
            <section id="other-broadly-used-protocols-1" class="level3"
            data-number="7.3.6">
            <h3 data-number="7.3.6"><span
            class="header-section-number">7.3.6</span> Other Broadly
            Used Protocols</h3>
            <p>Autonomous (and other embedded systems) use a variety of
            other communication protocols in order to interface with the
            external world and/or other systems (either other nodes in
            the system or external components such as back end
            clouds).</p>
            <p>Note that since many of these are well known and publicly
            documented, we won’t elaborate much here.</p>
            <p>Here are some of the well known communication protocols,
            also used in embedded systems:</p>
            <table>
            <colgroup>
            <col style="width: 57%" />
            <col style="width: 42%" />
            </colgroup>
            <thead>
            <tr>
            <th>protocol</th>
            <th>links</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>USB</td>
            <td>How USB works: <a
            href="https://www.circuitbread.com/tutorials/how-usb-works-introduction-part-1">part
            1</a>, <a
            href="https://www.circuitbread.com/tutorials/how-usb-works-communication-protocol-part-2">part2</a>,
            <a
            href="https://www.circuitbread.com/tutorials/how-usb-works-enumeration-and-configuration-part-3">part
            3</a>; <a
            href="https://www.beyondlogic.org/usbnutshell/usb1.shtml">USB
            in a Nutshell (very detailed)</a>.</td>
            </tr>
            <tr>
            <td>Ethernet</td>
            <td><a
            href="https://www.embedded.com/implement-reliable-embedded-ethernet-connectivity/">Reliable
            Embedded Ethernet</a>, <a
            href="https://www.google.com/books/edition/_/3ZPPBgAAQBAJ?hl=en&amp;gbpv=1&amp;pg=PA1">Embedded
            Ethernet and Internet (book, online)</a></td>
            </tr>
            <tr>
            <td>WiFi</td>
            <td><a
            href="https://ebulutvcu.github.io/COMST22_WiFi_Sensing_Survey.pdf">WiFi
            Sensing on the Edge (paper)</a></td>
            </tr>
            <tr>
            <td>Bluetooth</td>
            <td><a
            href="https://learn.sparkfun.com/tutorials/bluetooth-basics/all">Bluetooth
            Basics</a>, <a
            href="https://novelbits.io/bluetooth-low-energy-ble-complete-guide/">Bluetooth
            Low Energy</a></td>
            </tr>
            <tr>
            <td>Radio</td>
            <td><a
            href="https://wiki.gnuradio.org/index.php/Embedded_Development_with_GNU_Radio">Embedded
            Development with GNU Radio</a></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            <section id="raspberry-pi-and-navio2-1" class="level2"
            data-number="7.4">
            <h2 data-number="7.4"><span
            class="header-section-number">7.4</span> Raspberry Pi and
            Navio2</h2>
            <p>Let us look at the two architectures we use extensively
            in this course:</p>
            <ul>
            <li><a
            href="https://www.raspberrypi.com/products/raspberry-pi-4-model-b/specifications/">Raspberry
            Pi</a> model 4(b)</li>
            <li><a href="https://navio2.hipi.io">Navio2</a> → autopilot
            hat for the Raspberry Pi</li>
            </ul>
            <p>The high-level architecture of the Pi shows many of the
            components we have discussed so far:</p>
            <p><img src="img/embedded_arch/pi-4-architectural_features.png" width="400"></p>
            <p>In particular, the Pi has,</p>
            <table>
            <colgroup>
            <col style="width: 33%" />
            <col style="width: 66%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>description/details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>processor</td>
            <td>Broadcomm <strong>BCM2711</strong>, Quad core Cortex-A72
            (ARM v8) 64-bit SoC at 1.8GHz</td>
            </tr>
            <tr>
            <td>memory</td>
            <td>1GB, 2GB, 4GB or 8GB LPDDR4-3200 SDRAM</td>
            </tr>
            <tr>
            <td>network</td>
            <td>Wifi (2.4/5.0 GHz), Gigabit ethernet, Bluetooth/BLE</td>
            </tr>
            <tr>
            <td>I/O</td>
            <td>40 pin GPIO, USB 3.0/2.0/C</td>
            </tr>
            <tr>
            <td>storage</td>
            <td>Micro-SD Card</td>
            </tr>
            <tr>
            <td>misc</td>
            <td>micro-hdmi, stereo audio/video, displayport, camera
            port, power</td>
            </tr>
            <tr>
            <td>os</td>
            <td><a
            href="https://www.raspberrypi.com/software/">Raspberry Pi
            OS</a> (formerly called Raspbian)</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Read more about the Raspberry Pi: <a
            href="https://www.electronics-lab.com/project/raspberry-pi-4-look-hood-make/">Raspberry
            PI – A Look Under the Hood</a></p>
            <p><br></p>
            <p>The <strong>Navio2</strong> is a “hat” that adds the
            following to a Raspberry Pi:</p>
            <ul>
            <li>autopilot functionality</li>
            <li>multiple sensors</li>
            </ul>
            <p>The high-level architecture,</p>
            <p><img src="img/embedded_arch/navio2_features.jpg" width="400"></p>
            <p>As the figure shows, the Navio2 adds the following
            components:</p>
            <table>
            <colgroup>
            <col style="width: 32%" />
            <col style="width: 67%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>description/details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>GNSS receiver</td>
            <td>for GPS signals</td>
            </tr>
            <tr>
            <td>high-precision barometer</td>
            <td>for measuring pressure (and altitude)</td>
            </tr>
            <tr>
            <td>(dual) IMU</td>
            <td>two 9 DOF with gyroscope, accelerometer, magnetometer,
            each</td>
            </tr>
            <tr>
            <td>RC I/O co-processor</td>
            <td>PWM, ADC, SBUS, PPM</td>
            </tr>
            <tr>
            <td>extension ports</td>
            <td>ADC, I2C, UART</td>
            </tr>
            <tr>
            <td>power supply</td>
            <td>triple redundant</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>More details about the Navio2 and how to program it: <a
            href="https://docs.emlid.com/navio2/">Navio2
            Documentation</a>.</p>
            <p><br> <br></p>
            </section>
            <section id="references-1" class="level2" data-number="7.5">
            <h2 data-number="7.5"><span
            class="header-section-number">7.5</span> References</h2>
            </section>
            </section>
            <section id="sensors-and-sensing-1" class="level1"
            data-number="8">
            <h1 data-number="8"><span
            class="header-section-number">8</span> Sensors and
            Sensing</h1>
            <p>An embedded/autonomous system <em>perceives</em> the
            physical world via sensors – either to gather information
            about its environment or to model its <em>own</em> state.
            Hence it is a critical component in the <em>sensing →
            planning → actuation</em> loop and a critical component in
            the design of embedded and autonomous systems.</p>
            <table>
            <colgroup>
            <col style="width: 46%" />
            <col style="width: 53%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sense_planning_actuation.png" width="400"></td>
            <td><img src="img/stack_architecture/stack_overview.2.png" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Modern autonomous systems used a <em>wide array</em> of
            sensors. This is necessary due to:</p>
            <ul>
            <li>there is a need to measure <strong>different</strong>
            quantities, <em>e.g.,</em> GPS, velocity, objects,
            <em>etc.</em></li>
            <li>sensor measurements often have <strong>errors</strong> →
            hence, we need multiple sensors, often using
            <strong>different physical properties</strong> to measure
            the <em>same thing</em>; <em>e.g.,</em> LiDar and cameras
            can both be used to detect objects in front of, and around,
            an autonomous vehicle.</li>
            </ul>
            <p>At its core,</p>
            <blockquote>
            <p>a sensor captures a physical/chemical/environmental
            quantity and <strong>converts it to a digital
            quantity</strong>.</p>
            </blockquote>
            <p>(hence the need for an Analog-to-Digital Convertor (ADC)
            as we shall see later)</p>
            <p>By definition, sensors generate <strong>signals</strong>.
            A signal, <code>s</code>, is defined as a mapping from the
            <em>time</em> domain to a <em>value</em> domain:</p>
            <p><span
            class="math display"><em>s</em> : <em>D</em><sub><em>t</em></sub> ↦ <em>D</em><sub><em>v</em></sub></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>t</em></sub></span></td>
            <td>continuous or discrete <strong>time</strong> domain</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>v</em></sub></span></td>
            <td>continuous or discrete <strong>value</strong>
            domain</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><strong>Note:</strong> remember that computers require
            <strong>discrete</strong> sequences of physical values.
            Hence, we need to <strong>convert</strong> the above into
            the discrete domain. The way to achieve this:
            <strong>sampling</strong>:</p>
            <p><img src="img/sensors/discretization_sampled.signal.svg" title="Sampling image from Wikipedia" width="300"></p>
            <p>The figure shows a continuous signal being sampled (in
            <font color="red"><b>red</b></font> arrows). We will discuss
            sampling and related issues later in this topic.</p>
            <section id="types-of-sensors-1" class="level2"
            data-number="8.1">
            <h2 data-number="8.1"><span
            class="header-section-number">8.1</span> Types of
            Sensors</h2>
            <p>Sensors come in various shapes and sizes. Usually
            designers of autonomous systems will develop a
            “<strong>sensor plan</strong> that will consider,</p>
            <ul>
            <li>required functionality</li>
            <li>sensor range(s)</li>
            <li>cost</li>
            </ul>
            <p>Hence, each autonomous system will likely have its own
            set of sensors (or sensor plan). <em>Typical</em> sensors
            found on modern autonomous systems can be classified based
            on the underlying physics used:</p>
            <table>
            <colgroup>
            <col style="width: 70%" />
            <col style="width: 29%" />
            </colgroup>
            <thead>
            <tr>
            <th>physical property</th>
            <th>sensor</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><a
            href="#inertial-measurement-units-imu"><em>internal</em>
            measurements</a></td>
            <td>IMU</td>
            </tr>
            <tr>
            <td><em>external</em> measurements</td>
            <td>GPS</td>
            </tr>
            <tr>
            <td><a
            href="#bouncing-of-electromagnetic-waves--lidar-and-mmwave">“bouncing”
            electromagnetic waves</a></td>
            <td>LiDAR, RADAR, mmWave Radar</td>
            </tr>
            <tr>
            <td>optical</td>
            <td>cameras, infrared sensors</td>
            </tr>
            <tr>
            <td><a href="#ultrasonic">accoustic</a></td>
            <td>ultrasonic sensors</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Some of the above can be combined to generate other
            sensing patterns, <em>e.g.,</em> <strong>stereo
            vision</strong> using multiple cameras or camera+LiDAR.</p>
            <p>We will go over <strong>some</strong> of these sensors
            and their underlying physical principles.</p>
            <section id="inertial-measurement-units-imu-1"
            class="level3" data-number="8.1.1">
            <h3 data-number="8.1.1"><span
            class="header-section-number">8.1.1</span> Inertial
            Measurement Units (IMU)</h3>
            <p>These sensors define the <strong>movement of a
            vehicle</strong>, along the three axes, in addition to other
            behaviors like acceleration and directionality. An IMU
            typically includes the following sensors:</p>
            <table>
            <colgroup>
            <col style="width: 24%" />
            <col style="width: 21%" />
            <col style="width: 24%" />
            <col style="width: 29%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sensors/imu_exploded_view.jpg" width="600"></td>
            <td><img src="img/sensors/imu_accelerometer.png" width="400"></td>
            <td><img src="img/sensors/imu_gyro.png" width="400"></td>
            <td><img src="img/sensors/imu_magnetometer.png" width="400"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>As we see from the first picture above, an IMU also has a
            CPU (typically a microcontroller) to manage/collect/process
            the data from the sensors.</p>
            <p>The functions of the three sensors are:</p>
            <ol type="1">
            <li><strong>gyroscope</strong>: is an inertial sensor that
            measure an object’s angular rate with respect to an inertial
            reference frame. It measures the following movements:</li>
            </ol>
            <table>
            <colgroup>
            <col style="width: 29%" />
            <col style="width: 37%" />
            <col style="width: 33%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sensors/imu_yaw.gif"></td>
            <td><img src="img/sensors/imu_pitch.gif"></td>
            <td><img src="img/sensors/imu_roll.gif"></td>
            </tr>
            <tr>
            <td>“yaw”</td>
            <td>“pitch”</td>
            <td>“roll”</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>IMUs come in all shapes and sizes. These days they’re
            very small but the original IMU’s ver really large, as
            evidenced by the one used in the <a
            href="http://klabs.org/history/history_docs/mit_docs/1690.pdf">Apollo
            space missions</a>:</p>
            <p><img src="img/sensors/imu_apollo.jpg" width="300"></p>
            <p><br></p>
            <ol start="2" type="1">
            <li><p><strong>accelerometer</strong>: is the primary sensor
            responsible for measuring inertial acceleration, or the
            change in velocity over time.</p></li>
            <li><p><strong>magnetometer</strong>: measures the strength
            and direction of magnetic field – to find the magnetic
            north</p></li>
            </ol>
            </section>
            <section
            id="bouncing-of-electromagnetic-waves-lidar-and-mmwave-1"
            class="level3" data-number="8.1.2">
            <h3 data-number="8.1.2"><span
            class="header-section-number">8.1.2</span> Bouncing of
            Electromagnetic Waves | LiDAR and mmWave</h3>
            <p>A very common principle for measuring surroundings is to
            bounce electromagnetic waves off nearby objects and
            measuring the round trip times. Shorter times indicate
            closer objects while longer times indicate objects that are
            farther away. <a
            href="https://www.noaa.gov/jetstream/doppler/how-radar-works">RADAR</a>
            is a classic example of this type of sensor and its (basic)
            operation is shown in the following image (courtesy
            NOAA):</p>
            <p><img src="img/sensors/radar_doppler_ani.gif" width="400"></p>
            <p>While many autonomous vehicles use RADAR, we will focus
            on other technologies that are more prevalent and provide
            much higher precision, <em>viz.,</em></p>
            <ol type="1">
            <li><a
            href="#light-detection-and-ranging-lidar">LiDAR</a></li>
            <li>millimeter Wave RADAR (mmWave)</li>
            </ol>
            <section id="light-detection-and-ranging-lidar-1"
            class="level4" data-number="8.1.2.1">
            <h4 data-number="8.1.2.1"><span
            class="header-section-number">8.1.2.1</span> Light Detection
            and Ranging (LiDAR)</h4>
            <p><a
            href="https://web.stanford.edu/class/ee259/lectures/ee259_05_lidar.pdf">LiDAR</a>
            is a sensor that uses (<em>eye safe</em>) <strong>laser
            beams</strong> for mapping surroundings and creating
            <strong>3D representation</strong> of the environment. So
            lasers are used for,</p>
            <ul>
            <li>imaging</li>
            <li>detection</li>
            <li>ranging</li>
            </ul>
            <p>We can use LiDAR to distance, angle as well as the
            <em>radial velocity</em> of some objects – all relative to
            the autonomous system (rather the sensor). So, in practice,
            this is how it operates:</p>
            <p><img src="img/sensors/lidar_principle_operation.png" width="400"></p>
            <p>We define a <strong>roundtrip time</strong>, $ au$, as
            the time between when a pulse is sent out from the
            transmitter (<code>TX</code>) to when light reflected from
            the object is detected at the receiver
            (<code>RX</code>).</p>
            <p>So, the <strong>target range</strong> (<em>i.e.,</em> the
            distance to te object), <span
            class="math inline"><em>R</em></span>, is measured as:</p>
            <p><span
            class="math display"><em>R</em> = <em>r</em><em>a</em><em>c</em><em>c</em><em>a</em><em>u</em>2</span></p>
            <p>where, <code>c</code> is the speed of light.</p>
            <p>More details (from <a
            href="https://web.stanford.edu/class/ee259/lectures/ee259_05_lidar.pdf">Mahalati</a>):
            &gt; Lasers used in lidars have frequencies in the <span
            class="math inline">100<em>s</em></span> of Terahetrz.
            Compared to RF waves, lasers have significantly smaller
            wavelengths and can hence be easily collected into narrow
            beams using lenses. This makes DOA estimation almost trivial
            in lidar and gives it significantly better reso- lution than
            MIMO imaging radar.</p>
            <p>The <em>end product</em> of LiDAR is essentially a
            <strong>point cloud</strong>, defined as:</p>
            <blockquote>
            <p>a collection of points generated by a sensor. Such
            collections can be very dense and contain billions of
            points, which enables the creation of highly detailed 3D
            representations of an area.</p>
            </blockquote>
            <p><img src="img/sensors/lidar_point_cloud_torus.gif" title="3D point cloud of a Torus. Courtesy Wikipedia"></p>
            <p>In reality, point cloud representations around autonomous
            vehicles end up looking like:</p>
            <video controls width="500">
            <source src="https://sibin.github.io/teaching/csci6907_88-gwu-secure_autonomous/fall_2022/other_docs/What-is-Lidar-video.mp4">
            </video>
            <p><a
            href="https://www.yellowscan.com/knowledge/lidar-point-cloud-basics/">Point
            clouds</a> provide valuable information, <em>viz.,</em></p>
            <ul>
            <li>3D coordinates, <span
            class="math inline">(<em>x</em>, <em>y</em>, <em>z</em>)</span></li>
            <li><strong>strength</strong> of returned signal → provides
            valuable information about the <strong>density</strong> of
            the object (or even material composition)!</li>
            <li>additional attributes: return number, scan angle, scan
            direction, point density, RGB color values, and time stamps
            → each can be used for refining the scan.</li>
            </ul>
            <p>There are <strong>two types</strong> of <em>scene
            illumination</em> techniques for LiDAR:</p>
            <table>
            <colgroup>
            <col style="width: 20%" />
            <col style="width: 52%" />
            <col style="width: 27%" />
            </colgroup>
            <thead>
            <tr>
            <th>type</th>
            <th>illumination method</th>
            <th>detector</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>flash lidar</td>
            <td><em>entire</em> scene using wide laser</td>
            <td>receives all echoes on a photodetector array</td>
            </tr>
            <tr>
            <td>scanning lidar</td>
            <td>very narrow laser beams, scan illumination spot with
            laser beam scanner</td>
            <td>single photodetector to sequentially estimate $ au$ for
            each spot</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <table>
            <colgroup>
            <col style="width: 28%" />
            <col style="width: 28%" />
            <col style="width: 42%" />
            </colgroup>
            <thead>
            <tr>
            <th></th>
            <th>flash lidar</th>
            <th>scan lidar</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>architecture</strong></td>
            <td><img src="img/sensors/lidar_flash.png" width="400"></td>
            <td><img src="img/sensors/lidar_scan.png" width="400"></td>
            </tr>
            <tr>
            <td><strong>resolution</strong> determined by</td>
            <td>photodetector array pizel size (like camera)</td>
            <td>laser beam size and spot fixing</td>
            </tr>
            <tr>
            <td><strong>frame rates</strong></td>
            <td>higher (up to <code>100 fps</code>)</td>
            <td>lower (&lt; <code>30 fps</code>)</td>
            </tr>
            <tr>
            <td><strong>range</strong></td>
            <td>shorter (quick beam divergence, like photography)</td>
            <td>longer (<code>100m+</code>)</td>
            </tr>
            <tr>
            <td><strong>use</strong></td>
            <td>less common</td>
            <td><strong>most common</strong></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Now, consider the following scene (captured by a
            camera):</p>
            <p><img src="img/sensors/lidar_camera_image.png" width="400"></p>
            <p><br> <br></p>
            <p>Compare this to the LiDAR images captured by the two
            methods:</p>
            <table>
            <colgroup>
            <col style="width: 30%" />
            <col style="width: 30%" />
            <col style="width: 38%" />
            </colgroup>
            <thead>
            <tr>
            <th>flash lidar</th>
            <th>scan lidar (16 scan lines)</th>
            <th>scan lidar (32 scan lines)</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/sensors/lidar_flash_image.png" width="400"></td>
            <td><img src="img/sensors/lidar_scan_16.png" width="400"></td>
            <td><img src="img/sensors/lidar_scan_32.png" width="400"></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <blockquote>
            <p>A “LiDAR scan line” refers to a <strong>single horizontal
            line</strong> of laser pulses emitted by a LiDAR sensor,
            essentially capturing a cross-section of the environment at
            a specific angle as the sensor rotates, creating a 3D point
            cloud by combining multiple scan lines across the field of
            view; it’s the basic building block of a LiDAR scan, similar
            to how a single horizontal line is a building block of an
            image.</p>
            </blockquote>
            <p><strong>Potential Problems</strong>:</p>
            <p>Atmospheric/environmental conditions can
            <strong>negatively</strong> affect the quality of the data
            captured by the LiDAR. For instance, <strong>fog</strong>
            can scatter the laser photons resulting in <strong>false
            positives</strong>.</p>
            <p><img src="img/sensors/lidar_fog.png" width="400"></p>
            <p>As we see from the above image, the scattering due to the
            fog results in the system “identifying” multiple objects
            even though there is only <em>one</em> person in the
            scene.</p>
            <p>Here are additional examples from the <a
            href="https://www.mapix.com/lidar-scanner-sensors/velodyne/velodyne-vlp-32c/">Velodyne
            VLP-32C</a> sensor:</p>
            <ol type="1">
            <li><strong>light</strong> fog (camera vs LiDAR)</li>
            </ol>
            <p><img src="img/sensors/lidar_veoldyne_lightfog.png" width="600"></p>
            <p>The LiDAR does a good job isolating the main subject with
            very few false positives.</p>
            <ol start="2" type="1">
            <li><strong>heavy</strong> fog (camera vs LiDAR)</li>
            </ol>
            <p><img src="img/sensors/lidar_velodyne_heavyfog.png" width="600"></p>
            <p>The LiDAR <em>struggles</em> to isolate the main subject
            with very <em>high</em> false positives.</p>
            <p>In spite of these issues, LiDAR is one of the most
            popular sensors used in autonomous vehicles. They’re getting
            smaller and more precise by the day; also decreasing costs
            means that we will see a proliferation of these types of
            sensors in many autonomous systems.</p>
            <p>For an in-depth study on LiDARs, check this out: <a
            href="https://web.stanford.edu/class/ee259/lectures/ee259_05_lidar.pdf">Stanford
            EE 259 LiDAR Lecture</a>.</p>
            </section>
            <section id="millimeter-wave-radar-mmwave-1" class="level4"
            data-number="8.1.2.2">
            <h4 data-number="8.1.2.2"><span
            class="header-section-number">8.1.2.2</span> Millimeter Wave
            Radar [mmWave]</h4>
            <p>Short wavelengths like the *millimeter wave<strong>
            (</strong>mmWave**) in the electromagnetic spectrum allows
            for:</p>
            <ul>
            <li>smaller antennae</li>
            <li>integration of entire RADAR circuitry in a single
            chip!</li>
            <li>spectrum of 10 millimeters (<code>30 GHz</code>) to 1
            millimeter (<code>300 GHz</code>)</li>
            </ul>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sensors/mmwave.jpg" width="300"></td>
            <td><img src="img/sensors/mmwave_ucsdavif.avif" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>As we see from the above images, the sensors can be
            <strong>very small</strong>, yet <strong>very
            precise</strong> → some can detect movements up to <em>4
            millionths of a meter</em>!</p>
            <p><strong>Advantages</strong> of mmWave:</p>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <thead>
            <tr>
            <th>Advantage</th>
            <th>Description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>small antenna caliber</td>
            <td>narrow beam gives high tracking, accuracy; high-level
            resolution, high-resistance interference performance of
            narrow beam; high antenna gain; smaller object
            detection</td>
            </tr>
            <tr>
            <td>large bandwidth</td>
            <td>high information rate, details structural features of
            the target; reduces multipath, and enhances
            anti-interference ability; overcomes mutual interference;
            high-distance resolution</td>
            </tr>
            <tr>
            <td>high doppler frequency</td>
            <td>good detection and recognition ability of slow
            objectives and vibration targets; can work in snow
            conditions</td>
            </tr>
            <tr>
            <td>good anti-blanking performance</td>
            <td>works on the most used stealth material</td>
            </tr>
            <tr>
            <td>robustness to atmospheric conditions</td>
            <td>such as dust, smoke, and fog compared to other
            sensors</td>
            </tr>
            <tr>
            <td>operation under different lights</td>
            <td>radar can operate under bright lights, dazzling lights,
            or no lights</td>
            </tr>
            <tr>
            <td>insusceptible to ground clutter</td>
            <td>allowing for close-range observations; the low
            reflectivity can be measured using mmwave radar</td>
            </tr>
            <tr>
            <td>fine spatial resolution</td>
            <td>for the same range, mmwave radar offers finer spatial
            resolution than microwave radar &gt;</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>mmWave is also used for <strong>in-cabin monitoring of
            drivers</strong>!</p>
            <p><br></p>
            <p><strong>Limitations</strong>:</p>
            <ul>
            <li>line of sight operations</li>
            <li>affected by water content, gases in environments</li>
            <li>affected by contaminated environment and physical
            obstacles</li>
            </ul>
            <p><br></p>
            <p><strong>Resources</strong>:</p>
            <p>For a more detailed description of mmWave RADAR, read: <a
            href="https://www.design-reuse.com/articles/55851/mmwave-radar-principle-applications.html">Understanding
            mmWave RADAR, its Principle &amp; Applications</a></p>
            <p>For programming a LiDAR, see: <a
            href="h.ttps://www.engineersgarage.com/how-to-use-a-lidar-sensor-with-arduino/">how
            to program a LiDAR with an Arduino</a>.</p>
            </section>
            </section>
            <section id="ultrasonic-1" class="level3"
            data-number="8.1.3">
            <h3 data-number="8.1.3"><span
            class="header-section-number">8.1.3</span> Ultrasonic</h3>
            <p>Much like lidars, we can use reflected sounds waves to
            detect objects. They work by emitting high-frequency sound
            waves, typically above human hearing, and then listening for
            the echoes that bounce back from nearby objects. The sensor
            calculates the distance based on the time it takes for the
            echo to return, using the speed of sound. Popular modules
            like the HC-SR04 (Used in Lab#2) are easy to integrate with
            microcontrollers such as Arduino and Raspberry Pi. These
            sensors are widely used in robotics for obstacle avoidance,
            automated navigation, and liquid level sensing.</p>
            <p>However, unlike optical (electromagnetic waves)
            detectors, ultrasonic sensors, while useful for basic
            distance measurements, cannot replicate the functionalities
            of LiDAR systems due to several key limitations. Unlike
            LiDAR, which employs laser beams to generate
            high-resolution, three-dimensional point clouds, ultrasonic
            sensors emit sound waves that provide only limited,
            single-point distance data with lower precision. LiDAR
            offers greater accuracy and longer range, enabling detailed
            mapping and object recognition essential for applications
            like autonomous vehicles and advanced robotics.
            Additionally, LiDAR systems can cover a wider field of view
            and operate effectively in diverse environments by rapidly
            scanning multiple directions, whereas ultrasonic sensors
            typically have a narrow detection cone and struggle with
            complex or cluttered scenes. Furthermore, LiDAR’s ability to
            capture data at high speeds allows for real-time processing
            and dynamic obstacle detection, which ultrasonics cannot
            match. This is because comparitively, it sounds waves take a
            lot of time to return since they’re much slower in speed
            compared to light waves (360m/s vs 299,792,458m/s). These
            differences in data richness, accuracy, and versatility make
            ultrasonic sensors unsuitable substitutes for the
            sophisticated capabilities offered by LiDAR technology.</p>
            <p>We’ll be using ultrasonic distance finders in futures MPs
            to stop our rovers from colliding into objects. Since our
            rovers don’t moove to fast and complexity is relatively low,
            only a ultrasonic sensor would suffice.</p>
            </section>
            </section>
            <section id="errors-in-sensing-1" class="level2"
            data-number="8.2">
            <h2 data-number="8.2"><span
            class="header-section-number">8.2</span> Errors in
            Sensing</h2>
            <p>Since sensors deal with and measure the <em>physical</em>
            world, <strong>errors</strong> will creep in over time.</p>
            <p>Some typical errors in the use of physical sensors:</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 44%" />
            </colgroup>
            <thead>
            <tr>
            <th>error type</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>sensor drift</strong></td>
            <td>over time the sensor measurements will “drift”, i.e., a
            gradual change in its output → away from average values
            (e.g., due to wear and tear)</td>
            </tr>
            <tr>
            <td><strong>constant bias</strong></td>
            <td>bias of an accelerometer is the offset of its output
            signal from the actual acceleration value. A constant bias
            error causes an error in position which grows with time</td>
            </tr>
            <tr>
            <td><strong>calibration errors</strong></td>
            <td>‘calibration errors’ refers to errors in the scale
            factors, alignments and linearities of the gyros. Such
            errors tend to produce errors when the device is turning.
            These errors can result in additional drift</td>
            </tr>
            <tr>
            <td><strong>scale factor</strong></td>
            <td>scale factor is the relation of the accelerometer input
            to the actual sensor output for the measurement. Scale
            factor, expressed in ppm, is therefore the linear growth of
            input variation to actual measurement</td>
            </tr>
            <tr>
            <td><strong>vibration rectification errors</strong></td>
            <td>vibration rectification error (VRE) is the response of
            an accelerometer to current rectification in the sensor,
            causing a shift in the offset of the accelerometer. This can
            be a significant cumulative error, which propagates with
            time and can lead to over compensation in stabilization</td>
            </tr>
            <tr>
            <td><strong>noise</strong></td>
            <td>random variations in the sensor output that do not
            correspond to the actual measured value</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Each error type must be dealt with in different ways
            though one of the commomn ways to prevent sensor errors from
            causing harm to autonomous systems → <strong>sensor
            fusion</strong>, <em>i.e.,</em> use information from
            <strong>multiple sensors</strong> before making any
            decisions. We will dicuss sensor fusion later in this
            course.</p>
            </section>
            <section id="analog-to-digital-convertors-adcs-1"
            class="level2" data-number="8.3">
            <h2 data-number="8.3"><span
            class="header-section-number">8.3</span> Analog to Digital
            Convertors (ADCs)</h2>
            <p>As <a href="#sensors-and-sensing">mentioned earlier</a>,
            a sensor maps a physical quantity from the time domain to
            the value domain,</p>
            <p><span
            class="math display"><em>s</em> : <em>D</em><sub><em>t</em></sub> ↦ <em>D</em><sub><em>v</em></sub></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>t</em></sub></span></td>
            <td>continuous or discrete <strong>time</strong> domain</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>v</em></sub></span></td>
            <td>continuous or discrete <strong>value</strong>
            domain</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Remember that computers require <strong>discrete</strong>
            sequences of physical values since <strong>microcontrollers
            cannot read values unless it is digital data</strong>.
            Microcontrollers can only see “levels” of voltage, which
            depends on the resolution of the ADC and the system
            voltage.</p>
            <p>Hence, we need to <strong>convert</strong> the above into
            the discrete domain, <em>i.e.,</em> we require <span
            class="math inline"><em>D</em><sub><em>v</em></sub></span>
            to be composed of discrete values.</p>
            <p>According to <a
            href="https://en.wikipedia.org/wiki/Discrete_time_and_continuous_time#">Wikipedia</a>,</p>
            <blockquote>
            <p>A discrete signal or discrete-time signal is a time
            series consisting of a sequence of quantities. Unlike a
            continuous-time signal, a discrete-time signal is not a
            function of a continuous argument; however, it may have been
            obtained by sampling from a continuous-time signal. When a
            discrete-time signal is obtained by sampling a sequence at
            uniformly spaced times, it has an associated
            <strong>sampling rate</strong>.</p>
            </blockquote>
            <p><br></p>
            <p>A visual respresentation of the sampling rate and how it
            correlates to the sampling of an analog signal:</p>
            <table>
            <colgroup>
            <col style="width: 38%" />
            <col style="width: 38%" />
            <col style="width: 23%" />
            </colgroup>
            <thead>
            <tr>
            <th>analog signal</th>
            <th>sampling rate</th>
            <th>sampling</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/sensors/adc_analog_signal.png"></td>
            <td><img src="img/sensors/adc_sampling_rate.png"></td>
            <td><img src="img/sensors/adc_sampling.png"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, a device that converts analog signals to digital
            data values is called → an <strong>analog-to-digital
            convertor</strong> (<strong>ADC</strong>). This is one of
            the most common circuits/microcontrollers in embedded (and
            hence, autonomous) systems. <em>Any</em> sensor that
            measures a physical property must pass its values through an
            ADC so that the sensor values can be used by the system (the
            embedded processor/microcontroller, really).</p>
            <p>This is best described using an example:</p>
            <p><img src="img/sensors/adc_example.jpg" width="400"></p>
            <p>The <font color="blue"><b>analog</b></font> signal is
            <strong>discretized</strong> into the
            <font color="red"><b>digital</b></font> signal after passing
            through an ADC.</p>
            <p>ADCs follow a sequence:</p>
            <ul>
            <li><strong>sample</strong> the signal</li>
            <li><strong>quantify</strong> it to determine the resolution
            of the signal</li>
            <li>set <strong>binary values</strong></li>
            <li><strong>send it to the system</strong> to read the
            digital signal</li>
            </ul>
            <p>Hence, two important aspects of an ADC are:</p>
            <ul>
            <li><a href="#adc-sampling-rate">sampling rate</a></li>
            <li><a href="#adc-resolution">resolution</a></li>
            </ul>
            <section id="adc-sampling-rate-1" class="level3"
            data-number="8.3.1">
            <h3 data-number="8.3.1"><span
            class="header-section-number">8.3.1</span> ADC Sampling
            Rate</h3>
            <p>The sampling rate (aka Sampling Frequency) is measured in
            <strong>samples per second</strong> (SPS or S/s). It
            dictates <em>how many samples</em> (data points) are taken
            in one second. If an ADC records more samples, then it can
            handle higher frequencies.</p>
            <p>The sample rate, <span
            class="math inline"><em>f</em><sub><em>s</em></sub></span>
            is defined as,</p>
            <p><span
            class="math display"><em>f</em><sub><em>s</em></sub> = <em>r</em><em>a</em><em>c</em>1<em>T</em></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>definition</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>s</em></sub></span></td>
            <td>sampling rate/frequency</td>
            </tr>
            <tr>
            <td><span class="math inline"><em>T</em></span></td>
            <td>period of the sample</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, in the previous example,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>value</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>s</em></sub></span></td>
            <td><code>20 Hz</code></td>
            </tr>
            <tr>
            <td><span class="math inline"><em>T</em></span></td>
            <td><code>50 ms</code></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>While this looks slow (<code>20 Hz</code>), the digital
            signal tracks the original analog signal quite faithfully →
            the original signal itself is quite slow
            (<code>1 Hz</code>).</p>
            <p>Now, if the sampling signal is <em>considerably
            slower</em> than the analog signal, then it loses fidelity
            and we see <strong>aliasing</strong>, where the
            reconstructed signal (the digital one in the case)
            <strong>differs from the original</strong>. Consider the
            following example of such a case:</p>
            <p><img src="img/sensors/adc_aliasing_example.jpg" width="400"></p>
            <p>As we see from the above figure, the digital output is
            <strong>nothing</strong> like the original. Hence, this
            (digital) output will not be of much use to the system.</p>
            <p><br></p>
            <p><a
            href="https://fab.cba.mit.edu/classes/S62.12/docs/Shannon_noise.pdf"><strong>Nyquist-Shannon
            Sampling Theorem</strong></a>:</p>
            <blockquote>
            <p>to accurately reconstruct a signal from its samples, the
            sampling rate must be <strong>at least twice the highest
            frequency component</strong> present in the signal</p>
            </blockquote>
            <p>If the sampling frequency is less than the Nyquist rate,
            then aliasing starts to creep in.</p>
            <p>Hence,</p>
            <p><span
            class="math display"><em>f</em><sub><em>N</em><em>y</em><em>q</em><em>u</em><em>i</em><em>s</em><em>t</em></sub> = 2 * <em>f</em><sub><em>m</em><em>a</em><em>x</em></sub></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>definition</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>N</em><em>y</em><em>q</em><em>u</em><em>i</em><em>s</em><em>t</em></sub></span></td>
            <td>Nyquist sampling rate/frequency</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>m</em><em>a</em><em>x</em></sub></span></td>
            <td>the maximum frequency that appears in the signal</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>For instance, if your analog signal has a maximum
            frequency of <code>50 Hz</code> then your sampling frequency
            must be <em>at least</em>, <code>100 Hz</code>. If this
            principle is followed, then it is possible to
            <strong>accurately reconstruct</strong> the original signal
            and its values.</p>
            <p>Note that sometimes <em>noise</em> can introduce
            additonal (high) frequencies into the system but we don’t
            want to sample those (for obvious purposes). Hence, it is a
            good idea to add <a
            href="https://www.analog.com/en/resources/technical-articles/guide-to-antialiasing-filter-basics.html">anti-aliasing
            fitlers</a> to the analog signal <em>before</em> it is
            passed to the ADC.</p>
            </section>
            <section id="adc-resolution-1" class="level3"
            data-number="8.3.2">
            <h3 data-number="8.3.2"><span
            class="header-section-number">8.3.2</span> ADC
            Resolution</h3>
            <p>An ADC’s resolution is directly related to the
            <strong>precision</strong> of the ADC, determined by its
            <strong>bit length</strong>. The following examples shows
            the fidelity of the reconstruction, based on various bit
            lengths:</p>
            <p><img src="img/sensors/adc_resolution_example.jpg" width="400"></p>
            <p>Increasing bit lengths the digital signal more closely
            represents the analog one.</p>
            <p>There exists a correlation between the bit length and the
            <strong>voltage</strong> of the signal. Hence, the
            <strong>true resolution</strong> of the ADC is calculated
            using the bit length <strong>and</strong> the voltage as
            follows:</p>
            <p><span
            class="math display"><em>S</em><em>t</em><em>e</em><em>p</em><em>S</em><em>i</em><em>z</em><em>e</em> = <em>r</em><em>a</em><em>c</em><em>V</em><sub><em>r</em><em>e</em><em>f</em></sub><em>N</em></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>definition</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>S</em><em>t</em><em>e</em><em>p</em><em>S</em><em>i</em><em>z</em><em>e</em></span></td>
            <td>resolution of each level in terms of voltage</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>V</em><sub><em>r</em><em>e</em><em>f</em></sub></span></td>
            <td>voltage reference/range of voltages</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>N</em> = 2<sup><em>n</em></sup></span></td>
            <td>total “size” of the ADC</td>
            </tr>
            <tr>
            <td><span class="math inline"><em>n</em></span></td>
            <td>bit size</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>This is easier to understand with a concrete example:</p>
            <blockquote>
            <p>consider a sine wave with a voltage, <code>5 V</code>
            that must be digitized. <br> <br> If our ADC precision is
            <code>12 bits</code>, then we get <br> <span
            class="math inline"><em>N</em> = 2<sup>12</sup> = 4096</span>
            <br> <br> Hence, <span
            class="math inline"><em>S</em><em>t</em><em>e</em><em>p</em><em>S</em><em>i</em><em>z</em><em>e</em> = 5<em>V</em>/ 4096</span>
            which is <code>0.00122V</code> (or <code>1.22mV</code>)<br>
            <br> Hence, the system can tell when a voltage level changes
            by <code>1.22 mV</code>!</p>
            </blockquote>
            <p>(Repeat the exercise for say, bit length, <span
            class="math inline"><em>n</em> = 4</span>)</p>
            <p><br></p>
            <p><strong>Visual Example:</strong></p>
            <p>The above maybe intuitively understood as follows:</p>
            <p>Consider the following signal:</p>
            <p><img src="img/sensors/adc_bits/adc_bits.1.png" width="300"></p>
            <p>Now, if we want to sample this signal, we can obtain
            measurements at:</p>
            <p><img src="img/sensors/adc_bits/adc_bits.2.png" width="300"></p>
            <p><br></p>
            <p>The figure shows <code>9</code> measurements.</p>
            <p>Suppose, the ADC registers have a width of:
            <code>2 bits</code>. Hence it can store at most:
            <code>4 values</code>.</p>
            <p>Since is is <strong>not</strong> possible to store
            <code>9</code> values → <code>2</code> bits, we must select
            <strong>only <code>4</code> values</strong> omn the digital
            side.</p>
            <p>We then get the following representation:</p>
            <p><img src="img/sensors/adc_bits/adc_bits.3.png" width="300"></p>
            <p><br></p>
            <p>which, to be honest, is not really a good representation
            of the original signal!</p>
            <p>Now, consider the case where the ADC registers have a bit
            width: <strong><code>4 bits</code></strong> →
            <code>16 values</code>! Hence, we can easily store
            <strong>all <code>9 values</code></strong> easily.</p>
            <p>So, we can get a digital representation as follows:</p>
            <p><img src="img/sensors/adc_bits/adc_bits.4.png" width="300"></p>
            <p><br></p>
            <p>We see that this is a better representation, <em>but
            still not exact</em>. We can increase the bit length but at
            this point we are limited by the sampling as well. Since we
            only have <code>9</code> samples, adding more bits won’t
            help.</p>
            <p>Hence, to get a better fidelity representation of the
            original signal, we see that <strong>sampling
            frequency</strong> and <strong>resolution</strong> need to
            be increased, since they determine the quality of output we
            get from an ADC.</p>
            <p><strong>Resources</strong></p>
            <ul>
            <li>for more details about ADC, read: <a
            href="https://www.arrow.com/en/research-and-events/articles/engineering-resource-basics-of-analog-to-digital-converters">Analog-to-Digital
            Convertor Basics</a></li>
            <li>an <strong>in-depth</strong> explanation of how ADCs
            work: <a
            href="http://class.ece.iastate.edu/cpre288/lectures/lect12_13.pdf">Iowa
            State CpreE 288 Course Slides</a></li>
            <li>more details with videos: <a
            href="https://users.ece.utexas.edu/~valvano/Volume1/E-Book/C14_ADCdataAcquisition.htm">Analog
            to Digital Conversion, EE319K Univ. of Texas</a></li>
            <li>Programming an ADC: <a
            href="https://blog.embeddedexpert.io/?p=68">1</a>, <a
            href="https://labs.dese.iisc.ac.in/embeddedlab/tm4c123-adc-programming/">2</a>
            <!--link rel="stylesheet" href="./custom.sibin.css"--></li>
            </ul>
            </section>
            </section>
            </section>
            <section id="real-time-operating-systems-1" class="level1"
            data-number="9">
            <h1 data-number="9"><span
            class="header-section-number">9</span> Real-Time Operating
            Systems</h1>
            <p>Real-Time Operating Systems (RTOS) are specialized
            operating systems designed to manage hardware resources,
            execute applications and process data in a
            <strong>predictable</strong> manner. The main aim of this
            focus on “predictability” is to ensure that critical tasks
            complete in a <strong>timely</strong> fashion. Unlike
            general-purpose operating systems (GPOS) like Windows or
            Linux, which prioritize multitasking and user experience,
            RTOS focuses on meeting strict timing constraints, ensuring
            that tasks are completed within defined
            <strong>deadlines</strong>. This makes RTOS essential for
            systems where timing accuracy and reliability are critical,
            such as in embedded systems, autonomous driving, industrial
            automation, automotive systems, medical devices and
            aerospace applications, among others.</p>
            <p>Hence, real-time systems (RTS), and RTOSes in general,
            have <em>two</em> criteria for “correctness”:</p>
            <table>
            <colgroup>
            <col style="width: 23%" />
            <col style="width: 76%" />
            </colgroup>
            <thead>
            <tr>
            <th>criteria</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>functional</strong> correctness</td>
            <td>the system should work as expected, <em>i.e.</em>, carry
            out its intended function without errors</td>
            </tr>
            <tr>
            <td><strong>temporal</strong> correctness</td>
            <td>the functionally correct operations must be completed
            within a predefined timing constraint
            (<strong>deadline</strong>)</td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>To place ourselves in the context of this course, this is
            where we are:</p>
            <p><img src="img/stack_architecture/stack_overview.4.png" width="300"></p>
            <p><br></p>
            <p>We haven’t looked at the actuation part but we will come
            back to it later.</p>
            <section id="key-characteristics-for-rtos-1" class="level3"
            data-number="9.0.1">
            <h3 data-number="9.0.1"><span
            class="header-section-number">9.0.1</span> Key
            characteristics for RTOS</h3>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 44%" />
            </colgroup>
            <thead>
            <tr>
            <th>characteristic</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>determinism</strong></td>
            <td>primary feature of an RTOS is its ability to perform
            tasks within guaranteed time frames; this predictability
            ensures that high-priority tasks are executed without delay,
            even under varying system loads</td>
            </tr>
            <tr>
            <td><strong>task scheduling</strong></td>
            <td>RTOS uses advanced scheduling algorithms (e.g.,
            priority-based, round-robin or earliest-deadline-first) to
            manage task execution; RT tasks are often assigned
            priorities and the scheduler ensures that higher-priority
            tasks preempt lower-priority ones when necessary</td>
            </tr>
            <tr>
            <td><strong>low latency</strong></td>
            <td>RTOS minimizes interrupt response times and
            context-switching overhead, enabling rapid task execution
            and efficient handling of time-sensitive operations
            (<em>e.g.</em>, Linux spends <strong>many
            milliseconds</strong> handling interrupts such as disk
            access!)</td>
            </tr>
            <tr>
            <td><strong>resource management</strong></td>
            <td>RTOS provides mechanisms for efficient allocation and
            management of system resources, such as memory, CPU and
            peripherals, to ensure optimal performance</td>
            </tr>
            <tr>
            <td><strong>scalability</strong></td>
            <td>RTOS is often lightweight and modular, making it
            suitable for resource-constrained environments like
            microcontrollers and embedded systems</td>
            </tr>
            <tr>
            <td><strong>reliability and fault tolerance</strong></td>
            <td>many RTOS implementations include features to enhance
            system stability, such as error detection, recovery
            mechanisms and redundancy</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="kernels-in-rtos-1" class="level2"
            data-number="9.1">
            <h2 data-number="9.1"><span
            class="header-section-number">9.1</span> Kernels in
            RTOS</h2>
            <p>As with most operating systems, the kernel provides the
            essential services in an RTOS. In hard real-time systems,
            the kernel must guarantee predictable and deterministic
            behavior to ensure that all tasks meet their deadlines. In
            this chapter we focus on kernel aspects that are
            <em>specific to RTS</em>.</p>
            <p>The RTOS kernel deals with,</p>
            <ol type="1">
            <li><a href="#tasks-jobs-threads">task management</a></li>
            <li><a
            href="#inter-task-communication-and-synchronization">communication
            and synchronization</a></li>
            <li><a href="#memory-management">memory management</a></li>
            <li><a href="#timer-and-interrupt-management">timer and
            interrupt handling</a></li>
            <li><a href="#kernel-performance-metrics">performance
            metrics</a></li>
            </ol>
            <section id="tasks-jobs-threads-1" class="level3"
            data-number="9.1.1">
            <h3 data-number="9.1.1"><span
            class="header-section-number">9.1.1</span> Tasks, Jobs,
            Threads</h3>
            <p>The design of RTOSes (and RTS in general) deal with
            <strong>tasks</strong>, <strong>jobs</strong> and, for
            implementation-specific details,
            <strong>threads</strong>.</p>
            <p>A real-time <strong>task</strong>, <span
            class="math inline"><em>τ</em><sub><em>i</em></sub></span>
            is defined using the following parameters: <span
            class="math inline">(<em>ϕ</em><sub><em>i</em></sub>, <em>p</em><sub><em>i</em></sub>, <em>c</em><sub><em>i</em></sub>, <em>d</em><sub><em>i</em></sub>)</span>
            where,</p>
            <table>
            <thead>
            <tr>
            <th>Symbol</th>
            <th>Description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>ϕ</em><sub><em>i</em></sub></span></td>
            <td>Phase (offset for the first job of a task)</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>p</em><sub><em>i</em></sub></span></td>
            <td>Period</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>c</em><sub><em>i</em></sub></span></td>
            <td>Worst-case execution time</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>d</em><sub><em>i</em></sub></span></td>
            <td>Deadline</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, a real-time tast <em>set</em> (of size
            ‘<em>n</em>’) is collection of such tasks, <em>i.e.,</em>
            <span
            class="math inline"><em>τ</em> = <em>τ</em><sub>1</sub>, <em>τ</em><sub>2</sub>, ...<em>τ</em><sub><em>n</em></sub></span>.
            Given a real-time task set, the <em>first</em> step is to
            check if the task set is <strong>schedulable</strong>,
            <em>i.e.,</em> check whether all <strong>jobs</strong> of a
            task will meet their deadlines (a <strong>job</strong> is an
            <strong>instance</strong> of a task). For this purpose,
            multiple <strong>schedulability tests</strong> have been
            developed, each depending on the scheduling algorithm being
            used.</p>
            <blockquote>
            <ul>
            <li>remember that task is a set of parameters.</li>
            <li>We “release” multiple “<em>jobs</em>” of each task, each
            with its own deadline</li>
            <li>if all jobs of all tasks meet their deadlines, then the
            system remains <em>safe</em>.</li>
            </ul>
            </blockquote>
            <p>A <strong>thread</strong>, then, is an
            <strong>implementation</strong> of task/job – depending on
            the actual OS, it could be either, or both.</p>
            <p>At a high level, here is a comparison between tasks, jobs
            and threads (<strong>note:</strong> these details may vary
            depending on the <em>specific</em> RTOS):</p>
            <table>
            <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 18%" />
            <col style="width: 30%" />
            </colgroup>
            <thead>
            <tr>
            <th><strong>aspect</strong></th>
            <th><strong>task</strong></th>
            <th><strong>job</strong></th>
            <th><strong>thread</strong></th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>definition</strong></td>
            <td>a task is a <strong>unit of work</strong> that
            represents a program or function executing in the RTOS</td>
            <td>a job is a <strong>specific instance</strong> or
            execution of a task, often tied to a particular event or
            trigger</td>
            <td>a thread is the <strong>smallest unit of
            execution</strong> within a task, sharing the task’s
            resources</td>
            </tr>
            <tr>
            <td><strong>granularity</strong></td>
            <td>coarse-grained; represents a complete function or
            program</td>
            <td>fine-grained; represents a single execution of a
            task</td>
            <td>fine-grained; represents a single flow of execution
            within a task</td>
            </tr>
            <tr>
            <td><strong>resource ownership</strong></td>
            <td>owns its resources (e.g., stack, memory, state)</td>
            <td>does not own resources; relies on the task’s
            resources</td>
            <td>shares resources (e.g., memory, address space) with
            other threads in the same task</td>
            </tr>
            <tr>
            <td><strong>scheduling</strong></td>
            <td>scheduled by the RTOS kernel based on priority or
            scheduling algorithm</td>
            <td>not directly scheduled; executed as part of a task’s
            execution</td>
            <td>scheduled by the RTOS kernel, often within the context
            of a task</td>
            </tr>
            <tr>
            <td><strong>concurrency</strong></td>
            <td>tasks run concurrently, managed by the RTOS
            scheduler</td>
            <td>jobs are sequential within a task but may overlap across
            tasks</td>
            <td>threads run concurrently, even within the same task</td>
            </tr>
            <tr>
            <td><strong>state management</strong></td>
            <td>maintains its own state (e.g., ready, running,
            blocked)</td>
            <td>state is transient and tied to the task’s execution</td>
            <td>maintains its own state but shares the task’s overall
            context</td>
            </tr>
            <tr>
            <td><strong>isolation</strong></td>
            <td>high isolation; tasks do not share memory or resources
            by default <strong>++</strong></td>
            <td>no isolation; jobs are part of a task’s execution</td>
            <td>low isolation; threads share memory and resources within
            a task</td>
            </tr>
            <tr>
            <td><strong>overhead</strong></td>
            <td>higher overhead due to separate stacks and contexts</td>
            <td>minimal overhead, as it relies on the task’s
            resources</td>
            <td>moderate overhead, as threads share resources but
            require context switching</td>
            </tr>
            <tr>
            <td><strong>use case</strong></td>
            <td>used to model independent functions or processes (e.g.,
            control loops)</td>
            <td>used to represent a single execution of a task (e.g.,
            processing a sensor reading)</td>
            <td>used to parallelize work within a task (e.g., handling
            multiple i/o operations)</td>
            </tr>
            <tr>
            <td><strong>example</strong></td>
            <td>a task for controlling a motor</td>
            <td>a job for processing a specific motor command</td>
            <td>a thread for reading sensor data while another thread
            logs the data</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>(<strong>++</strong> sometimes tasks <strong>do</strong>
            contend for resources, so we need to mitigate access to
            them, via locks, semaphores, etc. and then have to deal with
            thorny issues such as <strong>priority
            inversions</strong>)</p>
            <p>A task is often described using a <strong>task control
            block</strong> (TCB):</p>
            <p><img src="img/rtos/tcb_sequence_png/tcb_12.png"></p>
            <p>Tasks typically cycle through a set of states, for
            instance (taken from the <a
            href="https://www.freertos.org/Documentation/02-Kernel/02-Kernel-features/01-Tasks-and-co-routines/02-Task-states">FreeRTOS</a>
            real-time OS):</p>
            <p><img src="img/rtos/free_rtos/freertos_taskstate.gif" width="300"></p>
            <p><br></p>
            <p>While the <code>READY</code>, <code>RUNNING</code> and
            <code>BLOCKED</code> states are similar to those in
            general-purpose operating systems (GPOS), <em>periodic</em>
            RTOSes must introduce an additional state:
            <strong><code>IDLE</code></strong> or
            <strong><code>SUSPENDED</code></strong>:</p>
            <ul>
            <li>periodic task enters this state when it (rather one
            ‘job’) completes its execution → has to wait for the
            beginning of the next period</li>
            <li>to be awakened by the timer (<em>i.e.,</em> to launch
            the next instance/job), the task must notify the end of its
            cycle by executing a specific system call,
            <code>end cycle</code> → puts the job in the IDLE state and
            assigns the processor to another ready job</li>
            <li>at the right time, each periodic task in IDLE state →
            awakened by kernel and inserted in the ready queue</li>
            </ul>
            <p>This operation is carried out by a routine
            <strong>activated by a timer</strong> → verifies, at each
            tick, whether some task(job) has to be awakened.</p>
            <p>TCBs are usually managed in kernel
            <strong>queues</strong> (the implementation details may vary
            depending on the particular RTOS).</p>
            <p><strong>Context Switch Overheads</strong>:</p>
            <p>One of the main issues with multitasking and preepmtion
            is that of <strong>context switch overheads</strong>,
            <em>i.e.,</em> the time and resources required to switch
            from one task to another. For instance, consider this
            example of two tasks running on an ARM Cortex-M4:</p>
            <div class="sourceCode" id="cb21"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> Task1<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Task 1 operations</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        LED_Toggle<span class="op">();</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        delay_ms<span class="op">(</span><span class="dv">100</span><span class="op">);</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>and</p>
            <div class="sourceCode" id="cb22"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> Task2<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Task 2 operations</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>        ReadSensor<span class="op">();</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>        delay_ms<span class="op">(</span><span class="dv">200</span><span class="op">);</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>When switching between Task1 and Task2, an RTOS might
            need to:</p>
            <ul>
            <li>save <code>16</code> general-purpose registers</li>
            <li>save the program counter and stack pointer</li>
            <li>update the memory protection unit settings</li>
            <li>load the new task’s context (program into memory,
            registers, cache, <em>etc.</em>)</li>
            </ul>
            <p>So, on the ARM Cortex-M4,</p>
            <table>
            <colgroup>
            <col style="width: 38%" />
            <col style="width: 61%" />
            </colgroup>
            <thead>
            <tr>
            <th>effect</th>
            <th>cost</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>basic context switch</td>
            <td><code>200-400</code> CPU cycles</td>
            </tr>
            <tr>
            <td>cache and pipeline effects, total overhead</td>
            <td><code>1000+</code> cycles</td>
            </tr>
            <tr>
            <td>frequent switching (e.g., every <code>1 ms</code>)</td>
            <td>could consume <code>1-2%</code> of CPU time!</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>These costs can add up, especially if the system has,</p>
            <ul>
            <li>many RT tasks and frequent
            <strong>preemption</strong></li>
            <li>high-frequency/short period jobs that execute
            frequently</li>
            <li>if tasks contend with each other for shared
            resources</li>
            </ul>
            <p>Hence and RTOS must not only be cognizant of such
            overheads but also <strong>actively manage/mitigate</strong>
            them. Some strategies could include:</p>
            <ol type="1">
            <li><strong>better task/schedule design</strong>:
            <em>e.g.,</em> group related operations to reduce context
            switches</li>
            </ol>
            <div class="sourceCode" id="cb23"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> Task_Sensors<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Handle multiple sensors in one task</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        ReadTemperature<span class="op">();</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        ReadPressure<span class="op">();</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        ReadHumidity<span class="op">();</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        delay_ms<span class="op">(</span><span class="dv">500</span><span class="op">);</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="2" type="1">
            <li><strong>priority-based scheduling</strong>:
            <em>e.g.,</em> high priority task gets more CPU</li>
            </ol>
            <div class="sourceCode" id="cb24"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> CriticalTask<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Set high priority</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    setPriority<span class="op">(</span>HIGH_PRIORITY<span class="op">);</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        ProcessCriticalData<span class="op">();</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        delay_ms<span class="op">(</span><span class="dv">50</span><span class="op">);</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="3" type="1">
            <li><strong>optimizing memory layouts</strong>:
            <em>e.g.</em>, align task stacks to cache line
            boundaries</li>
            </ol>
            <div class="sourceCode" id="cb25"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#define STACK_SIZE </span><span class="dv">1024</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="dt">static</span> __attribute__<span class="op">((</span>aligned<span class="op">(</span><span class="dv">32</span><span class="op">)))</span> </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="dt">uint8_t</span> task1_stack<span class="op">[</span>STACK_SIZE<span class="op">];</span></span></code></pre></div>
            <p><strong>Note:</strong> these are not comprehensive and
            other strategies could be followed, for instance
            <strong>avoiding multitasking altogether</strong>! All
            functions could be implemented in a <strong>single</strong>
            process that runs a giant, infinite loop known as a <a
            href="https://my.eng.utah.edu/~cs5785/slides-f10/22-1up.pdf"><strong>cyclic
            executive</strong></a>. Newer RTOSes shun ths cyclic
            executive in favor of the multitasking model since the
            latter provides more flexibility, control and adaptability
            but many critical systems (especially older, long-running
            ones) still use the cyclic executive. For instance, nuclear
            reactors, chemical plants, <em>etc.</em></p>
            <p>In any case, a <strong>precise</strong> understanding of
            these overheads is crucial for:</p>
            <ul>
            <li>setting appropriate task priorities</li>
            <li>determining minimum task periods</li>
            <li>calculating worst-case execution times</li>
            <li>meeting real-time deadlines</li>
            <li>optimizing system performance</li>
            </ul>
            <p>There is significant (ongoing) work, both in industry as
            well as academia, on how to get a handle on context switch
            overheads while still allowing for flexibility and
            modularity in the development of RTS.</p>
            </section>
            <section id="inter-task-communication-and-synchronization-1"
            class="level3" data-number="9.1.2">
            <h3 data-number="9.1.2"><span
            class="header-section-number">9.1.2</span> (Inter-Task)
            Communication and Synchronization</h3>
            <p>RTOSes use various mechanisms like semaphores, mutexes,
            message queues and event flags for communication and
            synchronization between tasks. Here are some examples:</p>
            <ol type="1">
            <li><strong>Semaphores</strong>:</li>
            </ol>
            <ul>
            <li>binary semaphores: work like a mutex, with values 0 or
            1</li>
            <li>counting semaphores: can have multiple values, useful
            for managing resource pools</li>
            </ul>
            <div class="sourceCode" id="cb26"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Example of binary semaphore usage</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>semaphore_t sem<span class="op">;</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>sem_init<span class="op">(&amp;</span>sem<span class="op">,</span> <span class="dv">1</span><span class="op">);</span>  <span class="co">// Initialize with 1</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> TaskA<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>        sem_wait<span class="op">(&amp;</span>sem<span class="op">);</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Critical section</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        accessSharedResource<span class="op">();</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        sem_post<span class="op">(&amp;</span>sem<span class="op">);</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="2" type="1">
            <li><strong>Mutexes</strong> (mutual exclusion):</li>
            </ol>
            <ul>
            <li>mutexes provide exclusive access to shared
            resources</li>
            <li>they include <strong>priority inheritance</strong> to
            prevent <strong>priority inversion</strong></li>
            </ul>
            <div class="sourceCode" id="cb27"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>mutex_t mutex<span class="op">;</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>mutex_init<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> TaskB<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    mutex_lock<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Protected shared resource access</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    updateSharedData<span class="op">();</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    mutex_unlock<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="3" type="1">
            <li><strong>Message Queues</strong>:</li>
            </ol>
            <ul>
            <li>they allow <strong>ordered data transfer</strong>
            between tasks</li>
            <li>provide for buffering capabilities</li>
            </ul>
            <div class="sourceCode" id="cb28"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>queue_t msgQueue<span class="op">;</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>queue_create<span class="op">(&amp;</span>msgQueue<span class="op">,</span> MSG_SIZE<span class="op">,</span> MAX_MSGS<span class="op">);</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> SenderTask<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    message_t msg <span class="op">=</span> prepareMessage<span class="op">();</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    queue_send<span class="op">(&amp;</span>msgQueue<span class="op">,</span> <span class="op">&amp;</span>msg<span class="op">,</span> TIMEOUT<span class="op">);</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> ReceiverTask<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    message_t msg<span class="op">;</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    queue_receive<span class="op">(&amp;</span>msgQueue<span class="op">,</span> <span class="op">&amp;</span>msg<span class="op">,</span> TIMEOUT<span class="op">);</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    processMessage<span class="op">(&amp;</span>msg<span class="op">);</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="4" type="1">
            <li><strong>Event Flags</strong>:</li>
            </ol>
            <ul>
            <li>enable <strong>multiple tasks</strong> to wait for one
            or more events</li>
            <li>support <code>AND</code>/<code>OR</code> conditions for
            event combinations</li>
            </ul>
            <div class="sourceCode" id="cb29"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>event_flags_t events<span class="op">;</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#define EVENT_SENSOR_DATA </span><span class="bn">0x01</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#define EVENT_USER_INPUT  </span><span class="bn">0x02</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> TaskC<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Wait for both events</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    event_wait<span class="op">(&amp;</span>events<span class="op">,</span> EVENT_SENSOR_DATA <span class="op">|</span> EVENT_USER_INPUT<span class="op">,</span> </span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>               EVENT_ALL<span class="op">,</span> TIMEOUT<span class="op">);</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    processEvents<span class="op">();</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <ol start="5" type="1">
            <li><strong>Condition Variables</strong>:</li>
            </ol>
            <ul>
            <li>tasks can wait for <strong>specific
            conditions</strong></li>
            <li>used with mutexes for complex synchronization</li>
            </ul>
            <div class="sourceCode" id="cb30"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>mutex_t mutex<span class="op">;</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>cond_t condition<span class="op">;</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> ConsumerTask<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    mutex_lock<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span><span class="op">(</span>bufferEmpty<span class="op">())</span> <span class="op">{</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        cond_wait<span class="op">(&amp;</span>condition<span class="op">,</span> <span class="op">&amp;</span>mutex<span class="op">);</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    processData<span class="op">();</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    mutex_unlock<span class="op">(&amp;</span>mutex<span class="op">);</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p><br></p>
            <p>Each mechanism has specific use cases:</p>
            <table>
            <thead>
            <tr>
            <th>mechanism</th>
            <th>use case</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>semaphores</strong></td>
            <td>resource management and simple synchronization</td>
            </tr>
            <tr>
            <td><strong>mutexes</strong></td>
            <td>exclusive access to shared resources</td>
            </tr>
            <tr>
            <td><strong>message queues</strong></td>
            <td>data exchange and task communication</td>
            </tr>
            <tr>
            <td><strong>event flags</strong></td>
            <td>multiple event synchronization</td>
            </tr>
            <tr>
            <td><strong>condition variables</strong></td>
            <td>complex state-dependent synchronization</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Common considerations:</p>
            <ol type="1">
            <li>Priority Inversion Prevention: a high-priority (HP) task
            is <strong>indirectly preempted</strong> by a lower-priority
            (LP) task; HP → needs resource (R); R held by → LP, LP
            preempted by medium-priority (MP) task. So <strong>HP waits
            for MP</strong> → inversion of priorities! We will discuss
            solutions (priority inheritance/priority ceiling)
            later.</li>
            <li>Deadlock Avoidance: tasks are *permanently blocked**
            waiting on resources from each other; <span
            class="math inline"><em>τ</em><sub>1</sub></span> holds
            resource <span
            class="math inline"><em>R</em><sub><em>A</em></sub></span>
            and waits for <span
            class="math inline"><em>R</em><sub><em>B</em></sub></span>;
            <span class="math inline"><em>τ</em><sub>2</sub></span>
            holds resource <span
            class="math inline"><em>R</em><sub><em>B</em></sub></span>
            and waits for <span
            class="math inline"><em>R</em><sub><em>A</em></sub></span>.</li>
            <li>Timeout Handling: <em>every</em> synchronization
            mechanism should have a <strong>timeout</strong> to avoid
            indefinite blocking of critical tasks.</li>
            <li>Error Handling: detecting errors and handling them in a
            <strong>robust</strong> manner is critical to maintain
            system reliability; RTOSes use <em>retry mechanisms</em>,
            <em>logging</em> and, most importantly, have <strong>clear
            recovery procedures</strong> for failure scenarios.</li>
            </ol>
            <p>These considerations are crucial for ensuring system
            reliability, maintaining real-time performance, preventing
            system deadlocks, managing system resources effectively and
            handling error conditions gracefully.</p>
            </section>
            <section id="memory-management-1" class="level3"
            data-number="9.1.3">
            <h3 data-number="9.1.3"><span
            class="header-section-number">9.1.3</span> Memory
            Management</h3>
            <p>Real-time systems require <strong>predictable memory
            allocation and deallocation</strong> to avoid delays or
            fragmentation. Hence, they often use <strong>limited memory
            management techniques</strong> often eschewing even the use
            of dynamic memory allocation in favor of <strong>static
            memory allocation</strong>. For instance, many RTS don’t
            even use <code>malloc()</code> or <code>new</code>
            (<em>i.e.,</em> no heap allocated memory) and very often
            avoid garbage collection. The main goal is for tight control
            of the memory management → this makes <em>timing behavior
            more predictable</em>. Hence, the following become
            easier:</p>
            <ul>
            <li>wcet analysis</li>
            <li>schedulability and other analyses</li>
            <li>runtime monitoring and management</li>
            <li>recovery/restart</li>
            </ul>
            <p>Some <strong>goals</strong> for memory management in
            RTOSes:</p>
            <ol type="1">
            <li>predictable execution times for memory operations</li>
            <li>fast allocation/deallocation</li>
            <li>minimal fragmentation, if any</li>
            <li>protection mechanisms between tasks</li>
            </ol>
            <p>In fact, to achieve these goals, many RTSes <strong>don’t
            even use caches</strong> since they can be a major source of
            non-determinism in terms of timing behavior,
            <em>e.g.,</em></p>
            <blockquote>
            <p>if we cannot <strong>exactly calculate</strong> when some
            data/code will hit/miss in cache, then we cannot estimate
            its true timing behavior, leading to a lot of uncertainty →
            <strong>bad</strong>!</p>
            </blockquote>
            <p>Some RTSes use <a
            href="http://www.irisa.fr/alf/downloads/puaut/papers/date07.pdf"><strong>scratchpads</strong></a>
            since they provide cache-like performance but have higher
            predictability since the data onboarding/offloading is
            <strong>explicitly managed</strong> (either by the program
            or the <a
            href="https://cs-people.bu.edu/rmancuso/files/papers/SPM-OS_RTSJ19.pdf">RTOS</a>).</p>
            <p><strong>Some common memory-management techniques for
            RTOSes</strong>:</p>
            <ol type="1">
            <li><strong>static memory allocation</strong>: all memory
            used is allocated/deallocated at <strong>compile
            time</strong>.</li>
            <li><strong>memory pools</strong>: fixed-size blocks are
            pre-allocated for specific purposes → fragmentation and
            provides deterministic allocation times.</li>
            <li><strong>careful stack management</strong>: careful
            sizing/placing/management of the stack</li>
            <li><strong>limited heap memory</strong>: using “safe”
            versions of <code>malloc()</code> for instance</li>
            <li><strong>memory protection</strong>: using hardware such
            as memory protection units (MPUs)</li>
            <li><strong>memory partitioning</strong>: explicitly
            partition memory/caches so that tasks cannot read/write in
            each others’ memory regions</li>
            <li><strong>runtime mechanisms</strong>: such as memory
            usage monitoring, leak detection and managing the
            fragmentation</li>
            </ol>
            <blockquote>
            <p>Of course, each of these mechanisms have their own
            problems and a deliberation on those is left as an exercise
            for the reader.</p>
            </blockquote>
            </section>
            <section id="timer-and-interrupt-management-1"
            class="level3" data-number="9.1.4">
            <h3 data-number="9.1.4"><span
            class="header-section-number">9.1.4</span> Timer and
            Interrupt Management</h3>
            <p>Timer and interrupt management are crucial components of
            an RTOS, ensuring that tasks are <strong>executed at precise
            intervals</strong> and that the system responds promptly to
            (internal and) external events. The role between timers and
            interrupts is closely related, since they offer the very
            <strong>basic</strong> timing mechanism in RTOSes (from <a
            href="https://link.springer.com/book/10.1007/978-1-4614-0676-1">Hard
            Real-Time Computing Systems: Predictable Scheduling
            Algorithms and Applications</a>):</p>
            <blockquote>
            <p>to generate a <strong>time reference</strong>, a timer
            circuit is programmed to interrupt the processor at a
            <strong>fixed rate</strong> and the internal system time is
            represented by an integer variable, which is reset at system
            initialization and is incremented at each <strong>timer
            interrupt</strong>. The interval of time with which the
            timer is programmed to interrupt defines the unit of time in
            the system; that is, the minimum interval of time handled by
            the kernel (time resolution). The unit of time in the system
            is also called a system
            <strong><code>tick</code></strong>.</p>
            </blockquote>
            <p><br></p>
            <p>Timers, in general, play important roles in such systems,
            <em>viz.,</em></p>
            <table>
            <thead>
            <tr>
            <th>role</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>task scheduling</strong></td>
            <td>enable periodic execution of tasks</td>
            </tr>
            <tr>
            <td><strong>timeout management</strong></td>
            <td>prevent indefinite blocking of resources</td>
            </tr>
            <tr>
            <td><strong>event timing</strong></td>
            <td>measure intervals between events</td>
            </tr>
            <tr>
            <td><strong>system timing</strong></td>
            <td>maintain system clock and timestamps</td>
            </tr>
            <tr>
            <td><strong>watchdog functions</strong></td>
            <td>monitor system health and detect lockups</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Typically these systems have the following <em>three</em>
            types of timers:</p>
            <table>
            <colgroup>
            <col style="width: 29%" />
            <col style="width: 70%" />
            </colgroup>
            <thead>
            <tr>
            <th>type</th>
            <th>properties</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>hardware</strong></td>
            <td>- direct access to hardware timing resources<br>-
            highest precision and accuracy<br>- limited in number
            (hardware dependent)<br>- used for critical timing
            functions</td>
            </tr>
            <tr>
            <td><strong>software</strong></td>
            <td>- implemented in software, using hardware timer as
            base<br>- more flexibility, less precise<br>- limited only
            by memory<br>- more suitable for non-critical timing
            functions</td>
            </tr>
            <tr>
            <td><strong>system <code>tick</code></strong></td>
            <td>- <strong>core</strong> timer for RTOS <br> - drives
            task scheduling <br> - fixed frequency</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p><img src="img/mermaid_figs/6.realtime.system_tick.png" width="400"></p>
            <p>There are various <strong>design considerations</strong>
            for timers in an RTOS, <em>viz.,</em></p>
            <ol type="1">
            <li><strong>resolution</strong> → the smaller the
            resolution, the higher the system/hardware/software/runtime
            overheads</li>
            <li><strong>accuracy</strong> → need to understand and
            manage <em>drift</em> and <em>jitter</em>; timers may need
            to be calibrated often++</li>
            <li><strong>power consumption</strong> → more
            accurate/high-precision a timer, higher the power
            consumption; also the <code>tick</code> can result in
            significant power consumption if not implemented/managed
            well</li>
            </ol>
            <p>(++ drift indicates a <em>gradual, long-term change</em>
            in the timer’s frequency over time, whereas jitter refers to
            <em>short-term, random fluctuations</em> in the timing of
            individual clock pulses)</p>
            <p><strong>Interrupt Latencies</strong> → time from when an
            interrupt occurs to when the corresponding interrupt service
            routine (ISR) starts executing. As interrupts are integral
            to the operation of an RTOS, from the implementation of the
            system <code>tick</code> to notifcations of internal
            (watchdog timers) and external events (new sensor data), it
            is important to <strong>minimize interrupt
            latencies</strong>.</p>
            <p>Optimization Techniques (to minimize latencies):</p>
            <ul>
            <li>minimize interrupt frequency → oftean an RTOS will
            disable interrupts in critical sections</li>
            <li>efficient timer and interrupt queue management →
            “nesting” interrupts,</li>
            <li>power-aware timing strategies → “<em>tickless</em>”
            operating systems have been tried</li>
            <li>optimize ISRs → keep them short, use other methods (<a
            href="https://www.osr.com/nt-insider/2009-issue1/deferred-procedure-call-details/">deferred
            procedure calls</a> or “<a
            href="http://www.cs.otago.ac.nz/cosc440/labs/lab08.pdf">bottom
            halves</a>”).</li>
            </ul>
            </section>
            <section id="kernel-performance-metrics-1" class="level3"
            data-number="9.1.5">
            <h3 data-number="9.1.5"><span
            class="header-section-number">9.1.5</span> Kernel
            Performance Metrics</h3>
            <blockquote>
            <p>Essentially, the kernel must be designed to
            <strong>minimize jitter</strong> and ensure that all
            operations have bounded and predictable execution times.</p>
            </blockquote>
            <p>Hence, we can try to evaluate whether an RTOS kernel
            meets these goals using the following metrics
            (<strong>note</strong>: not exhaustive):</p>
            <table>
            <colgroup>
            <col style="width: 48%" />
            <col style="width: 52%" />
            </colgroup>
            <thead>
            <tr>
            <th>metric</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>interrupt latency</strong></td>
            <td>the time taken to respond to an interrupt</td>
            </tr>
            <tr>
            <td><strong>context switch time</strong></td>
            <td>time to switch between tasks</td>
            </tr>
            <tr>
            <td><strong>dispatch latency</strong></td>
            <td>time difference between task being ready and when it
            starts executing</td>
            </tr>
            <tr>
            <td><strong>throughput</strong></td>
            <td>number of tasks?operations kernel can handle per unit
            time</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            <section id="examples-of-rtos-1" class="level2"
            data-number="9.2">
            <h2 data-number="9.2"><span
            class="header-section-number">9.2</span> Examples of
            RTOS</h2>
            <table>
            <colgroup>
            <col style="width: 24%" />
            <col style="width: 41%" />
            <col style="width: 34%" />
            </colgroup>
            <thead>
            <tr>
            <th><strong>name</strong></th>
            <th><strong>description</strong></th>
            <th><strong>features</strong></th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><a href="https://www.freertos.org">FreeRTOS</a></td>
            <td>a widely used, <strong>open-source</strong> RTOS for
            embedded systems</td>
            <td>small footprint, portable, supports a wide range of
            microcontrollers</td>
            </tr>
            <tr>
            <td><a
            href="https://www.windriver.com/products/vxworks">VxWorks</a></td>
            <td><strong>commercial</strong> RTOS used in aerospace,
            defense, applications</td>
            <td>high reliability, real-time performance, and support for
            multi-core processors</td>
            </tr>
            <tr>
            <td><a href="https://blackberry.qnx.com/en">QNX</a></td>
            <td>a <strong>commercial</strong> RTOS known for its
            reliability and use in automotive and medical systems</td>
            <td>microkernel architecture, high security, support for
            posix apis</td>
            </tr>
            <tr>
            <td><a href="https://www.zephyrproject.org">Zephyr</a></td>
            <td><strong>open-source</strong> RTOS designed for IoT and
            Edge devices</td>
            <td>modular, scalable, supports a wide range of hardware
            architectures</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Why is Linux not on the list? While it has many
            (increasing) <a
            href="https://www.zdnet.com/article/real-time-linux-leads-kernel-v6-12s-list-of-new-features/">list
            of real-time features</a>, it is still far from a
            <strong>hard real-time system</strong>, mainly due to its
            complexity. It is difficult to analyze WCETs on Linux or
            completely control its timers → the list is endless. It
            still sees use in many real-time and embedded systems and we
            will (brielfy) explore its real-time capabilities soon.</p>
            <section id="freertos-1" class="level3" data-number="9.2.1">
            <h3 data-number="9.2.1"><span
            class="header-section-number">9.2.1</span> FreeRTOS</h3>
            <p>As mentioned earlier, FreeRTOS is one of the most popular
            open-source RTOS options, widely used in embedded systems
            due to its simplicity, portability and extensive community
            support. It supports,</p>
            <ul>
            <li>creation of multiple tasks, each with its own
            priority</li>
            <li>preemptive and cooperative scheduling</li>
            <li>mechanisms like queues, semaphores, and mutexes for
            communication and synchronization between tasks</li>
            <li>several memory management schemes, including heap_1,
            heap_2, heap_3, heap_4, and heap_5, to suit different
            application requirements</li>
            <li><strong>highly portable</strong> and supports a wide
            range of microcontrollers and development boards, including
            ARM Cortex-M, ESP32 and STM32</li>
            <li>a large and active community, with [extensive
            documentation, tutorials and examples available online</li>
            </ul>
            <p>Here is an example that uses FreeRTOS to blink the LEDs
            on a microcontroller:</p>
            <div class="sourceCode" id="cb31"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;FreeRTOS.h&gt;</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;task.h&gt;</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;gpio.h&gt;</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co">// Task to blink an LED</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> vBlinkTask<span class="op">(</span><span class="dt">void</span> <span class="op">*</span>pvParameters<span class="op">)</span> <span class="op">{</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="op">(</span><span class="dv">1</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>        GPIO_TogglePin<span class="op">(</span>LED_PIN<span class="op">);</span>  <span class="co">// Toggle LED</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        vTaskDelay<span class="op">(</span>pdMS_TO_TICKS<span class="op">(</span><span class="dv">500</span><span class="op">));</span>  <span class="co">// Delay for 500ms</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main<span class="op">(</span><span class="dt">void</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Initialize hardware</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    GPIO_Init<span class="op">(</span>LED_PIN<span class="op">,</span> GPIO_MODE_OUTPUT<span class="op">);</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Create the blink task</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    xTaskCreate<span class="op">(</span>vBlinkTask<span class="op">,</span> <span class="st">&quot;Blink&quot;</span><span class="op">,</span> configMINIMAL_STACK_SIZE<span class="op">,</span> NULL<span class="op">,</span> <span class="dv">1</span><span class="op">,</span> NULL<span class="op">);</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Start the scheduler</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>    vTaskStartScheduler<span class="op">();</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">// The program should never reach here</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(;;);</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p><strong>Resources</strong>:</p>
            <ol type="1">
            <li><a
            href="https://www.freertos.org/Documentation/RTOS_book.html">FreeRTOS
            Documentation</a></li>
            <li><a
            href="https://www.freertos.org/Why-FreeRTOS/Features-and-demos/RAM_constrained_design_tutorial/Real-time-application-design">FreeRTOS
            Tutorials</a></li>
            <li><a
            href="https://forums.freertos.org/t/using-freertos-with-the-raspberry-pi-pico-blog-series/16497"><strong>Raspberry
            Pi and FreeRTOS</strong></a> [<a
            href="https://github.com/aws-iot-builder-tools/freertos-pi-pico">GitHub
            Repo</a>]</li>
            </ol>
            </section>
            <section id="linuxreal-time-1" class="level3"
            data-number="9.2.2">
            <h3 data-number="9.2.2"><span
            class="header-section-number">9.2.2</span>
            Linux+Real-Time</h3>
            <p>As mentioned earlier, Linux, as a general-purpose
            operating system, is not inherently a real-time operating
            system (RTOS). However, it does provide several features and
            mechanisms that can be used to achieve real-time
            performance, especially when combined with real-time patches
            or specialized configurations.</p>
            <p>Some of the real-time features of Linux include:</p>
            <ul>
            <li><p><strong><a
            href="https://wiki.linuxfoundation.org/realtime/start">Preempt-RT
            Patch</a></strong>: a set of patches that convert the Linux
            kernel into a fully preemptible kernel, reducing latency and
            improving real-time performance; the Preempt-RT patch
            achieves this by:</p>
            <ul>
            <li>making almost <strong>all kernel code
            preemptible</strong>: allows higher-priority tasks to
            preempt lower-priority tasks, even when the lower-priority
            tasks are executing kernel code</li>
            <li><strong>converting interrupt handlers to kernel
            threads</strong>: reduces time spent with interrupts
            disabled, for better predictability and lower latency</li>
            <li><strong>implementing priority inheritance</strong>:
            helps prevent priority inversion by temporarily elevating
            priority of lower-priority tasks holding a resource needed
            by higher-priority tasks</li>
            <li><strong>reducing non-preemptible sections</strong>:
            minimizes time during which preemption is disabled, further
            reducing latency</li>
            <li><strong>enhancing timer granularity</strong>: allows for
            more precise timing and scheduling of tasks, crucial for
            real-time applications</li>
            </ul>
            <p>the Preempt-RT patch is widely used in industries such as
            telecommunications, industrial automation and audio
            processing. It is actively maintained and supported by the
            Linux Foundation’s <a
            href="https://wiki.linuxfoundation.org/realtime/rtl/start">Real-Time
            Linux</a> (RTL) collaborative project</p></li>
            <li><p><strong><a
            href="https://man7.org/linux/man-pages/man7/sched.7.html">Real-Time
            scheduling policies</a></strong>: support for real-time
            scheduling policies such as <code>SCHED_FIFO</code> and
            <code>SCHED_RR</code>, which provide deterministic
            scheduling behavior</p></li>
            <li><p><strong><a
            href="https://www.kernel.org/doc/html/latest/timers/hrtimers.html">High-resolution
            timers</a></strong>: support for high-resolution timers that
            allow for precise timing and scheduling of tasks</p></li>
            <li><p>basic <strong><a
            href="https://www.kernel.org/doc/Documentation/locking/priority-inheritance.txt">priority
            inheritance</a></strong>: mechanism to prevent priority
            inversion by temporarily elevating the priority of
            lower-priority tasks holding a resource needed by
            higher-priority tasks</p></li>
            <li><p><strong><a
            href="https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.html#isolcpus">CPU
            isolation</a></strong>: ability to isolate CPUs from the
            general scheduler, dedicating them to specific real-time
            tasks; also pinning processes to certain cores</p></li>
            <li><p><strong><a
            href="https://www.kernel.org/doc/Documentation/core-api/genericirq.rst">Threaded
            interrupts</a></strong>: support for handling interrupts in
            kernel threads, reducing interrupt latency and improving
            predictability</p></li>
            <li><p><strong><a
            href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_for_real_time/8/html/understanding_rhel_for_real_time/assembly_memory-management-on-rhel-for-real-time-_understanding-rhel-for-real-time-core-concepts#con_demand-paging_assembly_memory-management-on-rhel-for-real-time-">Memory
            management</a></strong> techniques: such as <a
            href="https://linux.die.net/man/2/mlock"><strong>memory
            locking</strong></a> to prevent pages from being swapped,
            the use of “<a
            href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/performance_tuning_guide/s-memory-transhuge"><strong>huge</strong></a>”
            pages and memory <a
            href="https://docs.kernel.org/core-api/memory-allocation.html"><strong>pre-allocation</strong></a></p></li>
            <li><p><strong><a
            href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt">Control
            groups (cgroups)</a></strong>: mechanism to allocate CPU,
            memory and I/O resources to specific groups of tasks,
            ensuring resource availability for real-time tasks</p></li>
            </ul>
            <p>These features, when properly configured, can help
            achieve real-time performance on Linux, making it suitable
            for certain real-time and embedded applications.</p>
            </section>
            <section id="raspberry-pi-osreal-time-1" class="level3"
            data-number="9.2.3">
            <h3 data-number="9.2.3"><span
            class="header-section-number">9.2.3</span> Raspberry Pi
            OS+Real-Time</h3>
            <p>The <a
            href="https://www.raspberrypi.com/software/">Raspberry Pi
            OS</a> can also be made “real-time” in the same manner as
            decribed above, since it is a Linux variant.</p>
            <p>Though, there are some attempts at getting the Pi to
            behave in a real-time fashion, <em>e.g.,</em>: <a
            href="https://www.socallinuxexpo.org/sites/default/files/presentations/Steven_Doran_SCALE_13x.pdf"><strong>1</strong></a>,
            <a
            href="https://all3dp.com/2/rtos-raspberry-pi-real-time-os/#google_vignette"><strong>2</strong></a>,
            <a
            href="https://floating.io/2023/04/raspberry-pi-in-real-time/"><strong>3</strong></a>.</p>
            <p><br></p>
            </section>
            </section>
            <section id="robot-operating-system-ros-1" class="level2"
            data-number="9.3">
            <h2 data-number="9.3"><span
            class="header-section-number">9.3</span> Robot Operating
            System (ROS)</h2>
            <p>ROS is an <strong>open source middleware</strong>
            framework built for robotics applications. The main goal →
            develop <strong>standards</strong> for robotic software. ROS
            provides many <strong>reusable modules</strong> for
            developing robotic applications.</p>
            <p>Embedded/autonomous programs that do simple tasks (or
            operate with a single sensor/motor) are relatively easy to
            program. As more sensing, actuation, functionality is added
            (consider a larege industrial robot or even an autonomous
            car), programs quickly become quite complex – coordination
            of the data and system states becomes challenging.</p>
            <p><img src="img/rtos/ros/ros.complexity.webp" width="400"></p>
            <p><br></p>
            <p>ROS helps to develop and <strong>scale</strong> such
            applications and also <strong>manages
            communications</strong> between various parts of the
            software. As mentioned earlier, ROS is <a
            href="https://www.redhat.com/en/topics/middleware/what-is-middleware"><strong>middleware</strong></a>:</p>
            <blockquote>
            <p>Middleware is a software layer that connects the
            operating system to applications, data, and users. It
            provides common services and capabilities, like single-sign
            on (SSO), easy communication/coordination (like ROS) or
            application programming interface (API) management.
            Developers can rely on middleware to provide consistent,
            simplified integrations between application components. This
            frees up developers to build core features of applications,
            rather than spend time connecting those features to
            different endpoints and environments, including legacy
            systems.</p>
            </blockquote>
            <p>At a high level, ROS,</p>
            <ul>
            <li>creates a <em>separation</em> of code blocks → into
            reusable blocks</li>
            <li>provides <em>tools</em> → easy communication between
            sub-programs</li>
            <li>is <em>language agnostic</em> → allows different
            components to be written in, say Python and C and yet
            communicate using the <strong>ROS communication
            protocol</strong></li>
            </ul>
            <p>A simple example: <a
            href="https://dilipkumar.medium.com/ros-v1-robot-operating-system-88039990e913">control
            of a robotic arm+camera</a>:</p>
            <p><img src="img/rtos/ros/ros.robot_camera_example.webp" width="400"></p>
            <p><br></p>
            <p>To write a ROS application to control this robotic arm,
            we first create a few <strong>subprograms</strong>:</p>
            <ul>
            <li>one for the camera → <code>node</code></li>
            <li>another for → <code>motion planning</code></li>
            <li>one for → <code>hardware drivers</code></li>
            <li>finally one for → <code>joystick</code></li>
            </ul>
            <p>Now we use ROS → <strong>communication</strong> between
            these nodes.</p>
            <p>ROS even provides <strong>plug and play
            libraries</strong> for designing your system, <em>e.g.,</em>
            <a
            href="https://moveit.ai/moveit/ros2/2020/02/18/moveit-2-beta-feature-list.html">inverse
            kinematics libraries</a>, <a
            href="https://roboticseabass.com/2024/06/30/how-do-robot-manipulators-move/">trajectory
            planning for robotic arms</a>, <em>etc.</em></p>
            <section id="ros-components-1" class="level3"
            data-number="9.3.1">
            <h3 data-number="9.3.1"><span
            class="header-section-number">9.3.1</span> ROS
            Components</h3>
            <p>Some important <strong>components</strong> of ROS:</p>
            <p><img src="img/mermaid_figs/6.realtime.ros_architecture_legends.png" width="400">
            <br>
            <img src="img/mermaid_figs/6.realtime.ros_architecture.png" width="400"></p>
            <ol type="1">
            <li><a href="http://wiki.ros.org/Nodes">node</a></li>
            </ol>
            <ul>
            <li>a process that performs <strong>computation</strong> (a
            program/subprogram)</li>
            <li>combined together into a graph</li>
            <li>communicate via “topics”</li>
            <li>operate at a fine-grained scale</li>
            <li>a full system will have <em>multiple</em> nodes,
            <em>e.g.,</em>
            <ul>
            <li>one node controls a laser range-finder</li>
            <li>one Node controls the robot’s wheel motors</li>
            <li>one node performs localization</li>
            <li>one node performs path planning</li>
            <li>one node provides a graphical view of the system</li>
            </ul></li>
            </ul>
            <p>The use of nodes has several benefits such as
            <strong>fault tolerance</strong>, <strong>reduced
            complexity</strong> and <strong>modularity</strong>.</p>
            <ol start="2" type="1">
            <li><a href="http://wiki.ros.org/Topics">topics</a></li>
            </ol>
            <ul>
            <li>they’re <strong>named buses</strong> over which nodes
            exchange “messages”</li>
            <li><strong>anonymous publish/subscribe semantics</strong> →
            decouples production of information from its
            consumption</li>
            <li>nodes are not aware of who they are communicating
            with</li>
            <li>nodes that are interested in data
            <strong>subscribe</strong> to the <em>relevant
            topic</em></li>
            <li>nodes that <em>generate</em> data
            <strong>publish</strong> to the relevant topic</li>
            <li>can be <strong>multiple</strong> publishers and
            subscribers to a topic</li>
            <li>topic is <strong>strongly typed</strong> by publisher →
            nodes can only receive messages with a matching type</li>
            </ul>
            <p>Topics are meant for <em>unidirectional</em>,
            <em>streaming</em> communication. ROS includes other
            mechanisms such as <a
            href="http://wiki.ros.org/Services">services</a> and
            [parameter servers]http://wiki.ros.org/Parameter%20Server)
            for different types of communciations.</p>
            <ol start="3" type="1">
            <li><a href="http://wiki.ros.org/Messages">messages</a></li>
            </ol>
            <ul>
            <li>nodes communicate with each other by publishing messages
            to topics</li>
            <li>simple text files</li>
            <li>simple data structure → <strong>typed
            fields</strong></li>
            <li>support standard primitives (<code>int</code>,
            <code>float</code>, <code>boolean</code>)</li>
            <li>can include arbitrarily nested <code>structs</code> and
            <code>arrays</code></li>
            <li>nodes can exchange → <code>request</code> an
            <code>response</code> messages</li>
            </ul>
            <p>A simple ROS message:</p>
            <pre class="ros"><code>std_msgs/Header header
  uint32 seq
  time stamp
  string frame_id
geometry_msgs/Point point
  float64 x
  float64 y
  float64 z</code></pre>
            <p>Example: <a
            href="https://classes.cs.uchicago.edu/archive/2022/spring/20600-1/ros_intro.html">our
            first ROS message</a>.</p>
            <ol start="4" type="1">
            <li><a href="http://wiki.ros.org/Master">ROS Master</a></li>
            </ol>
            <ul>
            <li>provides naming and registration services to the rest of
            the nodes in the ROS system</li>
            <li>also runs the <a
            href="http://wiki.ros.org/Parameter%20Server">parameter
            server</a> → a shared, multi-variate dictionary that is
            accessible via network APIs, used by nodes to
            <strong>store/retrieve parameters</strong></li>
            <li>tracks publishers and subscribers to topics as well as
            services</li>
            <li>enable individual ROS nodes to locate one anothe</li>
            <li>once located, they communicate in a
            <strong>peer-to-peer</strong> fashion</li>
            </ul>
            <p>Example:</p>
            <ol type="1">
            <li>consider two nodes → <code>camera</code> node and
            <code>image_viewer</code> node</li>
            <li><code>camera</code> notifies <code>master</code> → wants
            to publish images on the topic, <code>images</code></li>
            </ol>
            <p><img src="img/rtos/ros/ROS_master_example_english_1.png"></p>
            <ol start="3" type="1">
            <li>no one is subscribing to the topic, yet → <strong>no
            images sent</strong></li>
            <li><code>image viewer</code> → subscribe to
            <code>images</code> topic</li>
            </ol>
            <p><img src="img/rtos/ros/ROS_master_example_english_2.png"></p>
            <ol start="5" type="1">
            <li>topic, <code>images</code> has both → publisher and
            subscriber</li>
            <li><code>master</code> notifies both → of each others’
            existence</li>
            </ol>
            <p><img src="img/rtos/ros/ROS_master_example_english_3.png"></p>
            <ol start="7" type="1">
            <li>both start <strong>communicating with each
            other</strong>, directly</li>
            </ol>
            <p><br></p>
            <p>A more intricate example of the same:</p>
            <p><img src="img/mermaid_figs/6.realtime.ros_publish_subscribe.png" width="400"></p>
            <ol start="5" type="1">
            <li><a href="http://wiki.ros.org/tf2">ROS transform</a></li>
            </ol>
            <ul>
            <li>robotic system typically has many 3D coordinate frames
            that change over time
            <ul>
            <li><em>e.g.,</em> world frame, base frame, gripper frame,
            head frame, <em>etc.</em></li>
            </ul></li>
            <li>lets the user keep track of multiple coordinate frames
            over time</li>
            <li>maintains the relationship between coordinate frames →
            manages <strong>spatial relationships</strong></li>
            <li>in a tree structure buffered in time</li>
            <li>lets the user transform points, vectors, <em>etc.</em> →
            at any desired point in time</li>
            <li><strong>distributed</strong> → coordinate frames of
            robot available to <strong>all</strong> ROS components on
            any computer in the system</li>
            <li>sensor fusion, motion planning, and navigation</li>
            <li>organizes all coordinate frames and their relationships
            into a <strong>transform tree</strong></li>
            </ul>
            <p>An example of a ROS transform and tree:</p>
            <p><img src="img/mermaid_figs/6.realtime.ros_transform.png" width="400"></p>
            </section>
            <section id="ros-and-real-time-1" class="level3"
            data-number="9.3.2">
            <h3 data-number="9.3.2"><span
            class="header-section-number">9.3.2</span> ROS and
            Real-time?</h3>
            <p>ROS (the first version) is <strong>not</strong>
            real-time. Hence, systems that requires <strong>hard
            real-time guarantees</strong> shoud not use it. But ROS can
            be itegrated into systems that require <em>some</em> latency
            guarantees. If needed, ROS can be run on top of the
            <code>RT_PREEMPT</code> real-time patch on Linux. In
            addition, <strong>specific nodes</strong> can be designed to
            handle real-time functions or programmed to behave as
            real-time control systems.</p>
            <p>If better real-time guarantees are required on ROS, then
            <a
            href="https://roscon.ros.org/2015/presentations/RealtimeROS2.pdf"><strong>ROS
            2</strong></a> if your best bet.</p>
            <p><strong>Resources</strong>: more information on real-time
            and ROS2 can be found at <a
            href="https://xilinx.github.io/KRS/sphinx/build/html/docs/features/realtime_ros2.html">RT
            ROS2 Xilinx</a> and <a
            href="https://github.com/ros-realtime">RT ROS
            Github</a>.</p>
            </section>
            <section id="rosnavio2-1" class="level3"
            data-number="9.3.3">
            <h3 data-number="9.3.3"><span
            class="header-section-number">9.3.3</span> Ros+Navio2</h3>
            <p>We use ROS (the original version, not ROS2) in our class.
            <strong>Note:</strong> while ROS has no real-time
            capabilities, one some embedded systems, if it <em>fast
            enough</em> that we can use it to control safety-critical
            systems such as drones and other small autonomous
            systems.</p>
            <p>In fact, the basic Raspbian image comes installed with
            ROS. We can use it communicate between the Navio2 and the
            controller running on the Pi to exchange critical
            information, <em>e.g.</em>, sensor data.</p>
            <p><img src="img/rtos/ros/ros.ardupilot_navio.png" width="400"></p>
            <p><strong>Resources</strong>: please read the <a
            href="https://docs.emlid.com/navio2/ros/">step-by-step
            instructions</a> on how to connect/use the Navio2 and the Pi
            using ROS.</p>
            <!--link rel="stylesheet" href="./custom.sibin.css"-->
            </section>
            </section>
            </section>
            <section id="scheduling-for-real-time-systems-1"
            class="level1" data-number="10">
            <h1 data-number="10"><span
            class="header-section-number">10</span> Scheduling for
            Real-Time Systems</h1>
            <p>Consider an engine control system that cycles through the
            various phases of operation for an <a
            href="http://automobile-us.blogspot.com">automotive
            engine</a>:</p>
            <p><img src="img/scheduling/engine_animation.gif"></p>
            <p><br></p>
            <p>This system <strong>periodically</strong> cycles through
            multiple tasks, <em>viz.</em>,</p>
            <ol type="1">
            <li>air intake</li>
            <li>pressure</li>
            <li>fuel injection+combustion</li>
            <li>exhaust</li>
            </ol>
            <p>If we correlate this to task “actiations”, then we may
            see the <a
            href="https://retis.sssup.it/~a.biondi/papers/ERIKA_AVR_RTAS16.pdf">following</a>:</p>
            <table>
            <colgroup>
            <col style="width: 50%" />
            <col style="width: 50%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/scheduling/engine_animation.gif" width="180"></td>
            <td><img src="img/scheduling/angular_task.png" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <section id="cyclic-executives" class="level2"
            data-number="10.1">
            <h2 data-number="10.1"><span
            class="header-section-number">10.1</span> Cyclic
            Executives</h2>
            <p>We see that for each <strong>cycle</strong>, the same set
            of tasks <strong>repeat</strong> (<em>i.e.</em>., “periodic
            behavior”). Note though that the tasks <em>need not</em>
            execute in parallel – rather, they must execute sequentially
            for this application. Usually such applications use a
            scheduling mechanism known as a “<strong>cyclic
            executive</strong>”.</p>
            <p>Consider this simple example with three tasks:</p>
            <table>
            <thead>
            <tr>
            <th>task</th>
            <th>c</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>T</em><sub>1</sub></span></td>
            <td>1</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>T</em><sub>2</sub></span></td>
            <td>2</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>T</em><sub>3</sub></span></td>
            <td>3</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>How would we <strong>schedule</strong> this? Assuming a
            single processors (hence a single timeline).</p>
            <p><img src="img/scheduling/cyclic/pngs/cyclic1.png" width="400"></p>
            <p>Well, the <em>simplest</em> mechanism is to just use a
            <strong>sequential</strong> schedule,</p>
            <p><img src="img/scheduling/cyclic/pngs/cyclic4.png" width="400"></p>
            <p>If, as in the case of the engine control example we saw
            earlier, the tasks repeat <em>ad infinitum</em>, then we see
            the pattern also repeating…</p>
            <p><img src="img/scheduling/cyclic/pngs/cyclic5.png" width="400"></p>
            <p>Cyclic executives were common in many critical RTS, since
            they’re <strong>simple</strong> and
            <strong>deterministic</strong>. An implementation could look
            like,</p>
            <pre><code>while(1)    // an infinite loop
{
    // Some Initialization

    Task_T1() ;

    // Some processing, maybe

    Task_T2() ;

    // Some other processing, maybe

    Task_T3() ;

    // Cleanup
}</code></pre>
            <p><strong>Question</strong>: what problems, if any, can
            happen due to cyclic executives?</p>
            <p>The very simplicity of such systems can also be their
            biggest weakness.</p>
            <ol type="1">
            <li><p><strong>lack of flexibility</strong>: as the example
            and code above demonstrate, once a pattern of executions is
            set, it cannot be changed, <strong>unless the system is
            stopped, redesigned/recompiled and restarted</strong>! This
            may not be possible for critical applications. Even for the
            engine control application in cars, this doesn’t just mean
            stopping and restarting the car, but
            <strong>re-flashing</strong> the firmware for the engine,
            which is quite an involved task.</p></li>
            <li><p><strong>scalability</strong>: along similar lines, it
            is difficult to scale the system to deal with additional
            issues or add functionality.</p></li>
            <li><p><strong>resource management</strong>: certain tasks
            can corral resources and hold on to them while others may
            <em>starve</em> – leading to the system becoming unstable.
            For instance, even in the simple example, we see that <span
            class="math inline"><em>T</em><sub>3</sub></span> can
            dominate the execution time on the CPU:</p></li>
            </ol>
            <p><img src="img/scheduling/cyclic/cyclic6.svg" width="400"></p>
            <p>Since the system is <em>one giant executable</em>, it is
            difficult to stop a “runaway task” – the entire system must
            be stopped and restarted, which can lead to serious
            problems.</p>
            <ol start="4" type="1">
            <li><strong>priority</strong>: there is no way to assign
            priority or preemption since all tasks essentially execute a
            the <em>same priority</em>. Hence, if we want to deal with
            higher-priority events (<em>e.g.</em>, read a sensor) or
            even <em>atypical</em> (aperiodic/sporadic) events, such as
            sudden braking in an autonomous car, then a cyclic executive
            is not the right way to go about it.</li>
            </ol>
            <section id="frames" class="level3" data-number="10.1.1">
            <h3 data-number="10.1.1"><span
            class="header-section-number">10.1.1</span> Frames</h3>
            <p>One way to mitigate <em>some</em> of the problems with
            cyclic executives, is to split the resource allocation into
            “frames” → <strong>fixed</strong> chunks of time when a task
            can ain exclusive access to a resource, <em>e.g..</em> the
            processor:</p>
            <ul>
            <li>once a frame starts, the task gets to execute
            <em>uninterrupted</em></li>
            <li>at the end of the frame, the task <em>must give up</em>
            the resource → regardless of whether it was done or not</li>
            </ul>
            <p>So, if we revisit our simple example and break the
            processor schedule into frame sizes of <code>2</code> units,
            each,</p>
            <p><img src="img/scheduling/cyclic/cyclic6_5.frame.svg" width="400"></p>
            <blockquote>
            <p>why <code>2</code>? Well, it is arbitrary for now. But,
            as we shall see later, we can calculate a “good” frame
            size</p>
            </blockquote>
            <p>Now, our schedule looks like,</p>
            <p><img src="img/scheduling/cyclic/cyclic8.frame.svg" width="400"></p>
            <p>As we see from this picture, task <span
            class="math inline"><em>T</em><sub>1</sub></span> doesn’t
            end up using its entire frame and hence, can waste resources
            (one of the pifalls of this method).</p>
            <p>Continuing further,</p>
            <p><img src="img/scheduling/cyclic/cyclic9.frame.svg" width="400"></p>
            <p>Task <span
            class="math inline"><em>T</em><sub>3</sub></span> is
            <em>forced</em> to relinquish the processo at
            <code>t=6</code> even though it has some execution left → on
            account of the frame ending. Now <span
            class="math inline"><em>T</em><sub>1</sub></span> resumes in
            its own frame. <span
            class="math inline"><em>T</em><sub>3</sub></span> has to
            wait until <code>t=10</code> to resume (and complete) its
            execution:</p>
            <p><img src="img/scheduling/cyclic/cyclic12.frame.svg" width="400"></p>
            <p><br> <br> <br> <br> <br> <br> <br> <br> <br> <br></p>
            <p>TODOs:</p>
            <ul>
            <li>cyclic executives</li>
            <li>simple task example – how would you schedule this?</li>
            <li>hard vs soft RTS – explain with deadline diagrams</li>
            <li>task model</li>
            <li>more on cyclic executives, round robin, etc. [static
            table-driven]</li>
            <li>static vs dynamic</li>
            <li>priority-based [static v dynamic]</li>
            <li>dynamic best effort?</li>
            </ul>
            </section>
            </section>
            </section>
            <section id="footnotes"
            class="footnotes footnotes-end-of-document"
            role="doc-endnotes">
            <hr />
            <ol>
            <li id="fn1"><p>TBD<a href="#fnref1" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            <li
            id="fn2"><p>https://dl.acm.org/doi/10.5555/244522.244548<a
            href="#fnref2" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            <li
            id="fn3"><p>https://www.cecs.uci.edu/~papers/compendium94-03/papers/2002/date02/pdffiles/05a_1.pdf
            <!--link rel="stylesheet" href="./custom.sibin.css"--><a
            href="#fnref3" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            <li id="fn4"><p>TBD<a href="#fnref4" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            <li
            id="fn5"><p>https://dl.acm.org/doi/10.5555/244522.244548<a
            href="#fnref5" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            <li
            id="fn6"><p>https://www.cecs.uci.edu/~papers/compendium94-03/papers/2002/date02/pdffiles/05a_1.pdf
            <!--link rel="stylesheet" href="./custom.sibin.css"--><a
            href="#fnref6" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            </ol>
            </section>
            </div>
    </div>
  </div>
  <!--script src="https://vjs.zencdn.net/5.4.4/video.js"></script-->

</body>
</html>
