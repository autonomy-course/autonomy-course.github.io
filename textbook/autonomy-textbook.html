<!doctype html>
<html >
<head>

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!--[if lt IE 9]>
                <script src="http://css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
        <![endif]-->
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Style-Type" content="text/css" />

    <!-- <link rel="stylesheet" type="text/css" href="template.css" /> -->
    <link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/template.css" />

    <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />

    <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
    <!-- <script type='text/javascript' src='menu/js/jquery.cookie.js'></script> -->
    <!-- <script type='text/javascript' src='menu/js/jquery.hoverIntent.minified.js'></script> -->
    <!-- <script type='text/javascript' src='menu/js/jquery.dcjqaccordion.2.7.min.js'></script> -->

    <!-- <link href="menu/css/skins/blue.css" rel="stylesheet" type="text/css" /> -->
    <!-- <link href="menu/css/skins/graphite.css" rel="stylesheet" type="text/css" /> -->
    <!-- <link href="menu/css/skins/grey.css" rel="stylesheet" type="text/css" /> -->

    <!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->


    <!-- <script src="script.js"></script> -->

    <!-- <script src="jquery.sticky-kit.js "></script> -->
    <script type='text/javascript' src='https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/js/jquery.cookie.js'></script>
    <script type='text/javascript' src='https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/js/jquery.hoverIntent.minified.js'></script>
    <script type='text/javascript' src='https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/js/jquery.dcjqaccordion.2.7.min.js'></script>

    <link href="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/css/skins/blue.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/css/skins/graphite.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/menu/css/skins/grey.css" rel="stylesheet" type="text/css" />
    <link href="./elegant_bootstrap.css" rel="stylesheet" type="text/css" />
    <!-- <link href="https://cdn.rawgit.com/ryangrose/easy-pandoc-templates/948e28e5/css/elegant_bootstrap.css" rel="stylesheet" type="text/css" /> -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script src="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/script.js"></script>

    <script src="https://cdn.rawgit.com/diversen/pandoc-bootstrap-adaptive-template/959c3622/jquery.sticky-kit.js"></script>
    <meta name="generator" content="pandoc" />
  <meta name="author" content="Prof. Sibin Mohan, The George Washington University" />
  <meta name="date" content="2025-01-23" />
  <title>Design of Autonomous Systems</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="style.css" />
</head>
<body>


    <div class="navbar navbar-static-top">
    <div class="navbar-inner">
      <div class="container">
        <span class="doc-title">Design of Autonomous Systems</span>
        <ul class="nav pull-right doc-info">
                    <li><p class="navbar-text">Prof. Sibin Mohan, The
George Washington University</p></li>
                              <li><p class="navbar-text">January 23,
2025</p></li>
                  </ul>
      </div>
    </div>
  </div>
    <div class="container">
    <div class="row">
            <div id="TOC" class="span3">
        <div class="well toc">

        <ul>
        <li><a href="#introduction" id="toc-introduction"><span
        class="toc-section-number">1</span> introduction</a>
        <ul>
        <li><a href="#autonomy" id="toc-autonomy"><span
        class="toc-section-number">1.1</span> autonomy</a>
        <ul>
        <li><a href="#what-are-the-aspects-of-autonomy"
        id="toc-what-are-the-aspects-of-autonomy"><span
        class="toc-section-number">1.1.1</span> what are the
        <em>aspects</em> of autonomy?</a></li>
        </ul></li>
        <li><a href="#let-us-define-autonomy"
        id="toc-let-us-define-autonomy"><span
        class="toc-section-number">1.2</span> let us define
        <strong>autonomy</strong></a></li>
        <li><a href="#autonomous-systems"
        id="toc-autonomous-systems"><span
        class="toc-section-number">1.3</span> autonomous
        systems</a></li>
        <li><a href="#sensors-and-actuators"
        id="toc-sensors-and-actuators"><span
        class="toc-section-number">1.4</span> sensors and
        actuators…</a></li>
        <li><a href="#sensing-and-actuation-in-the-real-world"
        id="toc-sensing-and-actuation-in-the-real-world"><span
        class="toc-section-number">1.5</span> sensing and actuation in
        the real world</a>
        <ul>
        <li><a href="#come-back-to-sensing"
        id="toc-come-back-to-sensing"><span
        class="toc-section-number">1.5.1</span> Come back to
        <strong>sensing</strong></a></li>
        </ul></li>
        <li><a href="#overviewarchitecture-of-autonomous-systems"
        id="toc-overviewarchitecture-of-autonomous-systems"><span
        class="toc-section-number">1.6</span> Overview/Architecture of
        Autonomous Systems</a>
        <ul>
        <li><a href="#high-order-functions"
        id="toc-high-order-functions"><span
        class="toc-section-number">1.6.1</span> high-order
        functions</a></li>
        <li><a href="#slam" id="toc-slam"><span
        class="toc-section-number">1.6.2</span> slam</a></li>
        <li><a href="#waypoint-detection"
        id="toc-waypoint-detection"><span
        class="toc-section-number">1.6.3</span> waypoint
        detection</a></li>
        <li><a href="#yolo" id="toc-yolo"><span
        class="toc-section-number">1.6.4</span> yolo</a></li>
        <li><a href="#object-avoidance" id="toc-object-avoidance"><span
        class="toc-section-number">1.6.5</span> object
        avoidance</a></li>
        <li><a href="#path-planning" id="toc-path-planning"><span
        class="toc-section-number">1.6.6</span> path planning</a></li>
        <li><a href="#compute-platform" id="toc-compute-platform"><span
        class="toc-section-number">1.6.7</span> compute
        platform</a></li>
        <li><a href="#still-some-non-functional-requirements-remain"
        id="toc-still-some-non-functional-requirements-remain"><span
        class="toc-section-number">1.6.8</span> still some
        <strong>non-functional</strong> requirements remain</a></li>
        <li><a href="#safety" id="toc-safety"><span
        class="toc-section-number">1.6.9</span> safety!</a></li>
        <li><a href="#security" id="toc-security"><span
        class="toc-section-number">1.6.10</span> security</a></li>
        <li><a href="#course-structure" id="toc-course-structure"><span
        class="toc-section-number">1.6.11</span> Course
        Structure</a></li>
        </ul></li>
        </ul></li>
        <li><a href="#embedded-architectures"
        id="toc-embedded-architectures"><span
        class="toc-section-number">2</span> Embedded Architectures</a>
        <ul>
        <li><a href="#the-wcet-problem" id="toc-the-wcet-problem"><span
        class="toc-section-number">2.1</span> The <strong>wcet</strong>
        problem</a></li>
        <li><a href="#embedded-processors"
        id="toc-embedded-processors"><span
        class="toc-section-number">2.2</span> Embedded Processors</a>
        <ul>
        <li><a href="#microcontrollers" id="toc-microcontrollers"><span
        class="toc-section-number">2.2.1</span>
        Microcontrollers</a></li>
        <li><a href="#digital-signal-processors-dsps"
        id="toc-digital-signal-processors-dsps"><span
        class="toc-section-number">2.2.2</span> Digital Signal
        Processors (DSPs)</a></li>
        <li><a href="#microprocessors" id="toc-microprocessors"><span
        class="toc-section-number">2.2.3</span> Microprocessors</a></li>
        <li><a href="#system-on-a-chip-soc"
        id="toc-system-on-a-chip-soc"><span
        class="toc-section-number">2.2.4</span> System-on-a-Chip
        (SoC)</a></li>
        <li><a href="#embedded-accelarators-e.g.-gpu-enabled-systems"
        id="toc-embedded-accelarators-e.g.-gpu-enabled-systems"><span
        class="toc-section-number">2.2.5</span> Embedded Accelarators
        (e.g. GPU-enabled systems)</a></li>
        <li><a href="#asics-and-fpgas" id="toc-asics-and-fpgas"><span
        class="toc-section-number">2.2.6</span> ASICs and FPGAs</a></li>
        </ul></li>
        <li><a href="#communication-and-io"
        id="toc-communication-and-io"><span
        class="toc-section-number">2.3</span> Communication and I/O</a>
        <ul>
        <li><a href="#uart-rs-232" id="toc-uart-rs-232"><span
        class="toc-section-number">2.3.1</span> UART | RS-232</a></li>
        <li><a href="#synchronous-i2c-and-spi"
        id="toc-synchronous-i2c-and-spi"><span
        class="toc-section-number">2.3.2</span> Synchronous |
        I<sup>2</sup>C and SPI</a></li>
        <li><a href="#general-purpose-io-gpio"
        id="toc-general-purpose-io-gpio"><span
        class="toc-section-number">2.3.3</span> General-Purpose I/O
        (GPIO)</a></li>
        <li><a href="#jtag-debugging-interface"
        id="toc-jtag-debugging-interface"><span
        class="toc-section-number">2.3.4</span> JTAG Debugging
        Interface</a></li>
        <li><a href="#controller-area-network-can"
        id="toc-controller-area-network-can"><span
        class="toc-section-number">2.3.5</span> Controller Area Network
        (CAN)</a></li>
        <li><a href="#other-broadly-used-protocols"
        id="toc-other-broadly-used-protocols"><span
        class="toc-section-number">2.3.6</span> Other Broadly Used
        Protocols</a></li>
        </ul></li>
        <li><a href="#raspberry-pi-and-navio2"
        id="toc-raspberry-pi-and-navio2"><span
        class="toc-section-number">2.4</span> Raspberry Pi and
        Navio2</a></li>
        <li><a href="#references" id="toc-references"><span
        class="toc-section-number">2.5</span> References</a></li>
        </ul></li>
        <li><a href="#sensors-and-sensing"
        id="toc-sensors-and-sensing"><span
        class="toc-section-number">3</span> Sensors and Sensing</a>
        <ul>
        <li><a href="#types-of-sensors" id="toc-types-of-sensors"><span
        class="toc-section-number">3.1</span> Types of Sensors</a>
        <ul>
        <li><a href="#inertial-measurement-units-imu"
        id="toc-inertial-measurement-units-imu"><span
        class="toc-section-number">3.1.1</span> Inertial Measurement
        Units (IMU)</a></li>
        <li><a
        href="#bouncing-of-electromagnetic-waves-lidar-and-mmwave"
        id="toc-bouncing-of-electromagnetic-waves-lidar-and-mmwave"><span
        class="toc-section-number">3.1.2</span> Bouncing of
        Electromagnetic Waves | LiDAR and mmWave</a></li>
        <li><a href="#ultrasonic" id="toc-ultrasonic"><span
        class="toc-section-number">3.1.3</span> Ultrasonic</a></li>
        </ul></li>
        <li><a href="#errors-in-sensing"
        id="toc-errors-in-sensing"><span
        class="toc-section-number">3.2</span> Errors in Sensing</a></li>
        <li><a href="#analog-to-digital-convertors-adcs"
        id="toc-analog-to-digital-convertors-adcs"><span
        class="toc-section-number">3.3</span> Analog to Digital
        Convertors (ADCs)</a>
        <ul>
        <li><a href="#adc-sampling-rate"
        id="toc-adc-sampling-rate"><span
        class="toc-section-number">3.3.1</span> ADC Sampling
        Rate</a></li>
        <li><a href="#adc-resolution" id="toc-adc-resolution"><span
        class="toc-section-number">3.3.2</span> ADC Resolution</a></li>
        </ul></li>
        </ul></li>
        </ul>

        </div>
      </div>
            <div class="span9">
            <!--link rel="stylesheet" href="./custom.sibin.css"-->
            <section id="introduction" class="level1" data-number="1">
            <h1 data-number="1"><span
            class="header-section-number">1</span> introduction</h1>
            <section id="autonomy" class="level2" data-number="1.1">
            <h2 data-number="1.1"><span
            class="header-section-number">1.1</span> autonomy</h2>
            <p>what is “<em>autonomy</em>”?</p>
            <p>we see various examples of it…</p>
            <p><img src="img/philippine_uav.png" height="100" width = "200" style="display: inline-block; margin-right: 10px;">
            <img src="img/white_tesla.png" height="100" width = "200"  style="display: inline-block;"></p>
            <section id="what-are-the-aspects-of-autonomy"
            class="level3" data-number="1.1.1">
            <h3 data-number="1.1.1"><span
            class="header-section-number">1.1.1</span> what are the
            <em>aspects</em> of autonomy?</h3>
            <table>
            <colgroup>
            <col style="width: 13%" />
            <col style="width: 86%" />
            </colgroup>
            <tbody>
            <tr>
            <td><strong>perception</strong></td>
            <td>how do you “<em>see</em>” the world around you?</td>
            </tr>
            <tr>
            <td><strong>sensing</strong></td>
            <td>various ways to perceive the world around you
            (<em>e.g</em>, camera, LiDar)</td>
            </tr>
            <tr>
            <td><strong>compute</strong></td>
            <td>what do you “<em>do</em>” with the information about the
            world?</td>
            </tr>
            <tr>
            <td><strong>motion</strong></td>
            <td>do your computations result in any “<em>physical</em>”
            changes?</td>
            </tr>
            <tr>
            <td><strong>actuation</strong></td>
            <td>what “<em>actions</em>”, if any, do you take for said
            physical changes?</td>
            </tr>
            <tr>
            <td><strong>planning</strong></td>
            <td>can you do some “<em>higher order</em>” thinking <br>
            (<em>i.e.,</em> not just your immediate next move)</td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            <section id="let-us-define-autonomy" class="level2"
            data-number="1.2">
            <h2 data-number="1.2"><span
            class="header-section-number">1.2</span> let us define
            <strong>autonomy</strong></h2>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <tbody>
            <tr>
            <td>Autonomy is the ability to <br> <strong>perform given
            tasks</strong> <br> based on the system’s perception <br>
            <scb>without</scb> human intervention</td>
            <td><img src="img/robot_profile_view.jpg" height="275"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="autonomous-systems" class="level2"
            data-number="1.3">
            <h2 data-number="1.3"><span
            class="header-section-number">1.3</span> autonomous
            systems</h2>
            <table>
            <colgroup>
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            </colgroup>
            <tbody>
            <tr>
            <td><strong>cyber</strong></td>
            <td><img src="img/cps_software.png" width="275"></td>
            <td><img src="img/cps_networking.png" height="275"></td>
            <td><img src="img/cps_ecus.png" height="275"></td>
            </tr>
            <tr>
            <td><strong>physical</strong></td>
            <td><img src="img/cps_sensors.png" height="275"></td>
            <td><img src="img/cps_actuators.png" height="275"></td>
            <td><img src="img/cps_plants.png" height="275"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>hence, they fall under the class of systems →
            <strong>cyber-physical</strong> systems</p>
            </section>
            <section id="sensors-and-actuators" class="level2"
            data-number="1.4">
            <h2 data-number="1.4"><span
            class="header-section-number">1.4</span> sensors and
            actuators…</h2>
            <table>
            <colgroup>
            <col style="width: 50%" />
            <col style="width: 50%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/cps_sensors.png" width="150" style="border: 2px solid purple; display: inline-block; padding: 10px; background-color:rgb(236, 219, 250);"></td>
            <td><img src="img/cps_actuators.png" width="125" style="border: 2px solid purple; display: inline-block; padding: 10px; background-color:rgb(236, 219, 250);"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>…are <strong>everywhere</strong>!</p>
            <p>the <strong>embedded</strong> components → interactions
            with the real world</p>
            </section>
            <section id="sensing-and-actuation-in-the-real-world"
            class="level2" data-number="1.5">
            <h2 data-number="1.5"><span
            class="header-section-number">1.5</span> sensing and
            actuation in the real world</h2>
            <p>consider the following example of two cars… <img
            src="img/cars_sensing/cars_sensing_1.png"
            alt="Two cars, one behind the over, top view" /></p>
            <p>the second car is approaching the first <img
            src="img/cars_sensing/cars_sensing_2.png"
            alt="Two cars, one behind the over, top view, an arror to the left on top of the car on the right" /></p>
            <p><strong>sensors</strong> → constantly gathering
            data/sensing</p>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/cars_sensing/cars_sensing_3.png" width="400"></p>
            </div>
            </div>
            <p>on detection (of other car) → quickly
            <strong>compute</strong> what to do</p>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            <li>
            computation
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/cars_sensing/cars_sensing_4.png" width="400"></p>
            </div>
            </div>
            <p>take <strong>physical action</strong> (actuation) → say
            by braking <em>in time</em></p>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            <li>
            computation
            </li>
            <li>
            actuation
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/cars_sensing/cars_sensing_5.png" width="400"></p>
            </div>
            </div>
            <div class="multicolumn">
            <div>
            <ol>
            <li>
            periodic sensing
            </li>
            <li>
            computation
            </li>
            <li>
            actuation
            </li>
            </ol>
            </div>
            <div>
            <p><img src="img/sense_planning_actuation.png" width="400"></p>
            </div>
            </div>
            <p>“<strong>control</strong>”</p>
            <p>Remember this → on detection (of other car) →
            <scb>quickly</scb> <strong>compute</strong> what to do</p>
            <p><img src="img/cars_sensing/cars_sensing_4.png" width="400"></p>
            <p>“quickly” compute → complete computation/actuation →
            before a <strong>deadline</strong></p>
            <p>This is a <strong>real-time system</strong>.</p>
            <section id="come-back-to-sensing" class="level3"
            data-number="1.5.1">
            <h3 data-number="1.5.1"><span
            class="header-section-number">1.5.1</span> Come back to
            <strong>sensing</strong></h3>
            <!--div class="multicolumn">
            <div>
            <br>
            <ul>
                <li>we see <i>one</i> sensor (maybe LiDAR)</li>
                <li>reality &rarr; <b>multiple</b> sensors</li>
                <li>cameras, radars, lidar, etc.</li>
            <ul>
            </div>
            <div>
            <img src="img/autonomous_cars_sensors.png">
            </div>
            </div-->
            <p>Multiple sensors in an autonomous vehicle → need to
            <em>combine</em> them somehow</p>
            <p><strong>sensor fusion</strong></p>
            <p>Once we have information from the sensors (fused or
            otherwise)…</p>
            <p><img src="img/kalman_statistical_view.png" width="400"></p>
            <p>We need <strong>state estimation</strong>
            (<strong>kalman</strong> filter, <strong>ekf</strong>).</p>
            </section>
            </section>
            <section id="overviewarchitecture-of-autonomous-systems"
            class="level2" data-number="1.6">
            <h2 data-number="1.6"><span
            class="header-section-number">1.6</span>
            Overview/Architecture of Autonomous Systems</h2>
            <p>So far, we’ve (briefly) talked about…</p>
            <p>Sensing:</p>
            <p><img src="img/stack_architecture/stack_overview.2.png" width="200"></p>
            <p>Actuation:</p>
            <p><img src="img/stack_architecture/stack_overview.3.png" width="200"></p>
            <p>But the system includes…an <strong>operating
            system</strong> (OS) in there</p>
            <p><img src="img/stack_architecture/stack_overview.4.png" width="300"></p>
            <p>and it includes <strong>real-time</strong>
            mechanisms.</p>
            <p>We have briefly discussed, <strong>EKF</strong>:</p>
            <p><img src="img/stack_architecture/stack_overview.5.png" width="300"></p>
            <p><strong>note</strong>: ekf is versatile; can be used for
            sensor fusion, slam, etc.</p>
            <p>All of it integrates with…<strong>control</strong>:</p>
            <p><img src="img/stack_architecture/stack_overview.6.png" width="300"></p>
            <p>There are some <strong>real-time</strong> functions in
            there…</p>
            <p><img src="img/stack_architecture/stack_overview.7.png" width="300"></p>
            <p>like <em>braking</em>, <em>engine control</em>.</p>
            <p>Question: if we design such a system…</p>
            <p><img src="img/stack_architecture/stack_overview.7.png" width="300"></p>
            <p>is it “<strong>autonomous</strong>”?</p>
            <p>We are missing some “higher order” functionss from the
            perspective of the autonomous system:</p>
            <ul>
            <li><em>where</em> am I?</li>
            <li><em>where</em> do I need to go?</li>
            <li><em>how</em> do I get there?</li>
            <li><em>what</em> obstacles may I face?</li>
            <li><em>how</em> do I avoid them?</li>
            </ul>
            <p>let’s not forget the most important question of all…</p>
            <p><img src="img/drax_gamora.avif" width="400"></p>
            <p><strong>why</strong> is gamora?</p>
            <section id="high-order-functions" class="level3"
            data-number="1.6.1">
            <h3 data-number="1.6.1"><span
            class="header-section-number">1.6.1</span> high-order
            functions</h3>
            <p>In order to answer the following, we need
            <strong>additional functionality</strong>. Let’s go through
            what that might be.</p>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <tbody>
            <tr>
            <td></td>
            <td><img src="img/stack_architecture/stack_overview.7.png" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="slam" class="level3" data-number="1.6.2">
            <h3 data-number="1.6.2"><span
            class="header-section-number">1.6.2</span> slam</h3>
            <p>Simultaneous localization and mapping → figure out
            <strong>where</strong> we are.</p>
            <p><img src="img/stack_architecture/stack_overview.8.png" width="300"></p>
            </section>
            <section id="waypoint-detection" class="level3"
            data-number="1.6.3">
            <h3 data-number="1.6.3"><span
            class="header-section-number">1.6.3</span> waypoint
            detection</h3>
            <p>Understand how to move in the <em>right</em> direction at
            the <strong>micro</strong> level, <em>i.e.,</em> find
            <strong>waypoints</strong>.</p>
            <p><img src="img/stack_architecture/stack_overview.9.png" width="300"></p>
            </section>
            <section id="yolo" class="level3" data-number="1.6.4">
            <h3 data-number="1.6.4"><span
            class="header-section-number">1.6.4</span> yolo</h3>
            <p>Is it “you only live once”? Actually this stands for:
            “you only <strong>look</strong> once”. It is an object
            <strong>detection</strong> model that uses convolutional
            neural networks (cnns)</p>
            <p><img src="img/stack_architecture/stack_overview.10.png" width="300"></p>
            </section>
            <section id="object-avoidance" class="level3"
            data-number="1.6.5">
            <h3 data-number="1.6.5"><span
            class="header-section-number">1.6.5</span> object
            avoidance</h3>
            <p>The objective is to avoid objects in the
            <strong>immediate path</strong>.</p>
            <p><img src="img/stack_architecture/stack_overview.11.png" width="300"></p>
            </section>
            <section id="path-planning" class="level3"
            data-number="1.6.6">
            <h3 data-number="1.6.6"><span
            class="header-section-number">1.6.6</span> path
            planning</h3>
            <p>i.e., how to get to <strong>destination</strong> at the
            <strong>macro</strong> level → uses waypoints.</p>
            <p><img src="img/stack_architecture/stack_overview.12.png" width="300"></p>
            </section>
            <section id="compute-platform" class="level3"
            data-number="1.6.7">
            <h3 data-number="1.6.7"><span
            class="header-section-number">1.6.7</span> compute
            platform</h3>
            <p>To run all of these functions, we need low power,
            embedded platforms.</p>
            <p><img src="img/stack_architecture/stack_overview.13.png" width="300"></p>
            </section>
            <section id="still-some-non-functional-requirements-remain"
            class="level3" data-number="1.6.8">
            <h3 data-number="1.6.8"><span
            class="header-section-number">1.6.8</span> still some
            <strong>non-functional</strong> requirements remain</h3>
            <p>any guesses what they could be?</p>
            </section>
            <section id="safety" class="level3" data-number="1.6.9">
            <h3 data-number="1.6.9"><span
            class="header-section-number">1.6.9</span> safety!</h3>
            <p>Essentially safety of → operator, other people, the
            vehicle, environment This is <strong>cross-cutting</strong>
            issue → affected <scb>by</scb> <strong>all</strong> parts of
            system.</p>
            <p><img src="img/stack_architecture/stack_overview.14.png" width="300"></p>
            </section>
            <section id="security" class="level3" data-number="1.6.10">
            <h3 data-number="1.6.10"><span
            class="header-section-number">1.6.10</span> security</h3>
            <p>Security is another cross-cutting issue → <scb>can
            affect</scb> <strong>all</strong> components.</p>
            <p><img src="img/stack_architecture/stack_overview.png" width="300"></p>
            </section>
            <section id="course-structure" class="level3"
            data-number="1.6.11">
            <h3 data-number="1.6.11"><span
            class="header-section-number">1.6.11</span> Course
            Structure</h3>
            <p>Hence this figure is a (loose) map of this course:</p>
            <p><img src="img/stack_architecture/stack_overview.png" width="300"></p>
            <!--link rel="stylesheet" href="./custom.sibin.css"-->
            </section>
            </section>
            </section>
            <section id="embedded-architectures" class="level1"
            data-number="2">
            <h1 data-number="2"><span
            class="header-section-number">2</span> Embedded
            Architectures</h1>
            <p>Just like “autonomy” describing and “embedded system” is
            hard. What (typically) distinguishes it from other types of
            computer systems (e.g., laptops, servers or GPUs even) is
            that such systems are typically created for
            <em>specific</em> functionality and often remain fixed and
            operational for years, decades even.</p>
            <p>Embedded systems often trade off between performance and
            other considerations such as power (or battery life), less
            memory, fewer peripherals, limited applications, smaller
            operating system (OS) and so on. There are numerous reasons
            for this – chief among them is <em>predictability</em> –
            designers need to guarantee that the system works correctly,
            and remains safe, all the time. Hence, it must be easy to
            <em>certify</em> <a href="#fn1" class="footnote-ref"
            id="fnref1" role="doc-noteref"><sup>1</sup></a> the
            <em>entire</em> system. This process ensures that the system
            operates <strong>safely</strong>.</p>
            <section id="the-wcet-problem" class="level2"
            data-number="2.1">
            <h2 data-number="2.1"><span
            class="header-section-number">2.1</span> The
            <strong>wcet</strong> problem</h2>
            <p>One piece of information that is required to ensure
            predictability and guarentee safety is <strong><a
            href="https://www.cs.fsu.edu/~whalley/papers/tecs07.pdf">worst-case
            execution time</a></strong> (WCET). The WCET/BCET is the
            <strong>longest</strong>/shortest execution time possible
            for a program, <strong>on a specific hardware
            platform</strong> – and it has to consider <em>all possible
            inputs</em>. WCET is necessary to ensure the
            “schedulability”, resource requirements and performance
            limits of embedded and real-time programs. There are lots of
            approaches to computing the WCET, <em>e.g.,</em></p>
            <ul>
            <li><a
            href="https://www.cs.fsu.edu/~whalley/papers/tecs07.pdf">dynamic/empirical</a>
            analysis → run the program lots of times (thousands,
            millions?) on the platform and measure it</li>
            <li><a
            href="https://www.cs.fsu.edu/~whalley/papers/tecs07.pdf">static</a>
            analysis → analyze the program at <em>compile time</em> to
            compute the <em>worst-case paths</em> through the
            program</li>
            <li><a
            href="https://sibin.github.io/papers/2008_NCSU-Dissertation_CheckerMode_SibinMohan.pdf">hybrid</a>
            → a combination of the two</li>
            <li><a
            href="https://people.ac.upc.edu/fcazorla/articles/jabella_ecrts2014_2.pdf">probabilistic</a>
            → a combination of dynamic analysis+statistical methods</li>
            <li><a
            href="https://dl.acm.org/doi/10.1145/3570361.3615740">ML-based
            methods</a> → applying machine-learning to the problem</li>
            </ul>
            <p>At a high-level, the execution time distributions of
            applications look like:</p>
            <p><img src="./img/embedded_arch/wcet_wilhelm.png" width="400" style="display: inline-block;" title="https://www.inf.ed.ac.uk/teaching/courses/es/PDFs/lecture_11.pdf" /></p>
            <p>WCET analysis is a very active area of research and
            hundreds of papers have been written about it, since it
            directly affects the safety of many critical systems
            (aircraft, power systems, nuclear reactors, space vehicles
            and…autonomous systems).</p>
            <p>There are structural challenges (both in software and
            hardware) that prevent the computation of <em>proper</em>
            wcet for anything but trivial examples. For instance,
            consider,</p>
            <div class="sourceCode" id="cb1"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> main<span class="op">()</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> max <span class="op">=</span> <span class="dv">10</span> <span class="op">;</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> max <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        sum <span class="op">+=</span> i <span class="op">;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>How do you compute the WCET for this code? Say running on
            some known processor, P?</p>
            <p>Well, there’s some information we need,</p>
            <ul>
            <li>how long each instruction takes to execute on P</li>
            <li>how many loop iterations?</li>
            <li>what is the startup/cleanup times for the program on
            P?</li>
            </ul>
            <p>Let’s assume (from the manual for P), we get the
            following information,</p>
            <div class="sourceCode" id="cb2"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>   <span class="dt">void</span> main<span class="op">()</span>         <span class="co">// startup cost = 100 cycles</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>   <span class="op">{</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>       <span class="dt">int</span> max <span class="op">=</span> <span class="dv">15</span> <span class="op">;</span>  <span class="co">// 10 cycles</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>       <span class="dt">int</span> sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span>    <span class="co">// 10 cycles </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>       <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> max <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span> <span class="co">// 5 cycles, once</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>            sum <span class="op">+=</span> i <span class="op">;</span> <span class="co">// 20 cycles each iteration</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>   <span class="op">}</span>                   <span class="co">// cleanup cost = 120 cycles</span></span></code></pre></div>
            <p>So, based on this, we can calculate the total time to
            execute this program:</p>
            <p><span
            class="math display"><em>w</em><em>c</em><em>e</em><em>t</em> = <em>s</em><em>t</em><em>a</em><em>r</em><em>t</em><em>u</em><em>p</em>_<em>c</em><em>o</em><em>s</em><em>t</em> + <em>l</em><em>i</em><em>n</em><em>e</em>_3 + <em>l</em><em>i</em><em>n</em><em>e</em>_4 + <em>l</em><em>o</em><em>o</em><em>p</em>_<em>s</em><em>t</em><em>a</em><em>r</em><em>t</em><em>u</em><em>p</em>_<em>c</em><em>o</em><em>s</em><em>t</em> + (<em>l</em><em>i</em><em>n</em><em>e</em>_6 * <em>m</em><em>a</em><em>x</em>)  [1]</span></p>
            <p><span
            class="math display"><em>w</em><em>c</em><em>e</em><em>t</em> = 100 + 10 + 10 + 5 + (20 * 15)</span></p>
            <p><span
            class="math display"><em>w</em><em>c</em><em>e</em><em>t</em> = 425 <em>c</em><em>y</em><em>c</em><em>l</em><em>e</em><em>s</em></span></p>
            <p>Now consider this slight change to the above code:</p>
            <div class="sourceCode" id="cb3"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> main<span class="op">(</span> <span class="dt">int</span> argc<span class="op">,</span> <span class="dt">char</span><span class="op">*</span> argv<span class="op">[]</span> <span class="op">)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> max <span class="op">=</span> atoi<span class="op">(</span> argv<span class="op">[</span><span class="dv">1</span><span class="op">]</span> <span class="op">)</span> <span class="op">;</span>     <span class="co">// convert the command line arg to max</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> max <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span> <span class="co">// how many iterations?</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        sum <span class="op">+=</span> i <span class="op">;</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>The problem is that equation [1] above fails since we no
            longer know the value of <code>max</code>. Hence the
            <em>program can run for any arbitrary amount of time,
            depending on the given input!</em> Note that
            <strong>none</strong> of the aforemention wcet methods will
            help in this case since the input can be completely
            arbitrary. Hence, the structure of the software code can
            affect wcet calculations.</p>
            <p>Another problem is that of <strong>hardware</strong> (and
            interactions between hardware and software). Now consider if
            we modify the original code as,</p>
            <div class="sourceCode" id="cb4"><pre
            class="sourceCode c"><code class="sourceCode c"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#define VERY_LARGE_ARRAY</span><span class="op">+</span><span class="pp">SIZE </span><span class="dv">1</span><span class="op">&gt;&gt;</span><span class="dv">18</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> main<span class="op">()</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> first_array<span class="op">[</span>VERY_LARGE_ARRAY_SIZE<span class="op">]</span> <span class="op">;</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> second_array<span class="op">[</span>VERY_LARGE_ARRAY_SIZE<span class="op">]</span> <span class="op">;</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum_first <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> sum_second <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span><span class="op">(</span> <span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span> <span class="op">;</span> i <span class="op">&lt;</span> VERY_LARGE_ARRAY_SIZE <span class="op">*</span> <span class="dv">2</span> <span class="op">;</span> <span class="op">++</span>i<span class="op">)</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span><span class="op">(</span> i<span class="op">%</span><span class="dv">2</span> <span class="op">)</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>            first_sum <span class="op">+=</span> first_array<span class="op">[</span>i<span class="op">/</span><span class="dv">2</span><span class="op">]</span> <span class="op">;</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            second_sum <span class="op">+=</span> second_array<span class="op">[(</span><span class="dt">int</span><span class="op">)((</span>i<span class="op">/</span><span class="dv">2</span><span class="op">)+</span><span class="dv">1</span><span class="op">)]</span> <span class="op">;</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
            <p>Now, while we can compute, using equation [1] the wcet
            from the code perspective (since we know the loop runs for
            <code>VERY_LARGE_ARRAY_SIZE * 2</code> iterations), there
            will be significant non-obvious hardware issues, in the
            <strong>cache</strong>. Each iteration is accessing a
            <em>different</em> large array. Hence, it will load the
            cache with lines from that array and in the <em>very next
            iteration</em> the other array will be loaded, also missing
            in the cache. For instance,</p>
            <table>
            <colgroup>
            <col style="width: 14%" />
            <col style="width: 25%" />
            <col style="width: 17%" />
            <col style="width: 41%" />
            </colgroup>
            <thead>
            <tr>
            <th>iteration</th>
            <th>operation</th>
            <th>cache state</th>
            <th>reason</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>1</td>
            <td><code>first_array</code> loaded</td>
            <td>miss</td>
            <td>evicts whatever was previously in cache</td>
            </tr>
            <tr>
            <td>2</td>
            <td><code>second_array</code> loaded</td>
            <td>miss</td>
            <td><strong>evicts <code>first_array</code></strong> due to
            lack of space</td>
            </tr>
            <tr>
            <td>3</td>
            <td><code>first_array</code> loaded again</td>
            <td>miss</td>
            <td><strong>evicts <code>second_array</code></strong> due to
            lack of space</td>
            </tr>
            <tr>
            <td>…</td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, this program will <em>constantly</em> sufffer
            cache misses and since caches misses (and reloads) are
            expensive (in terms of time), the loop’s execution time will
            balloon out of control! Hence, even though we fixed the code
            issue (upper bound on number of iterations, hardware
            artifacts can change the wcet calculations). So now, we need
            to <em>model cache behavior</em> for each program and data
            variable! This is <a
            href="https://user.it.uu.se/~wangyi/pdf-files/2015/lgyrw-acm15.pdf">notoriously
            complicated</a> even for the simplest of programs.</p>
            <p>Other hardware designs further complicate matters,
            e.g.,</p>
            <ul>
            <li>processor pipelining</li>
            <li>prefetching</li>
            <li>branch prediction</li>
            <li>multithreading</li>
            <li>multicore systems</li>
            <li>memory buses</li>
            <li>networks-on-chip</li>
            <li>and too many others to recount here…</li>
            </ul>
            <p>Any contemporary processor design that improves
            performance, <em>turns out to be bad for wcet analysis</em>.
            So, the fewer (or simpler versions of) these features, the
            better it is for the (eventual) safety and certification of
            the system.</p>
            <p>This is one of the main reasons why embedded (and
            especially real-time) systems <strong>prefer simpler
            processors</strong> (simple pipelines, fewer complex
            features, simpler memory/cache architectures, if any) since
            they’re easier to analyze. In fact, many critical systems
            (e.g., aircraft, cars, etc.) <strong>use older
            processors</strong> (often designed in the 1980s and 1990s)
            – even the ones beind design today!</p>
            </section>
            <section id="embedded-processors" class="level2"
            data-number="2.2">
            <h2 data-number="2.2"><span
            class="header-section-number">2.2</span> Embedded
            Processors</h2>
            <p>Just as embedded systems are varied, embedded processors
            come in a myriad of shapes and sizes as well. From the very
            small and simple (e.g., DSPs) to the very large and complex
            (modern multicore chips, some with GPUs!). Here is a
            (non-exhaustive) list of the types of embedded
            processors/architectures in use today:</p>
            <ol type="1">
            <li><a href="#microcontrollers">Microcontrollers</a></li>
            <li><a href="#digital-signal-processors-dsps">Digital Signal
            Processors</a> (DSPs)</li>
            <li><a href="#microprocessors">Microprocessors</a> of
            various designs and architectures (e.g., ARM, x86)</li>
            <li><a href="#system-on-a-chip-soc">System-on-a-Chip</a>
            (SoC)</li>
            <li><a
            href="#embedded-accelarators-eg-gpu-enabled-systems">Embedded
            accelerators</a></li>
            <li><a href="#asics-and-fpgas">ASICs and FPGAs</a></li>
            </ol>
            <section id="microcontrollers" class="level3"
            data-number="2.2.1">
            <h3 data-number="2.2.1"><span
            class="header-section-number">2.2.1</span>
            Microcontrollers</h3>
            <p>According to <a
            href="https://en.wikipedia.org/wiki/Microcontroller">Wikipedia</a>,</p>
            <blockquote>
            <p>“A microcontroller (MC, UC, or μC) or microcontroller
            unit (MCU) is a small computer on a single integrated
            circuit.”</p>
            </blockquote>
            <p>These may be among the most common type of “processors”
            used in embedded systems. According to many studies,
            <strong><a
            href="https://www.embedded.com/the-two-percent-solution/">more
            than 55%</a></strong> of the world’s processors are
            microntrollers! Microcontrollers are typically used in
            small, yet critical, systems such as car engine control,
            implantable medical devices, thermal monitoring, <a
            href="https://sibin.github.io/papers/2021_BuildSys_PIRMedic_AshishKashinath.pdf">fault
            detection and classification</a> among millions of other
            applications.</p>
            <p>Microcontrollers hardware features typically include,</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 45%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>one (sometimes more) CPU cores</td>
            <td>typically simple <code>4</code> or <code>8</code> bit
            chips</td>
            </tr>
            <tr>
            <td>small pipelined architectues</td>
            <td>sometimes <code>2</code> or <code>4</code> stage
            pipelines</td>
            </tr>
            <tr>
            <td>some limited memory</td>
            <td>typically a few hundred kilobytes, perhaps in the form
            of EEPROMs or FLASH</td>
            </tr>
            <tr>
            <td>some programmable I/O</td>
            <td>to interact with the real world</td>
            </tr>
            <tr>
            <td>low operating frequencies</td>
            <td>e.g., <code>4 KHz</code>; simpler/older processors, yet
            more predictable</td>
            </tr>
            <tr>
            <td>low power consumption</td>
            <td>in the <strong>milliwatts</strong> or
            <strong>microwatts</strong> ranges; might even be
            <strong>nanowatts</strong> when the system is
            <em>sleeping</em></td>
            </tr>
            <tr>
            <td>interrupts (some programmable)</td>
            <td>often <em>real-time</em> (ficed/low latency)</td>
            </tr>
            <tr>
            <td>several general-purpose I/O (GPIO) pins</td>
            <td>for I/O</td>
            </tr>
            <tr>
            <td>timers</td>
            <td>e.g., a programmable interval timer (PIT)</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>There are some <strong>additional features</strong> found
            on some microcontrollers, viz.,</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 45%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>analog to digital (ADC) signal convertors</td>
            <td>to convert incoming (real-world, sensor) data to a
            digital form that the uC can operate on</td>
            </tr>
            <tr>
            <td>digital-to-analog (DAC) convertor</td>
            <td>to do the opposite, convert from digital to analog
            signals to send outputs in that form</td>
            </tr>
            <tr>
            <td>universal asynchronous transmitter/receiver (UART)</td>
            <td>to receive/send data over a <em>serial</em> line</td>
            </tr>
            <tr>
            <td>pulse width modulation (PWM)</td>
            <td>so that the CPU can control <strong>motors</strong>
            (significant for us in autonomous/automotive systems), power
            systems, resistive loads, etc.</td>
            </tr>
            <tr>
            <td>JTAG interace</td>
            <td>debugging interface</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Some examples of popular microcontroller families:</p>
            <table>
            <colgroup>
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            <col style="width: 25%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="./img/embedded_arch/ATmega169-MLF.jpg" height="100"><br>Atmel
            ATmega</td>
            <td><img src="./img/embedded_arch/Microchip_PIC24HJ32GP202.jpg" height="100">
            <br> Microchip Technology</td>
            <td><img src="./img/embedded_arch/Motorola_68HC11.jpg" height="100">
            <br> Motorola (Freescale)</td>
            <td><img src="./img/embedded_arch/NXP_LPC2387FBD100-5543.jpg" height="100">
            <br> NXP</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Microcontroller programs and data,</p>
            <ul>
            <li>are small –&gt; must fit in memory (since very little
            expandable memory exists)</li>
            <li>often directly programmed in <strong>assembly</strong>!
            <ul>
            <li>sometimes the assembly code might need <em>hand
            tuning</em> –&gt; for both, performance as well as fitting
            into the limited memory</li>
            </ul></li>
            <li><strong>C</strong> is another popular language</li>
            <li><strong>no operating systems</strong> (or very
            rare)!</li>
            <li>sometimes have their own special-purpose programming
            languages or instructions</li>
            </ul>
            </section>
            <section id="digital-signal-processors-dsps" class="level3"
            data-number="2.2.2">
            <h3 data-number="2.2.2"><span
            class="header-section-number">2.2.2</span> Digital Signal
            Processors (DSPs)</h3>
            <p>DSPs are specialized microcontrollers optimized for
            <em>digital signal processing</em>. They find wide use in
            audio processing, radar and sonar, speech recognition
            systems, image processing, satellites, telecommunications,
            mobile phones, televisions, etc. Their main goals are to
            isoloate, measure, compress and filter <em>analog</em>
            signals in the real world. They often have <strong>stringent
            real-time constraints</strong>.</p>
            <p>The Texas Instruments DSP chip, <a
            href="https://www.ti.com/lit/ug/spruh79c/spruh79c.pdf?ts=1736945981001">TMS320
            Series</a> is one of the most famous example of this type of
            system:</p>
            <p><img src="./img/embedded_arch/TI_DSP.jpg" height="100" title="Texas Instruments DSP Chip"></p>
            <p>Typical digital signal processing (of any kind) requires
            repetitive mathematical operations over a large number of
            samples, in real-time, viz., - analog to digital conversion
            - maniupulation (the core algorithm) - digital to analog
            conversion</p>
            <p>Often, the <em>entire</em> process must be completed with
            low latency, even within a fixed deadline. They also have
            <strong>low power</strong> requirements since DSPs are often
            used in battery-constrained devices such as mobile phones.
            Hence, the proliferation of specialized DSP chips (instead
            of pure <a href="https://liquidsdr.org">software
            implementations</a>, which also exist; MATLAB has an entire
            <a href="https://www.mathworks.com/help/dsp/index.html">DSP
            System Toolbox</a>).</p>
            <p><strong>Typical DSP architecture</strong>/flow (credit:
            <a
            href="https://en.wikipedia.org/wiki/Digital_signal_processor">Wikipedia</a>):</p>
            <p><img src="./img/embedded_arch/dsp_architecture.png" height="100" title="https://en.wikipedia.org/wiki/Digital_signal_processor"></p>
            <p>These types of chips typically have custom instructions
            for optimizing certain (mathematical) operations (apart from
            the typical <code>add</code>, <code>subtract</code>,
            <code>multiply</code> and <code>divide</code>), e.g., -
            <code>saturate</code>; caps the minimum or maximum value
            that can be held in a fixed-point representation -
            <code>ed</code> ; euclidian distance -
            <code>accumulate</code> instructions ; for <a
            href="https://skills.microchip.com/dsp-features-of-the-microchip-dspic-dsc/693207"><em>multiply-and-accumulate</em></a>
            operations, i.e., <span
            class="math inline"><em>a</em> ← <em>a</em> + (<em>b</em> * <em>c</em>)</span></p>
            <blockquote>
            <p>See the <a
            href="https://ww1.microchip.com/downloads/en/DeviceDoc/sect2.pdf">Microchip
            instruction set</a> details for more information for a
            typical DSP ISA.</p>
            </blockquote>
            <p>DSPs require <em>optimization of streaming data</em> and
            hence, - require <strong>optimized memories and
            caches</strong> → fetch multiple data elements at the same
            time - code may need to be aware of, and
            <strong>explicitly</strong> manipulate caches - may have
            rudimentary OS but <strong>no virtual memory</strong></p>
            </section>
            <section id="microprocessors" class="level3"
            data-number="2.2.3">
            <h3 data-number="2.2.3"><span
            class="header-section-number">2.2.3</span>
            Microprocessors</h3>
            <p>Microprocessors are, then,
            <strong>general-purpose</strong> chips (as opposed to
            microcontrollers and DSPs) that are also used extensively in
            embedded systems. They are used in systems that need more
            heavy duty computing/memory and/or more flexibility in terms
            of programming and management of the system. They use a
            number of commodity processor architectures (e.g,, ARM,
            Intel x86).</p>
            <p>Main features of microprocessors:</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 45%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>cores</td>
            <td>single or multicore; powerful</td>
            </tr>
            <tr>
            <td>pipelines</td>
            <td>more complex pipelines; better performance, harder to
            analyze (e.g., wcet)</td>
            </tr>
            <tr>
            <td>clock speeds</td>
            <td>higher clock speeds; <code>100s</code> of khz, or even
            GHz</td>
            </tr>
            <tr>
            <td>ISA</td>
            <td>common ISA; well understood, not custom</td>
            </tr>
            <tr>
            <td>memory</td>
            <td>significant memory; megabytes, even gigabytes</td>
            </tr>
            <tr>
            <td>cache hierarchies</td>
            <td>multiple levels, optimized</td>
            </tr>
            <tr>
            <td>power consumption</td>
            <td>much higher, but can be reduced (e.g., via <a
            href="https://developer.arm.com/documentation/ddi0375/a/functional-overview/intelligent-energy-management--iem-/dynamic-voltage-scaling--dvs-">voltage
            and frequency scaling</a>)</td>
            </tr>
            <tr>
            <td>size, cost</td>
            <td>often higher</td>
            </tr>
            <tr>
            <td>interrupts, timers</td>
            <td>more varied, easily programmable</td>
            </tr>
            <tr>
            <td>I/O</td>
            <td>more interfaces, including commodity ones like USB</td>
            </tr>
            <tr>
            <td>security</td>
            <td>often includes additional hardware security features,
            e.g., <a
            href="https://sefcom.asu.edu/publications/trustzone-explained-cic2016.pdf">ARM
            TrustZone</a>.</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The <a
            href="https://armkeil.blob.core.windows.net/developer/Files/pdf/product-brief/arm-cortex-m85-product-brief.pdf">ARM
            M-85</a> Embedded Microprocessor architecture:</p>
            <p><img src="./img/embedded_arch/arm_cortex_m85.png" width="300" title="Arm M-85"></p>
            <p>When compared to microcontrollers (or even SoCs), most
            microprpcessors <strong>do not</strong> include components
            such as DSPs, ADCs, DACs, etc. It is possible to
            <em>augment</em> the microprocessor to include this
            functionality → usually by <em>connecting one or more
            microcontrollers to it</em>!</p>
            <p>On the software side, microprocessors typically have the
            <strong>most flexibility</strong>:</p>
            <ul>
            <li>general purpose operating systems (e.g., Linux, Android,
            Windows, UNIX, etc.)</li>
            <li>most programming languages and infrastructures (even <a
            href="https://www.docker.com/blog/getting-started-with-docker-for-arm-on-linux/">Docker</a>!)</li>
            <li>large number of tooling, analysis, debugging
            capabilities</li>
            <li>complex code can run, but <strong>increases analysis
            difficulty</strong></li>
            </ul>
            <p>Due to their power (and cost) these types of systems are
            only used when really necessary or in higher-end systems
            such as mobile phones and autonomous cars.</p>
            </section>
            <section id="system-on-a-chip-soc" class="level3"
            data-number="2.2.4">
            <h3 data-number="2.2.4"><span
            class="header-section-number">2.2.4</span> System-on-a-Chip
            (SoC)</h3>
            <p>An SoC <strong>integrates</strong> most components in and
            around a processor into a <strong>single</strong> circuit,
            viz.,</p>
            <ul>
            <li>processor/chip → could be a microcontroller or even a
            microprocessor</li>
            <li>memory and memory interfaces</li>
            <li>I/O devices</li>
            <li>buses (memory and I/O)</li>
            <li>storage (e.g., flash) and sometimes even secondary
            storage</li>
            <li>radio modems</li>
            <li>(sometimes) accelerators such as GPUs</li>
            </ul>
            <p>All of these are placed on a <strong>single
            substrate</strong>.</p>
            <p>SoCs are often designed in <code>C++</code>,
            <code>MATLAB</code>, <code>SystemC</code>, etc. Once the
            hardware architectures are defined, additional hardware
            elements are written in hardware description languages,
            e.g., register transfer levels (<code>RTL</code>) <a
            href="#fn2" class="footnote-ref" id="fnref2"
            role="doc-noteref"><sup>2</sup></a>.</p>
            <p>Additional components could include,</p>
            <ul>
            <li>DAC</li>
            <li>ADC</li>
            <li>radio and signal processing</li>
            <li>wireless modems</li>
            <li><a
            href="https://www.amd.com/en/products/adaptive-socs-and-fpgas/soc/zynq-7000.html"><em>programmable
            logic</em></a>.</li>
            <li>networks on chip (NoC) <a href="#fn3"
            class="footnote-ref" id="fnref3"
            role="doc-noteref"><sup>3</sup></a></li>
            </ul>
            <p>In some sense, an SoC is an <em>integration of a
            processor with peripherals</em>. New hardware elements</p>
            <p>Some examples of modern SoCs:</p>
            <div class="multicolumn">
            <div>
            <p><img src="./img/embedded_arch/broadcom_pi_chip.png" width="200" title="Broadcom SoC chip used in the Raspberry Pi"></p>
            <p>Broadcom Soc from Raspberry Pi</p>
            </div>
            <div>
            <p><img src="./img/embedded_arch/Apple_M1.jpg" width="200" title="Apple M1 SoC"></p>
            <p>Apple M1 SoC</p>
            </div>
            </div>
            <p>The integration of all hardware components has some
            interesting side-effects:</p>
            <table>
            <colgroup>
            <col style="width: 34%" />
            <col style="width: 31%" />
            <col style="width: 34%" />
            </colgroup>
            <thead>
            <tr>
            <th>effect</th>
            <th>benefit</th>
            <th>problems</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>tight integration</td>
            <td>better performance, fewer latencies</td>
            <td>cannot replace individual components</td>
            </tr>
            <tr>
            <td>custom code/firmware</td>
            <td>better use of hardware</td>
            <td>not reusable in other systems</td>
            </tr>
            <tr>
            <td>custom software libraries</td>
            <td>easier programming of SoC</td>
            <td>reduces code reusability in other systems</td>
            </tr>
            <tr>
            <td>low power consumption</td>
            <td>better battery life, less heat</td>
            <td>(potentially) slower</td>
            </tr>
            </tbody>
            </table>
            <p>Depending on the processor/microcontroller that sits at
            the center of the SoC, the software stack/capabilities can
            vary. Many commons SoCs exhibit the following software
            properties:</p>
            <ul>
            <li>usually use contemporary operating systems, though
            optimized for embedded/SoC systems → e.g., <a
            href="http://www.raspbian.org">Raspbian</a> aka Rasberry Pi
            OS. Hence, they can handle multiprocessing, virtual memory,
            different scheduling policies, etc.</li>
            <li>can be programmed using most common programming
            languages → <code>C</code>, <code>C++</code>,
            <code>python</code>, <code>java</code>, even <a
            href="https://medium.com/@kenichisasagawa/rediscovering-the-joy-of-hardware-hacking-with-raspberry-pi-and-lisp-574c833ab20e"><code>lisp</code></a>!</li>
            </ul>
            <p>The Raspberry Pi is a common example of a system that
            uses a <a
            href="https://www.raspberrypi.com/documentation/computers/processors.html">Broadcom
            BCM series of SoCs</a>. We use the <a
            href="https://www.raspberrypi.com/documentation/computers/processors.html#bcm2711">BCM2711</a>
            SoC in our course for the Raspberry Pi 4-B.</p>
            </section>
            <section id="embedded-accelarators-e.g.-gpu-enabled-systems"
            class="level3" data-number="2.2.5">
            <h3 data-number="2.2.5"><span
            class="header-section-number">2.2.5</span> Embedded
            Accelarators (e.g. GPU-enabled systems)</h3>
            <p>There are hardware platforms that include
            <strong>accelerators</strong> in embedded systems, e.g., <a
            href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">GPUs</a>,
            <a
            href="https://www.nature.com/articles/s41928-022-00778-y">AI-enabled
            silicon</a>, <a
            href="https://www.amd.com/en/products/adaptive-socs-and-fpgas/soc/zynq-7000.html">extra
            programmable FPGA fabric</a>, <a
            href="https://developer.arm.com/documentation/100230/0002/functional-description/external-coprocessors/configuring-which-coprocessors-are-included-in-secure-and-non-secure-states">security
            features</a>, etc. The main idea is that certain computation
            can be <em>offloaded</em> to these accelerators while the
            main CPU continues to process other code/requests. The
            accelerators are specialized for certain computations (e.g.,
            parallel matrix multiplications on GPUs, AES encryption).
            Some chips include FPGA fabric where the designer/user can
            <em>implement their own custom logic/accelerators</em>.</p>
            <p>In a loose sense, the <a
            href="https://navio2.hipi.io">Navio2</a> can be considered
            as a hardware coprocessor for the Raspbery Pi.</p>
            <p>The <a
            href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/">NVidia
            Jetson Orin</a> is a good example of an AI/GPU focussed
            embedded processor:</p>
            <p><img src="./img/embedded_arch/jetson-agx-orin-4c25-d-2x.png" width="300" title="NVIDIA Jetson AGX Orin 64 GB"></p>
            <p><br></p>
            <p>This system’s <a
            href="https://www.techpowerup.com/gpu-specs/jetson-agx-orin-64-gb.c4085">specifications</a>:</p>
            <ul>
            <li>1300 MHz clock speeds</li>
            <li>64 GB Memory</li>
            <li>256 bit memory bus</li>
            <li>204 GB/s bandwidth</li>
            <li>supports a variety of graphics features (DirectX,
            OpenGL, OpenCL, CUDA, Vulkan and Shader Models )</li>
            <li>maximum of 60W power</li>
            <li><strong>275 trillion</strong> operations/s (TOPS)!</li>
            </ul>
            <p>These systems are finding a lot of use in autonomous
            systems since they pack so much processing power into such a
            small form factor</p>
            </section>
            <section id="asics-and-fpgas" class="level3"
            data-number="2.2.6">
            <h3 data-number="2.2.6"><span
            class="header-section-number">2.2.6</span> ASICs and
            FPGAs</h3>
            <p>Application-specific integrated circuits (ASICs) and
            field programmable gate arrays (FPGAs). These platforms
            combine the advantages of both, hardware (<em>speed</em>)
            and software (<em>flexibility/programmability</em>). They
            are similar, yet different. Both are semiconductor devices
            that include <strong>programmable logic gates</strong> but
            an ASIC is <em>static</em> – i.e., once the board has been
            “programmed” it cannot be changed while an FPGA, as the name
            implies, allows for “reprogramming”.</p>
            <p>ASICs are <strong>custom-designed</strong> for specific
            applications and provide high efficiency and performance.
            FPGAs are <strong>reprogramamble</strong> devices that
            provide significant flexibility. Many designers also used it
            for prototyping hardware components (before they are
            eventually included either in the processors or custom
            ASICs). The <a
            href="https://www.wevolver.com/article/asic-vs-fpga">choice
            between ASICs and FPGAs</a> depends entirely on the
            application requirements and other factors such as cost.</p>
            <table>
            <colgroup>
            <col style="width: 50%" />
            <col style="width: 50%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="./img/embedded_arch/asic.webp" width="200"></td>
            <td><img src="./img/embedded_arch/xilinx_spartan_fpga.webp" width="200"></td>
            </tr>
            <tr>
            <td>An ASIC</td>
            <td>Xilinx Spartan FPGA</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <section id="asics" class="level4" data-number="2.2.6.1">
            <h4 data-number="2.2.6.1"><span
            class="header-section-number">2.2.6.1</span> ASICs</h4>
            <p>These are specialized semiconductor devices – to
            implement a <em>custom</em> function, e.g., cryptocurrency
            mining, nuclear reactor control, televisions. ASICs are
            tailored to their specific applications. Once created, it
            cannot be reprogrammed or modified. ASICs are created using
            a process known as <a
            href="https://www.sciencedirect.com/topics/physics-and-astronomy/photolithography">photolithography</a>,
            a method to prepare nanoparticles, that allows components to
            be “etched” on to a silicon wafer.</p>
            <p>The <a
            href="https://www.wevolver.com/article/the-ultimate-guide-to-asic-design-from-concept-to-production">ASIC
            design process</a>, while expensive and time consuming,
            becomes valuable for <em>high-volume</em> products as the
            per-unit cost decrease when production nunbers increase.</p>
            <table>
            <thead>
            <tr>
            <th>advantages</th>
            <th>disadvantages</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>high performance</td>
            <td>lack of flexibility</td>
            </tr>
            <tr>
            <td>low power consumption</td>
            <td>high initial costs</td>
            </tr>
            <tr>
            <td>small form factor</td>
            <td>long development time</td>
            </tr>
            <tr>
            <td>ip protection</td>
            <td>obsolescence risk</td>
            </tr>
            <tr>
            <td>good for mass production</td>
            <td>risks with manufacturing yields</td>
            </tr>
            <tr>
            <td>can integrate multiple functions</td>
            <td>design complexity</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            <section id="fpgas" class="level4" data-number="2.2.6.2">
            <h4 data-number="2.2.6.2"><span
            class="header-section-number">2.2.6.2</span> FPGAs</h4>
            <p>These are also semiconductor devices but they can be
            <strong>preprogrammed</strong> to implement various circuits
            and functions. Designers can change the functionality
            <strong>after</strong> the curcuits have been embossed onto
            the hardware. Hence, they’re good for systems that might
            require changes at design time and rapid prototyping. An
            FPGA is a collection of programmable logic and
            interconnects. They include lookup tables (LUTs) and other
            parts that can be used to develop multiple, fairly
            wide-ranging, functions. The programmable blocks can be
            connected to each other via the interconnects. Some FPGAs
            even come with additional flash memory.</p>
            <p><a href="https://www.wevolver.com/article/fpga">FPGAs are
            programmed</a> using hardware description languages such as
            Verilog/VHDL.</p>
            <table>
            <thead>
            <tr>
            <th>advantages</th>
            <th>disadvantages</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>flexibility</td>
            <td>lower performance</td>
            </tr>
            <tr>
            <td>shorter development time</td>
            <td>higher power consumption</td>
            </tr>
            <tr>
            <td>upgradability</td>
            <td>high design complexity</td>
            </tr>
            <tr>
            <td>lower (initial) costs</td>
            <td>higher per-unit costs</td>
            </tr>
            <tr>
            <td>better processing capabilities</td>
            <td>design complexity</td>
            </tr>
            <tr>
            <td>lower obsolescence risks</td>
            <td>larger form factor</td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            </section>
            <section id="communication-and-io" class="level2"
            data-number="2.3">
            <h2 data-number="2.3"><span
            class="header-section-number">2.3</span> Communication and
            I/O</h2>
            <p>Embedded systems need to <strong>communicate</strong>
            and/or <strong>interface</strong> with various elements:</p>
            <ul>
            <li>the physical world via sensors and actuators</li>
            <li>computers for programming (of the embedded system) or
            for data transfer</li>
            <li>with other embedded systems/nodes</li>
            <li>handheld devices</li>
            <li>with the internet (either public or to access back end
            servers)</li>
            <li>satellites?</li>
            </ul>
            <p>Hence a large number of communication standards and I/O
            interfaces have been developed over the years. Let’s look at
            a few of them:</p>
            <ol type="1">
            <li><a href="#uart--rs-232">serial (UART)</a> → e.g., RS
            232</li>
            <li><a href="#synchronous--i2c-and-spi">synchronous</a> →
            I2C, SPI</li>
            <li><a href="#general-purpose-io-gpio">general-purpose
            I/O</a> → GPIO</li>
            <li><a href="#jtag-debugging-interface">debugging
            interface</a> → JTAG</li>
            <li><a href="#controller-area-network-can">embedded internal
            communication</a> → CAN</li>
            <li><a href="#other-broadly-used-protocols">other broadly
            used protocols</a> → USB, Ethernet/WiFi, Radio,
            Bluetooth</li>
            </ol>
            <section id="uart-rs-232" class="level3"
            data-number="2.3.1">
            <h3 data-number="2.3.1"><span
            class="header-section-number">2.3.1</span> UART |
            RS-232</h3>
            <p>Serial communication standards are used extensively
            across many domains, mainly due to their
            <strong>simplicity</strong> and <strong>low hardware
            overheads</strong>. The most common among these are the
            <em>asynchronous serial communication systems</em>.</p>
            <p>From <a
            href="https://en.wikipedia.org/wiki/Asynchronous_serial_communication">Wikipedia</a>:</p>
            <blockquote>
            <p>Asynchronous serial communication is a form of serial
            communication in which the communicating endpoints’
            interfaces are not continuously synchronized by a common
            clock signal. Instead of a common synchronization signal,
            the data stream contains synchronization information in form
            of start and stop signals, before and after each unit of
            transmission, respectively. The start signal prepares the
            receiver for arrival of data and the stop signal resets its
            state to enable triggering of a new sequence.</p>
            </blockquote>
            <p>The following figure shows a communication sample that
            demonstrates these principles:</p>
            <p><img src="img/embedded_arch/comms/Puerto_serie_Rs232.png" width="300"></p>
            <p>We see that each byte has a <code>start</code> bit,
            <code>stop</code> bit and eight <code>data</code> bits. The
            last bit is often used as a <code>parity</code> bit. All of
            these “standards” (i.e., the start/stop/parity bits) must be
            <em>agreed upon ahead of time</em>.</p>
            <p>A <strong>universal asynchronous
            receiver-transmitter</strong> (<strong>UART</strong>) then
            is a peripheral device for such asynchronous commnication;
            the data format and transmission speeds are configurable. It
            sends data bits <em>one-by-one</em> (from least significant
            to most). The precise timing is handlded by the
            communication channel.</p>
            <p>The electric <em>signalling levels</em> are handled by an
            external driver circuit. Common signal levels:</p>
            <ul>
            <li><a
            href="https://www.analog.com/en/resources/technical-articles/fundamentals-of-rs232-serial-communications.html">RS
            232</a></li>
            <li><a
            href="https://www.renkeer.com/what-is-rs485/">RS-485</a></li>
            <li>raw <a
            href="https://www.seeedstudio.com/blog/2019/12/11/rs232-vs-ttl-beginner-guide-to-serial-communication">TTL</a></li>
            </ul>
            <p>Here we will focus on the <strong>RS-232</strong>
            standard since it is most widely used UART signaling level
            standard today. The full name of the standard is:
            “EIA/TIA-232-E Interface Between Data Terminal Equipment and
            Data Circuit-Termination Equipment Employing Serial Binary
            Data Interchange” (“EIA/TIA” stands for the Electronic
            Industry Association and the Telecommunications Industry
            Association). It was introduced in 1962 and has since been
            updated <em>four</em> times to meet evolving needs.</p>
            <p>The RS-232 is a <em>complete</em> standard in that it
            specifies,</p>
            <ul>
            <li>(common) voltage and signal levels</li>
            <li>(common) pin and wiring configurations</li>
            <li>(minimal) control information between
            host/peripherals</li>
            </ul>
            <p>The RS-232 specifies the electrical, functional and
            mechanical characteristics to meet all of the above
            criteria.</p>
            <p>For instance, the <em>electrical</em> characteristics are
            defined in the following figure:</p>
            <p><img src="img/embedded_arch/comms/rs232-electrical.gif" width="400"></p>
            <p>Details:</p>
            <ul>
            <li><strong>high</strong> level [<strong>logical
            <code>0</code></strong>] (aka “marking”) → <code>+5V</code>
            to <code>+15V</code> (realistically <code>+3V</code> to
            <code>+15V</code>)</li>
            <li><strong>low</strong> level [<strong>logical
            <code>1</code></strong>] (aka “spacing”) → <code>-5V</code>
            to <code>-15V</code> (realistically <code>-3V</code> to
            <code>-15V</code>)</li>
            </ul>
            <p>Other properties also defined, <em>e.g.</em>, “<a
            href="https://en.wikipedia.org/wiki/Slew_rate">slew
            rate</a>”, impedance, capacitive loads, etc.</p>
            <p>The standard also defines the mechanical interfaces,
            i.e., the <em>pin connector</em>:</p>
            <p><img src="img/embedded_arch/comms/rs232_pins.gif" width="400"></p>
            <p>While the official standard calls for a 25-pin connector,
            it is rarely used. Instead, the <strong>9-pin</strong>
            connector (shown on the right in the above figure) is in
            common use.</p>
            <p>You can read more details about the standard here: <a
            href="https://www.analog.com/en/resources/technical-articles/fundamentals-of-rs232-serial-communications.html">RS
            232</a></p>
            </section>
            <section id="synchronous-i2c-and-spi" class="level3"
            data-number="2.3.2">
            <h3 data-number="2.3.2"><span
            class="header-section-number">2.3.2</span> Synchronous |
            I<sup>2</sup>C and SPI</h3>
            <p>Synchronous Serial Interfaces (SSIs) are a widely used in
            industrial applications between a master device
            (e.g. controller) and a slave device (e.g. sensor). It is
            based on the <a
            href="https://www.analog.com/media/en/technical-documentation/tech-articles/guide-to-selecting-and-using-rs232-rs422-and-rs485-serial-data-standards--maxim-integrated.pdf">RS-422</a>
            standards and has a high protocol efficiency as well
            multiple hardware implementations.</p>
            <p>SSI properties:</p>
            <ul>
            <li><a
            href="https://en.wikipedia.org/wiki/Differential_signalling">differential
            signalling</a></li>
            <li>simplex (i.e., unidirectional communication only)</li>
            <li>non-multiplexed</li>
            <li>point-to-point and</li>
            <li>uses time-outs to frame the data.</li>
            </ul>
            <section id="i2c" class="level4" data-number="2.3.2.1">
            <h4 data-number="2.3.2.1"><span
            class="header-section-number">2.3.2.1</span>
            I<sup>2</sup>C</h4>
            <p>The <a
            href="https://www.ti.com/lit/an/sbaa565/sbaa565.pdf">Inter-Integrated
            Circuit</a> (I<sup>2</sup>C, IIC, I2C) is a synchronous,
            multi-controller/multi-target (historically termed as
            multi-master/multi-slave), single-ended, serial
            communication bus. I2C systems are used for <em>attaching
            low-power integrated circuits to processors and
            microcontrollers</em> – usually for short distance or
            <em>intra-board communication</em>.</p>
            <p>I2C components are found in a wide variety of products,
            <em>e.g.,</em></p>
            <ul>
            <li>EEPROMs</li>
            <li>VGA/DVI/HDMI connectors</li>
            <li>NVRAM chips</li>
            <li>real-time clocks</li>
            <li>reading hardware monitors and sensors</li>
            <li>controlling actuators</li>
            <li>DAC/ADC</li>
            <li>controlling LCD/OLEDs displays</li>
            <li>changing computer display settings (contrast,
            brightness, etc.)</li>
            <li>controlling speaker volume</li>
            <li>and many many more</li>
            </ul>
            <p>The main advantage of I2C is that a microcontroller can
            control a <em>network</em> of chips with just
            <strong>two</strong> general-purpose I/O pins (serial data
            line and a serial clock line) and software. A controller
            device can communicate with any target device through a
            unique I2C address sent through the serial data line. Hence
            the two signals are:</p>
            <table style="width:100%;">
            <colgroup>
            <col style="width: 30%" />
            <col style="width: 35%" />
            <col style="width: 35%" />
            </colgroup>
            <thead>
            <tr>
            <th>line</th>
            <th>voltage</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>serial data line (SDL)</td>
            <td><code>+5V</code></td>
            <td>transmit data to or from target devices</td>
            </tr>
            <tr>
            <td>serial clock line (SCL)</td>
            <td><code>+3V</code></td>
            <td>synchronously clock data in or out of the target
            device</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Both are bidirectional and pulled up with resistors.</p>
            <p>Here is a typical implementation of I2C:</p>
            <p><img src="img/embedded_arch/comms/i2c_implementation.png" width="400"></p>
            <p>An I2C chip example (used for controlling certain TV
            signals):</p>
            <p><img src="img/embedded_arch/comms/i2c_tv_control.jpg" width="100"></p>
            <p>I2C is half-duplex communication where only a single
            controller or a target device is sending data on the bus at
            a time. In comparison, the serial peripheral interface (SPI)
            is a full-duplex protocol where data can be sent to and
            received back at the same time. An I2C controller device
            starts and stops communication, which removes the potential
            problem of bus contention. Communication with a target
            device is sent through a unique address on the bus. This
            allows for both multiple controllers and multiple target
            devices on the I2C bus.</p>
            <p>I2C communication details (initiated from the controller
            device):</p>
            <table>
            <colgroup>
            <col style="width: 70%" />
            <col style="width: 29%" />
            </colgroup>
            <thead>
            <tr>
            <th>condition</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>I2C <code>START</code></td>
            <td>the controller device first pulls the SDA low and then
            pulls the SCL low</td>
            </tr>
            <tr>
            <td>I2C <code>STOP</code></td>
            <td>the SCL releases high and then SDA releases high</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><img src="img/embedded_arch/comms/i2c_start_stop.png" width="300"></p>
            <p><br></p>
            <p>I2C communication is split into: <strong>frames</strong>.
            Communciation starts when one controller sends an
            <code>address frame</code> after a <code>START</code>. This
            is followed by one or more <code>data frames</code>, each
            consisting of <strong>one byte</strong>. Each frame also has
            an <code>acknowledgement</code> bit. An example of two I2C
            communication frames:</p>
            <p><img src="img/embedded_arch/comms/i2c_frames.png"></p>
            <p><br></p>
            <p>You can read more at: <a
            href="https://www.ti.com/lit/an/sbaa565/sbaa565.pdf">I2C</a>.</p>
            </section>
            <section id="spi" class="level4" data-number="2.3.2.2">
            <h4 data-number="2.3.2.2"><span
            class="header-section-number">2.3.2.2</span> SPI</h4>
            <p>The <a
            href="https://www.analog.com/en/resources/analog-dialogue/articles/introduction-to-spi-interface.html">Serial
            Peripheral Interface</a> (SPI) has become the de facto
            standard for <em>synchronous</em> serial communication. It
            is used in embedded systems, especially between
            microcontrollers and peripheral ICs such as sensors, ADCs,
            DACs, shift registers, SRAM, <em>etc.</em></p>
            <p>The main aspect of SPI is that one main device
            <strong>orchestrates communication</strong> with one ore
            more sub/peripheral devices by <strong>driving the clock and
            chip select signals</strong>.</p>
            <p>SPI interface properties:</p>
            <ul>
            <li><em>synchronous</em></li>
            <li><em>full duplex</em></li>
            <li><em>main-subnode</em> (formerly called
            “master-slave”)</li>
            <li>data from the main or the subnode is synchronized on the
            rising or falling clock edge</li>
            <li>main and subnode can transmit data at the same time</li>
            <li>interface can be 3 or 4-wire (4 wire version is more
            popular)</li>
            </ul>
            <table>
            <colgroup>
            <col style="width: 46%" />
            <col style="width: 53%" />
            </colgroup>
            <thead>
            <tr>
            <th>microchip SPI</th>
            <th>basic SPI Interface</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/embedded_arch/comms/spi_microchip.avif" width="100"></td>
            <td><img src="img/embedded_arch/comms/spi_basic.png" width="500"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The SPI interface contains the following wires:</p>
            <table>
            <colgroup>
            <col style="width: 25%" />
            <col style="width: 41%" />
            <col style="width: 32%" />
            </colgroup>
            <thead>
            <tr>
            <th>signal</th>
            <th>description</th>
            <th>function</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><code>SCLK</code></td>
            <td>serial clock</td>
            <td>clock signal from main</td>
            </tr>
            <tr>
            <td><code>CS</code></td>
            <td>chip/serial select</td>
            <td>To select which host to communicate with</td>
            </tr>
            <tr>
            <td><code>MOSI</code></td>
            <td>main out, subnode In</td>
            <td>serial data out (SDO) for host to target
            communication</td>
            </tr>
            <tr>
            <td><code>MISO</code></td>
            <td>main in, subnode Out</td>
            <td>serial data in (SDI) for target to host
            communication</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The main node generates the clock signal. Data
            transmissions between main ahd sub nodes is synchronized by
            that clock signal generated by main. SPI devices support
            <em>much higher clock frequencies</em> than I2C. The
            <code>CS</code> signal is used to select the subnode. Note
            that this is an <strong>active low signal</strong>,
            <em>i.e.,</em> a low (<code>0</code>) is a selection and a
            high (<code>1</code>) is a disconnect. SPI is a full-duplex
            interface; both main and subnode can send data at the same
            time via the MOSI and MISO lines respectively. During SPI
            communication, the data is simultaneously transmitted
            (shifted out serially onto the MOSI/SDO bus) and received
            (the data on the bus (MISO/SDI) is sampled or read in).</p>
            <p><strong>Example</strong>: the <a
            href="https://www.analog.com/en/resources/analog-dialogue/articles/introduction-to-spi-interface.html">following
            example</a> demonstrates the significant savings and
            simplification in systems design (reduce the number of GPIO
            pins required).</p>
            <p>Consider the ADG1412 switch being managed by a
            microcontroller as follows:</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example1.svg" width="300"></p>
            <p>Now, as the number of switches increases, the requirement
            on GPIO pins also increases significantly. A
            <code>4x4</code> configuration requires <code>16</code> GPI
            pins, thus reducing the number of pins available for the
            microcontroller for other tasks, as follows:</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example2.svg" width="300"></p>
            <p>One approach to reduce the number of pins would be to use
            a serial-to-parallel convertor:</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example3.svg" width="300"></p>
            <p>This reduces the pressure on the number of GPIO pins but
            still introduces additional circuitry.</p>
            <p>Using an SPI-enabled microcontroller reduces the number
            of GPIOs required and and eliminates the overheads of the
            needing additional chips (serial-to-paralle convertor):</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example4.svg" width="300"></p>
            <p>In fact, using a different SPI configuration
            (“<strong>daisy-chain</strong>”), we can optimize the GPIO
            count even further!</p>
            <p><img src="img/embedded_arch/comms/spi_adg_example5.svg" width="300" height="250"></p>
            <p>You can read more about <a
            href="https://www.analog.com/en/resources/analog-dialogue/articles/introduction-to-spi-interface.html">SPI
            here</a>.</p>
            </section>
            </section>
            <section id="general-purpose-io-gpio" class="level3"
            data-number="2.3.3">
            <h3 data-number="2.3.3"><span
            class="header-section-number">2.3.3</span> General-Purpose
            I/O (GPIO)</h3>
            <p>A GPIO is a <strong>signal pin</strong> on an integrated
            circuit or board that can be used to perform <em>digital I/O
            operations</em>. By design, it <strong>has no predefined
            purpose</strong> → can be used by hardware/software
            developers to perform functions <em>they choose</em>,
            <em>e.g.,</em></p>
            <ul>
            <li>GPIO pins can be enabled or disabled.</li>
            <li>GPIO pins can be configured to be input or output.</li>
            <li>input values are readable, often with a 1 representing a
            high voltage, and a 0 representing a low voltage.</li>
            <li>input GPIO pins can be used as “interrupt” lines, which
            allow a peripheral board connected via multiple pins to
            signal to the primary embedded board that it requires
            attention.</li>
            <li>output pin values are both readable and writable.</li>
            </ul>
            <p>GPIOs can be implemented in a variety of ways,</p>
            <ul>
            <li>as a <em>primary</em> function of the microcontrollers,
            <em>e.g.</em>, <a
            href="https://www.geeksforgeeks.org/programmable-peripheral-interface-8255/">Intel
            8255</a></li>
            <li>as an <em>accessory</em> to the chip</li>
            </ul>
            <p>While microcontrollers may use GPIOs are their primary
            external interface, many a time the pins may be capable of
            other functions as well. In such instances, it may be
            necessary to configure the pins using other functions.</p>
            <p>Some examples of chips with GPIO pins:</p>
            <table>
            <colgroup>
            <col style="width: 27%" />
            <col style="width: 31%" />
            <col style="width: 40%" />
            </colgroup>
            <thead>
            <tr>
            <th>Intel 8255</th>
            <th>PIC microchip</th>
            <th>ASUS Tinker</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/embedded_arch/comms/gpio_Ic-photo-Intel--D8255.JPG" width="250"></td>
            <td><img src="img/embedded_arch/comms/gpio_microchip_PIC18F8720.jpg" width="150"></td>
            <td><img src="img/embedded_arch/comms/gpio_Asus_Tinker_Board.jpg" width ="200"></td>
            </tr>
            <tr>
            <td>24 GPIO pins</td>
            <td>29 GPIO pins</td>
            <td>28 GPIO pins</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>GPIOs are used in a diverse variety of applications,
            limited only by the electrical and timing specifications of
            the GPIO interface and the ability of software to interact
            with GPIOs in a sufficiently timely manner.</p>
            <p>Some “properties”/applications of GPIOs:</p>
            <ul>
            <li>GPIOs use standard logic levels and cannot supply
            significant current to output loads</li>
            <li>high-current output buffers or relays can be used to
            control high-power devices</li>
            <li>input buffers, relays, or opto-isolators translate
            incompatible signals to GPIO logic levels</li>
            <li>GPIOs can control or monitor other circuitry on a board,
            such as enabling/disabling circuits, reading switch states,
            and driving LEDs</li>
            <li>multiple GPIOs can implement bit banging communication
            interfaces like I²C or SPI</li>
            <li>GPIOs can control analog processes via PWM, adjusting
            motor speed, light intensity, or temperature</li>
            <li>PWM signals from GPIOs can be converted to analog
            control voltages using RC filters</li>
            </ul>
            <p>GPIO interfaces vary widely. Most commonly, they’re
            simple <em>groups of pins</em> that can switch between
            input/output. On the other hand, each pin can be set up
            differently → set up/accept/source different voltages/drive
            strengths/pull ups and downs.</p>
            <p>Programming the GPIO:</p>
            <ul>
            <li>usually pin states are exposed via different interfaces,
            <em>e.g.,</em> <strong>memory-mapped I/O</strong>
            peripherals or dedicated I/O port instructions</li>
            <li>input values can be used as interrupts (IRQs)</li>
            </ul>
            <p>For more information on programming/using GPIOs, read
            these: <a
            href="https://docs.oracle.com/javame/8.0/me-dev-guide/gpio.htm">GPIO
            setup and use</a>, <a
            href="https://www.instructables.com/Raspberry-Pi-Python-scripting-the-GPIO/">Python
            scripting the GPIO in Raspberry Pis</a>, <a
            href="https://docs.nordicsemi.com/bundle/ps_nrf52810/page/gpio.html">general
            purpose I/O</a>, <a
            href="https://projects.raspberrypi.org/en/projects/physical-computing/1">GPIO
            setup in Raspberry Pi</a>.</p>
            </section>
            <section id="jtag-debugging-interface" class="level3"
            data-number="2.3.4">
            <h3 data-number="2.3.4"><span
            class="header-section-number">2.3.4</span> JTAG Debugging
            Interface</h3>
            <p>The JTAG standard (named after the “Joint Test Action
            Group”), technically the <a
            href="https://web.archive.org/web/20170830070123/http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/jtag-101-ieee-1149x-paper.pdf">IEEE
            Std 1149.1-1990 IEEE Standard Test Access Port and
            Boundary-Scan Architecture</a>, is an industry standard for
            <strong>testing and verification of printed circuit
            boards</strong>, <em>after manufacture</em>.</p>
            <p>“JTAG”, depending on the context, could stand for one or
            more of the following:</p>
            <ul>
            <li>implementation of IEEE 1149.x for Board Test, or
            Boundary Scan testing</li>
            <li>appliance used to program on board flash or eeprom
            devices on a circuit board</li>
            <li>hardware device used to debug microprocessor
            software</li>
            <li>hardware device used to test a board using Boundary
            Scan</li>
            </ul>
            <p>The basic building block of a JTAG OCD is the
            <strong>Test Access Point</strong> or <strong>TAP
            controller</strong>. This allows access to all the custom
            features within a specific processor, and must support a
            minimum set of commands. On-chip debugging is a
            <em>combination of hardware and software</em>.</p>
            <table>
            <thead>
            <tr>
            <th>type</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>hardaware</td>
            <td><strong>on chip debug</strong> (OCD)</td>
            </tr>
            <tr>
            <td>software</td>
            <td><strong>in-circuit-emulator</strong> (ICE)/JTAG
            emulator</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>The off-chip parts are actually PC peripherals that need
            corresponding drivers running on a separate computer. On
            most systems, JTAG-based debugging is available from the
            very first instruction after CPU reset, letting it assist
            with development of early boot software which runs before
            anything is set up. The JTAG emulator allows developers to
            access the embedded system at the <strong>machine code
            level</strong> if needed! Many silicon architectures (Intel,
            ARM, PowerPC, etc.) have built entire infrastructures and
            extensions around JTAG.</p>
            <p>A high-level overview of the JTAG architecture/use:</p>
            <p><img src="img/embedded_arch/comms/jtag_high_level.png" width="400"></p>
            <p><br></p>
            <p>JTAG now allows for,</p>
            <ul>
            <li>processors can not be <em>halted</em>,
            <em>single-stepped</em> or <em>run freely</em></li>
            <li>can set code <em>breakpoints</em> for both, code in RAM
            as well as ROM/flash</li>
            <li><em>data breakpoints</em> are available</li>
            <li><em>bulk data download</em> to RAM</li>
            <li><em>access to registers and buses</em>, even without
            halting the processors!</li>
            <li><em>complex logic routines</em>, <em>e.g.,</em> ignore
            the first seven accesses to a register from one particular
            subroutine</li>
            </ul>
            <p>JTAG allows for <em>device programmer hardware</em>
            allows for transfering data into internal,
            <em>non-volatile</em> memory of the system! Hence, we can
            use JTAGs to <strong>program</strong> devices such as FPGAs.
            In fact, many memory chips also have JTAG interfaces. Some
            modern chips also allow access to the the (internal and
            external) data buses via JTAG.</p>
            <p><strong>JTAG interface</strong>: depending on the actual
            interface, JTAG has 2/4/5 pins. The 4/5 pin versions are
            designed so that <em>multiple chips</em> on a board can have
            their JTAG lines <strong>daisy-chained</strong> together if
            specific conditions are met.</p>
            <p>Schematic Diagram of a JTAG enabled device:</p>
            <p><img src="img/embedded_arch/comms/jtag_schematic_diagram.gif" width="300"></p>
            <p>The various pins signals in the JTAG TAP are: | signal |
            description | |——–|————-| | <code>TCK</code> | synchronizes
            the internal state machine operations | | <code>TMS</code> |
            sampled at the rising edge of <code>TCK</code> to determine
            the next state | | <code>TDI</code> | data shifted into the
            device’s test or programming logic; sampled at the rising
            edge of <code>TCK</code> when the internal state machine is
            in the correct state | | <code>TDO</code> | represents the
            data shifted out of the device’s test or programming logic
            and is valid on the falling edge of <code>TCK</code> when
            the internal state machine is in the correct state | |
            <code>TRST</code> | optional pin which, when available, can
            reset the tap controller’s state machine | ||</p>
            <p>The TAP controller implements the following state
            machine:</p>
            <p><img src="img/embedded_arch/comms/jtag_tap_state_machine.gif" width="300"></p>
            <p><br></p>
            <p>To use the JTAG interface,</p>
            <ul>
            <li>host is connected to the target’s JTAG signals
            (<code>TMS</code>, <code>TCK</code>, <code>TDI</code>,
            <code>TDO</code>, etc.) through some kind of JTAG
            adapter</li>
            <li>adapter connects to the host using some interface such
            as USB, PCI, Ethernet, etc.</li>
            <li>host communicates with the TAPs by manipulating
            <code>TMS</code> and <code>TDI</code> in conjunction with
            <code>TCK</code></li>
            <li>host reads results through <code>TDO</code> (which is
            the only standard host-side input)</li>
            <li><code>TMS</code>/<code>TDI</code>/<code>TCK</code>
            output transitions create the basic JTAG communication
            primitive on which higher layer protocols build</li>
            </ul>
            <p><br></p>
            <p>For more information about JTAG, read: <a
            href="https://web.archive.org/web/20170830070123/http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/jtag-101-ieee-1149x-paper.pdf">Intel
            JTAG Overview</a>, <a
            href="https://forums.raspberrypi.com/viewtopic.php?t=286115">Raspberry
            Pi JTAG programming</a>, <a
            href="https://www.xjtag.com/about-jtag/jtag-a-technical-overview/">Technical
            Guide to JTAG</a> and the <a
            href="https://en.wikipedia.org/wiki/JTAG">JTAG Wikipedia
            Entry</a> is quite detailed.</p>
            </section>
            <section id="controller-area-network-can" class="level3"
            data-number="2.3.5">
            <h3 data-number="2.3.5"><span
            class="header-section-number">2.3.5</span> Controller Area
            Network (CAN)</h3>
            <p>CAN is a vehicle bus standard to enable efficient
            communication between electronic control units (ECUs). CAN
            is,</p>
            <ul>
            <li>broadcast-based</li>
            <li>message-oriented</li>
            <li>uses arbitration → for data
            integrity/prioritization</li>
            </ul>
            <p>CAN <strong>does not</strong> need a a host controller.
            ECUs connected via the CAN bus can easily share information
            with each other. all ECUs are connected on a two-wire bus
            consisting of a twisted pair: CAN high and CAN low. The
            wires are often color coded:</p>
            <table>
            <tbody>
            <tr>
            <td>CAN high</td>
            <td>yellow</td>
            </tr>
            <tr>
            <td>CAN low</td>
            <td>green</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <table>
            <colgroup>
            <col style="width: 42%" />
            <col style="width: 57%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/embedded_arch/comms/can-twisted-can-bus-wiring-harness-high-low-green-yellow.svg" width="200"></td>
            <td><img src="img/embedded_arch/comms/CAN-bus_basic.svg" width="300"></td>
            </tr>
            <tr>
            <td>CAN wiring</td>
            <td>multi-ecu CAN setup</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>An ECU in a vehicle consists of:</p>
            <table>
            <tr>
            <th>
            components
            </th>
            <th>
            internal architecture
            </th>
            </tr>
            <tr>
            <td>
            <ul>
            <li>
            <b>microcontroller</b> to interpret/send out CAN messages
            </li>
            <li>
            <b>CAN controller</b> ensures all communication adheres to
            CAN protocols
            </li>
            <li>
            <b>CAN transceiver</b> connects CAN controller to the
            physical wires
            </li>
            </ul>
            </td>
            <td>
            <img src="img/embedded_arch/comms/can_ecu_internals.svg" width="250">
            </td>
            </tr>
            <tr>
            <td>
            </td>
            <td>
            </td>
            </tr>
            </table>
            <p><em>Any</em> ECU can broadcast on the CAN bus and the
            messages are accepted by <em>all</em> ECUs connected to it.
            Each ECU can either choose to ignore the message or act on
            it.</p>
            <blockquote>
            <p>what are the implications for
            <strong>security</strong>?</p>
            </blockquote>
            <p>While there is no “standard” CAN connector (each vehicle
            may use different ones), the <strong>CAN Bus DB9</strong>
            connector has become the de facto standard:</p>
            <p><img src="img/embedded_arch/comms/can-bus-db9-connector-pinout-d-sub.svg" width="350"></p>
            <p>The above figure shows the various pins and their
            signals.</p>
            <p><br></p>
            <p><strong>CAN Communication Protocols</strong>: CAN is
            split into:</p>
            <table>
            <tr>
            <th>
            layer
            </th>
            <th>
            relation to OSI stack
            </th>
            </tr>
            <tr>
            <td>
            <ul>
            <li>
            <b>data link</b>: CAN frame formats, <br>error handling,
            data transmission, <br>data integrity
            </li>
            <li>
            <b>physical</b>: cable types, <br>electrical signal levels,
            <br>node requirements, <br>cable impedance, etc.
            </li>
            </ul>
            </td>
            <td>
            <img src="img/embedded_arch/comms/can-bus-osi-model-7-layer-iso-11898-physical-data.svg" width="350">
            </td>
            </tr>
            <tr>
            <td>
            </td>
            <td>
            </td>
            </tr>
            </table>
            <p><br></p>
            <p>All communication over the CAN bus is done via the
            <strong>CAN frames</strong>. The <em>standard</em> CAN frame
            (with an <code>11-bit</code> identifier) is shown below:</p>
            <p><img src="img/embedded_arch/comms/CAN-bus-frame-standard-message-SOF-ID-RTR-Control-Data-CRC-ACK-EOF.svg" width="400"></p>
            <p><br></p>
            <p>While the lower-level CAN protocols described so far work
            on the two lowest layers of the OSI networking stack, it is
            still limiting. For instance, the CAN standard doesn’t
            discuss how to,</p>
            <ul>
            <li>decode RAW data</li>
            <li>handle larger data (more than 8 bytes)</li>
            </ul>
            <p>Hence, some <strong>higher-order</strong> protocols have
            been developed, <em>viz.,</em></p>
            <table>
            <colgroup>
            <col style="width: 42%" />
            <col style="width: 57%" />
            </colgroup>
            <thead>
            <tr>
            <th>protocol</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/obd2-explained-simple-intro">OBD2</a></td>
            <td>on-board diagnostics in cars/trucks for diagnostics,
            maintenance, emissions tests</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/uds-protocol-tutorial-unified-diagnostic-services">UDS</a></td>
            <td>Unified Diagnostic Services (UDS) used in automotive
            ECUs for diagnostics, firmware updates, routine testing</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/ccp-xcp-on-can-bus-calibration-protocol">CCP/XCP</a></td>
            <td>used in embedded control/industrial automation for
            <em>off-the-shelf interoperability</em> between CAN
            devices</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/j1939-explained-simple-intro-tutorial">SAE
            J1939</a></td>
            <td>for heavy-duty vehicles</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/nmea-2000-n2k-intro-tutorial">NMEA
            2000</a></td>
            <td> used in maritime industry for connecting e.g. engines,
            instruments, sensors on boats</td>
            </tr>
            <tr>
            <td><a
            href="https://www.csselectronics.com/pages/isobus-introduction-tutorial-iso-11783">ISOBUS</a></td>
            <td>used in agriculture and forestry machinery to enable
            plug and play integration between vehicles/implements,
            <em>across brands</em></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>There also exist other higher-order protocols (numbering
            in the thousands) the most prominent of which are: ARINC,
            UAVCAN, DeviceNet, SafetyBUS p, MilCAN, HVAC CAN.</p>
            <p><br></p>
            <p>More details about CAN and its variants: <a
            href="https://www.csselectronics.com/pages/can-bus-simple-intro-tutorial">CAN
            Bus Explained</a>.</p>
            </section>
            <section id="other-broadly-used-protocols" class="level3"
            data-number="2.3.6">
            <h3 data-number="2.3.6"><span
            class="header-section-number">2.3.6</span> Other Broadly
            Used Protocols</h3>
            <p>Autonomous (and other embedded systems) use a variety of
            other communication protocols in order to interface with the
            external world and/or other systems (either other nodes in
            the system or external components such as back end
            clouds).</p>
            <p>Note that since many of these are well known and publicly
            documented, we won’t elaborate much here.</p>
            <p>Here are some of the well known communication protocols,
            also used in embedded systems:</p>
            <table>
            <colgroup>
            <col style="width: 57%" />
            <col style="width: 42%" />
            </colgroup>
            <thead>
            <tr>
            <th>protocol</th>
            <th>links</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>USB</td>
            <td>How USB works: <a
            href="https://www.circuitbread.com/tutorials/how-usb-works-introduction-part-1">part
            1</a>, <a
            href="https://www.circuitbread.com/tutorials/how-usb-works-communication-protocol-part-2">part2</a>,
            <a
            href="https://www.circuitbread.com/tutorials/how-usb-works-enumeration-and-configuration-part-3">part
            3</a>; <a
            href="https://www.beyondlogic.org/usbnutshell/usb1.shtml">USB
            in a Nutshell (very detailed)</a>.</td>
            </tr>
            <tr>
            <td>Ethernet</td>
            <td><a
            href="https://www.embedded.com/implement-reliable-embedded-ethernet-connectivity/">Reliable
            Embedded Ethernet</a>, <a
            href="https://www.google.com/books/edition/_/3ZPPBgAAQBAJ?hl=en&amp;gbpv=1&amp;pg=PA1">Embedded
            Ethernet and Internet (book, online)</a></td>
            </tr>
            <tr>
            <td>WiFi</td>
            <td><a
            href="https://ebulutvcu.github.io/COMST22_WiFi_Sensing_Survey.pdf">WiFi
            Sensing on the Edge (paper)</a></td>
            </tr>
            <tr>
            <td>Bluetooth</td>
            <td><a
            href="https://learn.sparkfun.com/tutorials/bluetooth-basics/all">Bluetooth
            Basics</a>, <a
            href="https://novelbits.io/bluetooth-low-energy-ble-complete-guide/">Bluetooth
            Low Energy</a></td>
            </tr>
            <tr>
            <td>Radio</td>
            <td><a
            href="https://wiki.gnuradio.org/index.php/Embedded_Development_with_GNU_Radio">Embedded
            Development with GNU Radio</a></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            </section>
            </section>
            <section id="raspberry-pi-and-navio2" class="level2"
            data-number="2.4">
            <h2 data-number="2.4"><span
            class="header-section-number">2.4</span> Raspberry Pi and
            Navio2</h2>
            <p>Let us look at the two architectures we use extensively
            in this course:</p>
            <ul>
            <li><a
            href="https://www.raspberrypi.com/products/raspberry-pi-4-model-b/specifications/">Raspberry
            Pi</a> model 4(b)</li>
            <li><a href="https://navio2.hipi.io">Navio2</a> → autopilot
            hat for the Raspberry Pi</li>
            </ul>
            <p>The high-level architecture of the Pi shows many of the
            components we have discussed so far:</p>
            <p><img src="img/embedded_arch/pi-4-architectural_features.png" width="400"></p>
            <p>In particular, the Pi has,</p>
            <table>
            <colgroup>
            <col style="width: 33%" />
            <col style="width: 66%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>description/details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>processor</td>
            <td>Broadcomm <strong>BCM2711</strong>, Quad core Cortex-A72
            (ARM v8) 64-bit SoC at 1.8GHz</td>
            </tr>
            <tr>
            <td>memory</td>
            <td>1GB, 2GB, 4GB or 8GB LPDDR4-3200 SDRAM</td>
            </tr>
            <tr>
            <td>network</td>
            <td>Wifi (2.4/5.0 GHz), Gigabit ethernet, Bluetooth/BLE</td>
            </tr>
            <tr>
            <td>I/O</td>
            <td>40 pin GPIO, USB 3.0/2.0/C</td>
            </tr>
            <tr>
            <td>storage</td>
            <td>Micro-SD Card</td>
            </tr>
            <tr>
            <td>misc</td>
            <td>micro-hdmi, stereo audio/video, displayport, camera
            port, power</td>
            </tr>
            <tr>
            <td>os</td>
            <td><a
            href="https://www.raspberrypi.com/software/">Raspberry Pi
            OS</a> (formerly called Raspbian)</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Read more about the Raspberry Pi: <a
            href="https://www.electronics-lab.com/project/raspberry-pi-4-look-hood-make/">Raspberry
            PI – A Look Under the Hood</a></p>
            <p><br></p>
            <p>The <strong>Navio2</strong> is a “hat” that adds the
            following to a Raspberry Pi:</p>
            <ul>
            <li>autopilot functionality</li>
            <li>multiple sensors</li>
            </ul>
            <p>The high-level architecture,</p>
            <p><img src="img/embedded_arch/navio2_features.jpg" width="400"></p>
            <p>As the figure shows, the Navio2 adds the following
            components:</p>
            <table>
            <colgroup>
            <col style="width: 32%" />
            <col style="width: 67%" />
            </colgroup>
            <thead>
            <tr>
            <th>component</th>
            <th>description/details</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>GNSS receiver</td>
            <td>for GPS signals</td>
            </tr>
            <tr>
            <td>high-precision barometer</td>
            <td>for measuring pressure (and altitude)</td>
            </tr>
            <tr>
            <td>(dual) IMU</td>
            <td>two 9 DOF with gyroscope, accelerometer, magnetometer,
            each</td>
            </tr>
            <tr>
            <td>RC I/O co-processor</td>
            <td>PWM, ADC, SBUS, PPM</td>
            </tr>
            <tr>
            <td>extension ports</td>
            <td>ADC, I2C, UART</td>
            </tr>
            <tr>
            <td>power supply</td>
            <td>triple redundant</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>More details about the Navio2 and how to program it: <a
            href="https://docs.emlid.com/navio2/">Navio2
            Documentation</a>.</p>
            <p><br> <br></p>
            </section>
            <section id="references" class="level2" data-number="2.5">
            <h2 data-number="2.5"><span
            class="header-section-number">2.5</span> References</h2>
            </section>
            </section>
            <section id="sensors-and-sensing" class="level1"
            data-number="3">
            <h1 data-number="3"><span
            class="header-section-number">3</span> Sensors and
            Sensing</h1>
            <p>An embedded/autonomous system <em>perceives</em> the
            physical world via sensors – either to gather information
            about its environment or to model its <em>own</em> state.
            Hence it is a critical component in the <em>sensing →
            planning → actuation</em> loop and a critical component in
            the design of embedded and autonomous systems.</p>
            <table>
            <colgroup>
            <col style="width: 46%" />
            <col style="width: 53%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sense_planning_actuation.png" width="400"></td>
            <td><img src="img/stack_architecture/stack_overview.2.png" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Modern autonomous systems used a <em>wide array</em> of
            sensors. This is necessary due to:</p>
            <ul>
            <li>there is a need to measure <strong>different</strong>
            quantities, <em>e.g.,</em> GPS, velocity, objects,
            <em>etc.</em></li>
            <li>sensor measurements often have <strong>errors</strong> →
            hence, we need multiple sensors, often using
            <strong>different physical properties</strong> to measure
            the <em>same thing</em>; <em>e.g.,</em> LiDar and cameras
            can both be used to detect objects in front of, and around,
            an autonomous vehicle.</li>
            </ul>
            <p>At its core,</p>
            <blockquote>
            <p>a sensor captures a physical/chemical/environmental
            quantity and <strong>converts it to a physical
            quantity</strong>.</p>
            </blockquote>
            <p>(hence the need for an Analog-to-Digital Convertor (ADC)
            as we shall see later)</p>
            <p>By definition, sensors generate <strong>signals</strong>.
            A signal, <code>s</code>, is defined as a mapping from the
            <em>time</em> domain to a <em>value</em> domain:</p>
            <p><span
            class="math display"><em>s</em> : <em>D</em><sub><em>t</em></sub> ↦ <em>D</em><sub><em>v</em></sub></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>t</em></sub></span></td>
            <td>continuous or discrete <strong>time</strong> domain</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>v</em></sub></span></td>
            <td>continuous or discrete <strong>value</strong>
            domain</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><strong>Note:</strong> remember that computers require
            <strong>discrete</strong> sequences of physical values.
            Hence, we need to <strong>convert</strong> the above into
            the discrete domain. The way to achieve this:
            <strong>sampling</strong>:</p>
            <p><img src="img/sensors/discretization_sampled.signal.svg" title="Sampling image from Wikipedia" width="300"></p>
            <p>The figure shows a continuous signal being sampled (in
            <font color="red"><b>red</b></font> arrows). We will discuss
            sampling and related issues later in this topic.</p>
            <section id="types-of-sensors" class="level2"
            data-number="3.1">
            <h2 data-number="3.1"><span
            class="header-section-number">3.1</span> Types of
            Sensors</h2>
            <p>Sensors come in various shapes and sizes. Usually
            designers of autonomous systems will develop a
            “<strong>sensor plan</strong> that will consider,</p>
            <ul>
            <li>required functionality</li>
            <li>sensor range(s)</li>
            <li>cost</li>
            </ul>
            <p>Hence, each autonomous system will likely have its own
            set of sensors (or sensor plan). <em>Typical</em> sensors
            found on modern autonomous systems can be classified based
            on the underlying physics used:</p>
            <table>
            <colgroup>
            <col style="width: 70%" />
            <col style="width: 29%" />
            </colgroup>
            <thead>
            <tr>
            <th>physical property</th>
            <th>sensor</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><a
            href="#inertial-measurement-units-imu"><em>internal</em>
            measurements</a></td>
            <td>IMU</td>
            </tr>
            <tr>
            <td><em>external</em> measurements</td>
            <td>GPS</td>
            </tr>
            <tr>
            <td><a
            href="#bouncing-of-electromagnetic-waves--lidar-and-mmwave">“bouncing”
            electromagnetic waves</a></td>
            <td>LiDAR, RADAR, mmWave Radar</td>
            </tr>
            <tr>
            <td>optical</td>
            <td>cameras, infrared sensors</td>
            </tr>
            <tr>
            <td><a href="#ultrasonic">accoustic</a></td>
            <td>ultrasonic sensors</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Some of the above can be combined to generate other
            sensing patterns, <em>e.g.,</em> <strong>stereo
            vision</strong> using multiple cameras or camera+LiDAR.</p>
            <p>We will go over <strong>some</strong> of these sensors
            and their underlying physical principles.</p>
            <section id="inertial-measurement-units-imu" class="level3"
            data-number="3.1.1">
            <h3 data-number="3.1.1"><span
            class="header-section-number">3.1.1</span> Inertial
            Measurement Units (IMU)</h3>
            <p>These sensors define the <strong>movement of a
            vehicle</strong>, along the three axes, in addition to other
            behaviors like acceleration. An IMU typically includes the
            following sensors:</p>
            <table>
            <colgroup>
            <col style="width: 24%" />
            <col style="width: 21%" />
            <col style="width: 24%" />
            <col style="width: 29%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sensors/imu_exploded_view.jpg" width="600"></td>
            <td><img src="img/sensors/imu_accelerometer.png" width="400"></td>
            <td><img src="img/sensors/imu_gyro.png" width="400"></td>
            <td><img src="img/sensors/imu_magnetometer.png" width="400"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>As we see from the first picture above, an IMU also has a
            CPU (typically a microcontroller) to manage/collect/process
            the data from the sensors.</p>
            <p>The functions of the three sensors are:</p>
            <ol type="1">
            <li><strong>gyroscope</strong>: is an inertial sensor that
            measure an object’s angular rate with respect to an inertial
            reference frame. It measures the following movements:</li>
            </ol>
            <table>
            <colgroup>
            <col style="width: 29%" />
            <col style="width: 37%" />
            <col style="width: 33%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sensors/imu_yaw.gif"></td>
            <td><img src="img/sensors/imu_pitch.gif"></td>
            <td><img src="img/sensors/imu_roll.gif"></td>
            </tr>
            <tr>
            <td>“yaw”</td>
            <td>“pitch”</td>
            <td>“roll”</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>IMUs come in all shapes and sizes. These days they’re
            very small but the original IMU’s ver really large, as
            evidenced by the one used in the <a
            href="http://klabs.org/history/history_docs/mit_docs/1690.pdf">Apollo
            space missions</a>:</p>
            <p><img src="img/sensors/imu_apollo.jpg" width="300"></p>
            <p><br></p>
            <ol start="2" type="1">
            <li><p><strong>accelerometer</strong>: is the primary sensor
            responsible for measuring inertial acceleration, or the
            change in velocity over time.</p></li>
            <li><p><strong>magnetometer</strong>: measures the strength
            and direction of a magnetic field – to find the magnetic
            north</p></li>
            </ol>
            </section>
            <section
            id="bouncing-of-electromagnetic-waves-lidar-and-mmwave"
            class="level3" data-number="3.1.2">
            <h3 data-number="3.1.2"><span
            class="header-section-number">3.1.2</span> Bouncing of
            Electromagnetic Waves | LiDAR and mmWave</h3>
            <p>A very common principle for measuring surroundings is to
            bounce electromagnetic waves off nearby objects and
            measuring the round trip times. Shorter times indicate
            closer objects while longer times indicate objects that are
            farther away. <a
            href="https://www.noaa.gov/jetstream/doppler/how-radar-works">RADAR</a>
            is a classic example of this type of sensor and its (basic)
            operation is shown in the following image (courtesy
            NOAA):</p>
            <p><img src="img/sensors/radar_doppler_ani.gif" width="400"></p>
            <p>While many autonomous vehicles use RADAR, we will focus
            on other technologies that are more prevalent and provide
            much higher precision, <em>viz.,</em></p>
            <ol type="1">
            <li><a
            href="#light-detection-and-ranging-lidar">LiDAR</a></li>
            <li>millimeter Wave RADAR (mmWave)</li>
            </ol>
            <section id="light-detection-and-ranging-lidar"
            class="level4" data-number="3.1.2.1">
            <h4 data-number="3.1.2.1"><span
            class="header-section-number">3.1.2.1</span> Light Detection
            and Ranging (LiDAR)</h4>
            <p><a
            href="https://web.stanford.edu/class/ee259/lectures/ee259_05_lidar.pdf">LiDAR</a>
            is a sensor that uses (<em>eye safe</em>) <strong>laser
            beams</strong> for mapping surroundings and creating
            <strong>3D representation</strong> of the environment. So
            lasers are used for,</p>
            <ul>
            <li>imaging</li>
            <li>detection</li>
            <li>ranging</li>
            </ul>
            <p>We can use LiDAR to distance, angle as well as the
            <em>radial velocity</em> of some objects – all relative to
            the autonomous system (rather the sensor). So, in practice,
            this is how it operates:</p>
            <p><img src="img/sensors/lidar_principle_operation.png" width="400"></p>
            <p>We define a <strong>roundtrip time</strong>, <span
            class="math inline"><em>τ</em></span>, as the time between
            when a pulse is sent out from the transmitter
            (<code>TX</code>) to when light reflected from the object is
            detected at the receiver (<code>RX</code>).</p>
            <p>So, the <strong>target range</strong> (<em>i.e.,</em> the
            distance to te object), <span
            class="math inline"><em>R</em></span>, is measured as:</p>
            <p><span class="math display">$$
            R = \frac{c\tau}{2}
            $$</span></p>
            <p>where, <code>c</code> is the speed of light.</p>
            <p>More details (from <a
            href="https://web.stanford.edu/class/ee259/lectures/ee259_05_lidar.pdf">Mahalati</a>):
            &gt; Lasers used in lidars have frequencies in the <span
            class="math inline">100<em>s</em></span> of Terahetrz.
            Compared to RF waves, lasers have significantly smaller
            wavelengths and can hence be easily collected into narrow
            beams using lenses. This makes DOA estimation almost trivial
            in lidar and gives it significantly better reso- lution than
            MIMO imaging radar.</p>
            <p>The <em>end product</em> of LiDAR is essentially a
            <strong>point cloud</strong>, defined as:</p>
            <blockquote>
            <p>a collection of points generated by a sensor. Such
            collections can be very dense and contain billions of
            points, which enables the creation of highly detailed 3D
            representations of an area.</p>
            </blockquote>
            <p><img src="img/sensors/lidar_point_cloud_torus.gif" title="3D point cloud of a Torus. Courtesy Wikipedia"></p>
            <p>In reality, point cloud representations around autonomous
            vehicles end up looking like:</p>
            <video controls width="500">
            <source src="https://sibin.github.io/teaching/csci6907_88-gwu-secure_autonomous/fall_2022/other_docs/What-is-Lidar-video.mp4">
            </video>
            <p><a
            href="https://www.yellowscan.com/knowledge/lidar-point-cloud-basics/">Point
            clouds</a> provide valuable information, <em>viz.,</em></p>
            <ul>
            <li>3D coordinates, <span
            class="math inline">(<em>x</em>, <em>y</em>, <em>z</em>)</span></li>
            <li><strong>strength</strong> of returned signal → provides
            valuable information about the <strong>density</strong> of
            the object (or even material composition)!</li>
            <li>additional attributes: return number, scan angle, scan
            direction, point density, RGB color values, and time stamps
            → each can be used for refining the scan.</li>
            </ul>
            <p>There are <strong>two types</strong> of <em>scene
            illumination</em> techniques for LiDAR:</p>
            <table>
            <colgroup>
            <col style="width: 20%" />
            <col style="width: 52%" />
            <col style="width: 27%" />
            </colgroup>
            <thead>
            <tr>
            <th>type</th>
            <th>illumination method</th>
            <th>detector</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>flash lidar</td>
            <td><em>entire</em> scene using wide laser</td>
            <td>receives all echoes on a photodetector array</td>
            </tr>
            <tr>
            <td>scanning lidar</td>
            <td>very narrow laser beams, scan illumination spot with
            laser beam scanner</td>
            <td>single photodetector to sequentially estimate <span
            class="math inline"><em>τ</em></span> for each spot</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <table>
            <colgroup>
            <col style="width: 28%" />
            <col style="width: 28%" />
            <col style="width: 42%" />
            </colgroup>
            <thead>
            <tr>
            <th></th>
            <th>flash lidar</th>
            <th>scan lidar</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>architecture</strong></td>
            <td><img src="img/sensors/lidar_flash.png" width="400"></td>
            <td><img src="img/sensors/lidar_scan.png" width="400"></td>
            </tr>
            <tr>
            <td><strong>resolution</strong> determined by</td>
            <td>photodetector array pizel size (like camera)</td>
            <td>laser beam size and spot fixing</td>
            </tr>
            <tr>
            <td><strong>frame rates</strong></td>
            <td>higher (up to <code>100 fps</code>)</td>
            <td>lower (&lt; <code>30 fps</code>)</td>
            </tr>
            <tr>
            <td><strong>range</strong></td>
            <td>shorter (quick beam divergence, like photography)</td>
            <td>longer (<code>100m+</code>)</td>
            </tr>
            <tr>
            <td><strong>use</strong></td>
            <td>less common</td>
            <td><strong>most common</strong></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Now, consider the following scene (captured by a
            camera):</p>
            <p><img src="img/sensors/lidar_camera_image.png" width="400"></p>
            <p><br> <br></p>
            <p>Compare this to the LiDAR images captured by the two
            methods:</p>
            <table>
            <colgroup>
            <col style="width: 30%" />
            <col style="width: 30%" />
            <col style="width: 38%" />
            </colgroup>
            <thead>
            <tr>
            <th>flash lidar</th>
            <th>scan lidar (16 scan lines)</th>
            <th>scan lidar (32 scan lines)</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/sensors/lidar_flash.png" width="400"></td>
            <td><img src="img/sensors/lidar_scan_16.png" width="400"></td>
            <td><img src="img/sensors/lidar_scan_32.png" width="400"></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <blockquote>
            <p>A “LiDAR scan line” refers to a <strong>single horizontal
            line</strong> of laser pulses emitted by a LiDAR sensor,
            essentially capturing a cross-section of the environment at
            a specific angle as the sensor rotates, creating a 3D point
            cloud by combining multiple scan lines across the field of
            view; it’s the basic building block of a LiDAR scan, similar
            to how a single horizontal line is a building block of an
            image.</p>
            </blockquote>
            <p><strong>Potential Problems</strong>:</p>
            <p>Atmospheric/environmental conditions can
            <strong>negatively</strong> affect the quality of the data
            captured by the LiDAR. For instance, <strong>fog</strong>
            can scatter the laser photons resulting in <strong>false
            positives</strong>.</p>
            <p><img src="img/sensors/lidar_fog.png" width="400"></p>
            <p>As we see from the above image, the scattering due to the
            fog results in the system “identifying” multiple objects
            even though there is only <em>one</em> person in the
            scene.</p>
            <p>Here are additional examples from the <a
            href="https://www.mapix.com/lidar-scanner-sensors/velodyne/velodyne-vlp-32c/">Velodyne
            VLP-32C</a> sensor:</p>
            <ol type="1">
            <li><strong>light</strong> fog (camera vs LiDAR)</li>
            </ol>
            <p><img src="img/sensors/lidar_veoldyne_lightfog.png" width="600"></p>
            <p>The LiDAR does a good job isolating the main subject with
            very few false positives.</p>
            <ol start="2" type="1">
            <li><strong>heavy</strong> fog (camera vs LiDAR)</li>
            </ol>
            <p><img src="img/sensors/lidar_velodyne_heavyfog.png" width="600"></p>
            <p>The LiDAR <em>struggles</em> to isolate the main subject
            with very <em>high</em> false positives.</p>
            <p>In spite of these issues, LiDAR is one of the most
            popular sensors used in autonomous vehicles. They’re getting
            smaller and more precise by the day; also decreasing costs
            means that we will see a proliferation of these types of
            sensors in many autonomous systems.</p>
            <p>For an in-depth study on LiDARs, check this out: <a
            href="https://web.stanford.edu/class/ee259/lectures/ee259_05_lidar.pdf">Stanford
            EE 259 LiDAR Lecture</a>.</p>
            </section>
            <section id="millimeter-wave-radar-mmwave" class="level4"
            data-number="3.1.2.2">
            <h4 data-number="3.1.2.2"><span
            class="header-section-number">3.1.2.2</span> Millimeter Wave
            Radar [mmWave]</h4>
            <p>Short wavelengths like the *millimeter wave<strong>
            (</strong>mmWave**) in the electromagnetic spectrum allows
            for:</p>
            <ul>
            <li>smaller antennae</li>
            <li>integration of entire RADAR circuitry in a single
            chip!</li>
            <li>spectrum of 10 millimeters (<code>30 GHz</code>) to 1
            millimeter (<code>300 GHz</code>)</li>
            </ul>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <tbody>
            <tr>
            <td><img src="img/sensors/mmwave.jpg" width="300"></td>
            <td><img src="img/sensors/mmwave_ucsdavif.avif" width="300"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>As we see from the above images, the sensors can be
            <strong>very small</strong>, yet <strong>very
            precise</strong> → some can detect movements up to <em>4
            millionths of a meter</em>!</p>
            <p><strong>Advantages</strong> of mmWave:</p>
            <table>
            <colgroup>
            <col style="width: 45%" />
            <col style="width: 54%" />
            </colgroup>
            <thead>
            <tr>
            <th>Advantage</th>
            <th>Description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td>small antenna caliber</td>
            <td>narrow beam gives high tracking, accuracy; high-level
            resolution, high-resistance interference performance of
            narrow beam; high antenna gain; smaller object
            detection</td>
            </tr>
            <tr>
            <td>large bandwidth</td>
            <td>high information rate, details structural features of
            the target; reduces multipath, and enhances
            anti-interference ability; overcomes mutual interference;
            high-distance resolution</td>
            </tr>
            <tr>
            <td>high doppler frequency</td>
            <td>good detection and recognition ability of slow
            objectives and vibration targets; can work in snow
            conditions</td>
            </tr>
            <tr>
            <td>good anti-blanking performance</td>
            <td>works on the most used stealth material</td>
            </tr>
            <tr>
            <td>robustness to atmospheric conditions</td>
            <td>such as dust, smoke, and fog compared to other
            sensors</td>
            </tr>
            <tr>
            <td>operation under different lights</td>
            <td>radar can operate under bright lights, dazzling lights,
            or no lights</td>
            </tr>
            <tr>
            <td>insusceptible to ground clutter</td>
            <td>allowing for close-range observations; the low
            reflectivity can be measured using mmwave radar</td>
            </tr>
            <tr>
            <td>fine spatial resolution</td>
            <td>for the same range, mmwave radar offers finer spatial
            resolution than microwave radar &gt;</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>mmWave is also used for <strong>in-cabin monitoring of
            drivers</strong>!</p>
            <p><br></p>
            <p><strong>Limitations</strong>:</p>
            <ul>
            <li>line of sight operations</li>
            <li>affected by water content, gases in environments</li>
            <li>affected by contaminated environment and physical
            obstacles</li>
            </ul>
            <p><br></p>
            <p><strong>Resources</strong>:</p>
            <p>For a more detailed description of mmWave RADAR, read: <a
            href="https://www.design-reuse.com/articles/55851/mmwave-radar-principle-applications.html">Understanding
            mmWave RADAR, its Principle &amp; Applications</a></p>
            <p>For programming a LiDAR, see: <a
            href="h.ttps://www.engineersgarage.com/how-to-use-a-lidar-sensor-with-arduino/">how
            to program a LiDAR with an Arduino</a>.</p>
            </section>
            </section>
            <section id="ultrasonic" class="level3" data-number="3.1.3">
            <h3 data-number="3.1.3"><span
            class="header-section-number">3.1.3</span> Ultrasonic</h3>
            <p>[TBD]</p>
            </section>
            </section>
            <section id="errors-in-sensing" class="level2"
            data-number="3.2">
            <h2 data-number="3.2"><span
            class="header-section-number">3.2</span> Errors in
            Sensing</h2>
            <p>Since sensors deal with and measure the <em>physical</em>
            world, <strong>errors</strong> will creep in over time.</p>
            <p>Some typical errors in the use of physical sensors:</p>
            <table>
            <colgroup>
            <col style="width: 55%" />
            <col style="width: 44%" />
            </colgroup>
            <thead>
            <tr>
            <th>error type</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><strong>sensor drift</strong></td>
            <td>over time the sensor measurements will “drift”, i.e., a
            gradual change in its output → away from average values
            (e.g., due to wear and tear)</td>
            </tr>
            <tr>
            <td><strong>constant bias</strong></td>
            <td>bias of an accelerometer is the offset of its output
            signal from the actual acceleration value. A constant bias
            error causes an error in position which grows with time</td>
            </tr>
            <tr>
            <td><strong>calibration errors</strong></td>
            <td>‘calibration errors’ refers to errors in the scale
            factors, alignments and linearities of the gyros. Such
            errors tend to produce errors when the device is turning.
            These errors can result in additional drift</td>
            </tr>
            <tr>
            <td><strong>scale factor</strong></td>
            <td>scale factor is the relation of the accelerometer input
            to the actual sensor output for the measurement. Scale
            factor, expressed in ppm, is therefore the linear growth of
            input variation to actual measurement</td>
            </tr>
            <tr>
            <td><strong>vibration rectification errors</strong></td>
            <td>vibration rectification error (VRE) is the response of
            an accelerometer to current rectification in the sensor,
            causing a shift in the offset of the accelerometer. This can
            be a significant cumulative error, which propagates with
            time and can lead to over compensation in stabilization</td>
            </tr>
            <tr>
            <td><strong>noise</strong></td>
            <td>random variations in the sensor output that do not
            correspond to the actual measured value</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p><br></p>
            <p>Each error type must be dealt with in different ways
            though one of the commomn ways to prevent sensor errors from
            causing harm to autonomous systems → <strong>sensor
            fusion</strong>, <em>i.e.,</em> use information from
            <strong>multiple sensors</strong> before making any
            decisions. We will dicuss sensor fusion later in this
            course.</p>
            </section>
            <section id="analog-to-digital-convertors-adcs"
            class="level2" data-number="3.3">
            <h2 data-number="3.3"><span
            class="header-section-number">3.3</span> Analog to Digital
            Convertors (ADCs)</h2>
            <p>As <a href="#sensors-and-sensing">mentioned earlier</a>,
            a sensor maps a physical quantity from the time domain to
            the value domain,</p>
            <p><span
            class="math display"><em>s</em> : <em>D</em><sub><em>t</em></sub> ↦ <em>D</em><sub><em>v</em></sub></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>description</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>t</em></sub></span></td>
            <td>continuous or discrete <strong>time</strong> domain</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>D</em><sub><em>v</em></sub></span></td>
            <td>continuous or discrete <strong>value</strong>
            domain</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Remember that computers require <strong>discrete</strong>
            sequences of physical values since <strong>microcontrollers
            cannot read values unless it is digital data</strong>.
            Microcontrollers can only see “levels” of voltage, which
            depends on the resolution of the ADC and the system
            voltage.</p>
            <p>Hence, we need to <strong>convert</strong> the above into
            the discrete domain, <em>i.e.,</em> we require <span
            class="math inline"><em>D</em><sub><em>v</em></sub></span>
            to be composed of discrete values.</p>
            <p>According to <a
            href="https://en.wikipedia.org/wiki/Discrete_time_and_continuous_time#">Wikipedia</a>,</p>
            <blockquote>
            <p>A discrete signal or discrete-time signal is a time
            series consisting of a sequence of quantities. Unlike a
            continuous-time signal, a discrete-time signal is not a
            function of a continuous argument; however, it may have been
            obtained by sampling from a continuous-time signal. When a
            discrete-time signal is obtained by sampling a sequence at
            uniformly spaced times, it has an associated
            <strong>sampling rate</strong>.</p>
            </blockquote>
            <p><br></p>
            <p>A visual respresentation of the sampling rate and how it
            correlates to the sampling of an analog signal:</p>
            <table>
            <colgroup>
            <col style="width: 38%" />
            <col style="width: 38%" />
            <col style="width: 23%" />
            </colgroup>
            <thead>
            <tr>
            <th>analog signal</th>
            <th>sampling rate</th>
            <th>sampling</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><img src="img/sensors/adc_analog_signal.png"></td>
            <td><img src="img/sensors/adc_sampling_rate.png"></td>
            <td><img src="img/sensors/adc_sampling.png"></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, a device that converts analog signals to digital
            data values is called → an <strong>analog-to-digital
            convertor</strong> (<strong>ADC</strong>). This is one of
            the most common circuits/microcontrollers in embedded (and
            hence, autonomous) systems. <em>Any</em> sensor that
            measures a physical property must pass its values through an
            ADC so that the sensor values can be used by the system (the
            embedded processor/microcontroller, really).</p>
            <p>This is best described using an example:</p>
            <p><img src="img/sensors/adc_example.jpg" width="400"></p>
            <p>The <font color="blue"><b>analog</b></font> signal is
            <strong>discretized</strong> into the
            <font color="red"><b>digital</b></font> signal after passing
            through an ADC.</p>
            <p>ADCs follow a sequence:</p>
            <ul>
            <li><strong>sample</strong> the signal</li>
            <li><strong>quantify</strong> it to determine the resolution
            of the signal</li>
            <li>set <strong>binary values</strong></li>
            <li><strong>send it to the system</strong> to read the
            digital signal</li>
            </ul>
            <p>Hence, two important aspects of an ADC are:</p>
            <ul>
            <li><a href="#adc-sampling-rate">sampling rate</a></li>
            <li><a href="#adc-resolution">resolution</a></li>
            </ul>
            <section id="adc-sampling-rate" class="level3"
            data-number="3.3.1">
            <h3 data-number="3.3.1"><span
            class="header-section-number">3.3.1</span> ADC Sampling
            Rate</h3>
            <p>The sampling rate (aka Sampling Frequency) is measured in
            <strong>samples per second</strong> (SPS or S/s). It
            dictates <em>how many samples</em> (data points) are taken
            in one second. If an ADC records more samples, then it can
            handle higher frequencies.</p>
            <p>The sample rate, <span
            class="math inline"><em>f</em><sub><em>s</em></sub></span>
            is defined as,</p>
            <p><span class="math display">$$
            f_s = \frac{1}{T}
            $$</span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>definition</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>s</em></sub></span></td>
            <td>sampling rate/frequency</td>
            </tr>
            <tr>
            <td><span class="math inline"><em>T</em></span></td>
            <td>period of the sample</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>Hence, in the previous example,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>value</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>s</em></sub></span></td>
            <td><code>20 Hz</code></td>
            </tr>
            <tr>
            <td><span class="math inline"><em>T</em></span></td>
            <td><code>50 ms</code></td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>While this looks slow (<code>20 Hz</code>), the digital
            signal tracks the original analog signal quite faithfully →
            the original signal itself is quite slow
            (<code>1 Hz</code>).</p>
            <p>Now, if the sampling signal is <em>considerably
            slower</em> than the analog signal, then it loses fidelity
            and we see <strong>aliasing</strong>, where the
            reconstructed signal (the digital one in the case)
            <strong>differs from the original</strong>. Consider the
            following example of such a case:</p>
            <p><img src="img/sensors/adc_aliasing_example.jpg" width="400"></p>
            <p>As we see from the above figure, the digital output is
            <strong>nothing</strong> like the original. Hence, this
            (digital) output will not be of much use to the system.</p>
            <p><br></p>
            <p><a
            href="https://fab.cba.mit.edu/classes/S62.12/docs/Shannon_noise.pdf"><strong>Nyquist-Shannon
            Sampling Theorem</strong></a>:</p>
            <blockquote>
            <p>to accurately reconstruct a signal from its samples, the
            sampling rate must be <strong>at least twice the highest
            frequency component</strong> present in the signal</p>
            </blockquote>
            <p>If the sampling frequency is less than the Nyquist rate,
            then aliasing starts to creep in.</p>
            <p>Hence,</p>
            <p><span
            class="math display"><em>f</em><sub><em>N</em><em>y</em><em>q</em><em>u</em><em>i</em><em>s</em><em>t</em></sub> = 2 * <em>f</em><sub><em>m</em><em>a</em><em>x</em></sub></span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>definition</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>N</em><em>y</em><em>q</em><em>u</em><em>i</em><em>s</em><em>t</em></sub></span></td>
            <td>Nyquist sampling rate/frequency</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>f</em><sub><em>m</em><em>a</em><em>x</em></sub></span></td>
            <td>the maximum frequency that appears in the signal</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>For instance, if your analog signal has a maximum
            frequency of <code>50 Hz</code> then your sampling frequency
            must be <em>at least</em>, <code>100 Hz</code>. If this
            principle is followed, then it is possible to
            <strong>accurately reconstruct</strong> the original signal
            and its values.</p>
            <p>Note that sometimes <em>noise</em> can introduce
            additonal (high) frequencies into the system but we don’t
            want to sample those (for obvious purposes). Hence, it is a
            good idea to add <a
            href="https://www.analog.com/en/resources/technical-articles/guide-to-antialiasing-filter-basics.html">anti-aliasing
            fitlers</a> to the analog signal <em>before</em> it is
            passed to the ADC.</p>
            </section>
            <section id="adc-resolution" class="level3"
            data-number="3.3.2">
            <h3 data-number="3.3.2"><span
            class="header-section-number">3.3.2</span> ADC
            Resolution</h3>
            <p>An ADC’s resolution is directly related to the
            <strong>precision</strong> of the ADC, determined by its
            <strong>bit length</strong>. The following examples shows
            the fidelity of the reconstruction, based on various bit
            lengths:</p>
            <p><img src="img/sensors/adc_resolution_example.jpg" width="400"></p>
            <p>Increasing bit lengths the digital signal more closely
            represents the analog one.</p>
            <p>There exists a correlation between the bit length and the
            <strong>voltage</strong> of the signal. Hence, the
            <strong>true resolution</strong> of the ADC is calculated
            using the bit length <strong>and</strong> the voltage as
            follows:</p>
            <p><span class="math display">$$
            Step Size = \frac{V_{ref}}{N}
            $$</span></p>
            <p>where,</p>
            <table>
            <thead>
            <tr>
            <th>symbol</th>
            <th>definition</th>
            </tr>
            </thead>
            <tbody>
            <tr>
            <td><span
            class="math inline"><em>S</em><em>t</em><em>e</em><em>p</em><em>S</em><em>i</em><em>z</em><em>e</em></span></td>
            <td>resolution of each level in terms of voltage</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>V</em><sub><em>r</em><em>e</em><em>f</em></sub></span></td>
            <td>voltage reference/range of voltages</td>
            </tr>
            <tr>
            <td><span
            class="math inline"><em>N</em> = 2<sup><em>n</em></sup></span></td>
            <td>total “size” of the ADC</td>
            </tr>
            <tr>
            <td><span class="math inline"><em>n</em></span></td>
            <td>bit size</td>
            </tr>
            <tr>
            <td></td>
            <td></td>
            </tr>
            </tbody>
            </table>
            <p>This is easier to understand with a concrete example:</p>
            <blockquote>
            <p>consider a sine wave with a voltage, <code>5 V</code>
            that must be digitized. <br> If our ADC resolution is
            <code>12 bits</code>, then we get <br> <span
            class="math inline"><em>N</em> = 2<sup>12</sup> = 4096</span>
            <br> <br> Hence, <span
            class="math inline"><em>S</em><em>t</em><em>e</em><em>p</em><em>S</em><em>i</em><em>z</em><em>e</em> = 5<em>V</em>/ 4096</span>
            which is <code>0.00122V</code> (or <code>1.22mV</code>)<br>
            <br> Hence, the system can tell when a voltage level changes
            by <code>1.22 mV</code>!</p>
            </blockquote>
            <p>(Repeat the exercise for say, bit length, <span
            class="math inline"><em>n</em> = 4</span>)</p>
            <p>Hence, we see that <strong>sampling frequency</strong>
            and <strong>resolution</strong> determine the quality of
            output we get from an ADC.</p>
            <p><strong>Resources</strong></p>
            <ul>
            <li>for more details about ADC, read: <a
            href="https://www.arrow.com/en/research-and-events/articles/engineering-resource-basics-of-analog-to-digital-converters">Analog-to-Digital
            Convertor Basics</a></li>
            <li>an <strong>in-depth</strong> explanation of how ADCs
            work: <a
            href="http://class.ece.iastate.edu/cpre288/lectures/lect12_13.pdf">Iowa
            State CpreE 288 Course Slides</a></li>
            <li>more details with videos: <a
            href="https://users.ece.utexas.edu/~valvano/Volume1/E-Book/C14_ADCdataAcquisition.htm">Analog
            to Digital Conversion, EE319K Univ. of Texas</a></li>
            <li>Programming an ADC: <a
            href="https://blog.embeddedexpert.io/?p=68">1</a>, <a
            href="https://labs.dese.iisc.ac.in/embeddedlab/tm4c123-adc-programming/">2</a></li>
            </ul>
            </section>
            </section>
            </section>
            <section id="footnotes"
            class="footnotes footnotes-end-of-document"
            role="doc-endnotes">
            <hr />
            <ol>
            <li id="fn1"><p>TBD<a href="#fnref1" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            <li
            id="fn2"><p>https://dl.acm.org/doi/10.5555/244522.244548<a
            href="#fnref2" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            <li
            id="fn3"><p>https://www.cecs.uci.edu/~papers/compendium94-03/papers/2002/date02/pdffiles/05a_1.pdf<!--link rel="stylesheet" href="./custom.sibin.css"--><a
            href="#fnref3" class="footnote-back"
            role="doc-backlink">↩︎</a></p></li>
            </ol>
            </section>
            </div>
    </div>
  </div>
  <!--script src="https://vjs.zencdn.net/5.4.4/video.js"></script-->

</body>
</html>
